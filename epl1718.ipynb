{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAlperen Görmez\\nJan 16, 2020\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Alperen Görmez\n",
    "Jan 16, 2020\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamIndex = {}\n",
    "\n",
    "teamIndex[\"ArsenalFC\"] = 0\n",
    "teamIndex[\"AFCBournemouth\"] = 1\n",
    "teamIndex[\"Brighton&HoveAlbion\"] = 2\n",
    "teamIndex[\"BurnleyFC\"] = 3\n",
    "teamIndex[\"ChelseaFC\"] = 4\n",
    "teamIndex[\"CrystalPalace\"] = 5\n",
    "teamIndex[\"EvertonFC\"] = 6\n",
    "teamIndex[\"HuddersfieldTown\"] = 7\n",
    "teamIndex[\"LeicesterCity\"] = 8\n",
    "teamIndex[\"LiverpoolFC\"] = 9\n",
    "teamIndex[\"ManchesterCity\"] = 10\n",
    "teamIndex[\"ManchesterUnited\"] = 11\n",
    "teamIndex[\"NewcastleUnited\"] = 12\n",
    "teamIndex[\"SouthamptonFC\"] = 13\n",
    "teamIndex[\"StokeCity\"] = 14\n",
    "teamIndex[\"SwanseaCity\"] = 15\n",
    "teamIndex[\"TottenhamHotspur\"] = 16\n",
    "teamIndex[\"WatfordFC\"] = 17\n",
    "teamIndex[\"WestBromwichAlbion\"] = 18\n",
    "teamIndex[\"WestHamUnited\"] = 19\n",
    "\n",
    "teamResults = {}\n",
    "# 0: history of goals scored at home\n",
    "# 1: history of goals conceded at home\n",
    "# 2: history of goals conceded at away\n",
    "# 3: history of goals scored at away\n",
    "# 4: history of goals scored\n",
    "# 5: history of goals conceded\n",
    "numFeatures = 6\n",
    "\n",
    "teamResults[\"ArsenalFC\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"AFCBournemouth\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"Brighton&HoveAlbion\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"BurnleyFC\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"ChelseaFC\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"CrystalPalace\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"EvertonFC\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"HuddersfieldTown\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"LeicesterCity\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"LiverpoolFC\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"ManchesterCity\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"ManchesterUnited\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"NewcastleUnited\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"SouthamptonFC\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"StokeCity\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"SwanseaCity\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"TottenhamHotspur\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"WatfordFC\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"WestBromwichAlbion\"] = [ [] for i in range( numFeatures) ]\n",
    "teamResults[\"WestHamUnited\"] = [ [] for i in range( numFeatures) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw data\n",
    "f = open('epl1718.txt', \"r\")\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((380,52)) # 38 weeks = 380 matches, 2*6 + 20 + 20 = 52 features\n",
    "label = np.zeros((380,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alperen\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Alperen\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "matchNo = 0\n",
    "for line in lines:\n",
    "    if (line == \"\\n\") or (\"Matchday\" in line):\n",
    "        pass\n",
    "    else:\n",
    "        line = line.replace(\" \", \"\") # remove spaces\n",
    "        line = line.replace(\"\\n\", \"\") # remove \\n character\n",
    "        \n",
    "        m = re.search(r\"\\d\", line) # search an integer in the line\n",
    "        i = m.start() # the index of first integer in the line\n",
    "        \n",
    "        homeTeamName = line[:i]\n",
    "        homeTeamScore = int( line[i])\n",
    "        awayTeamName = line[i+3:]\n",
    "        awayTeamScore = int( line[i+2])\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        add the current result to the teamResults\n",
    "        \"\"\"      \n",
    "        \n",
    "        teamResults[ homeTeamName][0].append( homeTeamScore)\n",
    "        teamResults[ homeTeamName][1].append( awayTeamScore)\n",
    "        #teamResults[ homeTeamName][2].append( )\n",
    "        #teamResults[ homeTeamName][3].append( )\n",
    "        teamResults[ homeTeamName][4].append( homeTeamScore)\n",
    "        teamResults[ homeTeamName][5].append( awayTeamScore)\n",
    "        \n",
    "        #teamResults[ awayTeamName][0].append( )\n",
    "        #teamResults[ awayTeamName][1].append( )\n",
    "        teamResults[ awayTeamName][2].append( homeTeamScore)\n",
    "        teamResults[ awayTeamName][3].append( awayTeamScore)\n",
    "        teamResults[ awayTeamName][4].append( awayTeamScore)\n",
    "        teamResults[ awayTeamName][5].append( homeTeamScore)\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        add the current result to the dataset\n",
    "        \"\"\"\n",
    "        # for home team\n",
    "        # avg. goals scored at home\n",
    "        # avg. goals conceded at home\n",
    "        # avg. goals conceded at away\n",
    "        # avg. goals scored at away\n",
    "        # avg. goals scored at last 5 matches\n",
    "        # avg. goals conceded at last 5 matches\n",
    "        \n",
    "        # for away team\n",
    "        # avg. goals scored at home\n",
    "        # avg. goals conceded at home\n",
    "        # avg. goals conceded at away\n",
    "        # avg. goals scored at away\n",
    "        # avg. goals scored at last 5 matches\n",
    "        # avg. goals conceded at last 5 matches\n",
    "        \n",
    "        # which team is home, which team is away\n",
    "        \n",
    "        \n",
    "        data[matchNo][ 0] = np.mean( teamResults[ homeTeamName][0])\n",
    "        data[matchNo][ 1] = np.mean( teamResults[ homeTeamName][1])\n",
    "        data[matchNo][ 2] = np.mean( teamResults[ homeTeamName][2])\n",
    "        data[matchNo][ 3] = np.mean( teamResults[ homeTeamName][3])\n",
    "        \n",
    "        if len( teamResults[ homeTeamName][4]) >= 5:\n",
    "            data[matchNo][ 4] = np.sum( teamResults[ homeTeamName][4][-5:]) / 5.0\n",
    "        else:\n",
    "            data[matchNo][ 4] = np.sum( teamResults[ homeTeamName][4][-5:]) / len( teamResults[ homeTeamName][4])\n",
    "        \n",
    "        if len( teamResults[ homeTeamName][5]) >= 5:\n",
    "            data[matchNo][ 5] = np.sum( teamResults[ homeTeamName][5][-5:]) / 5.0\n",
    "        else:\n",
    "            data[matchNo][ 5] = np.sum( teamResults[ homeTeamName][5][-5:]) / len( teamResults[ homeTeamName][5])\n",
    "\n",
    "            \n",
    "        \n",
    "        data[matchNo][ 6] = np.mean( teamResults[ awayTeamName][0])\n",
    "        data[matchNo][ 7] = np.mean( teamResults[ awayTeamName][1])\n",
    "        data[matchNo][ 8] = np.mean( teamResults[ awayTeamName][2])\n",
    "        data[matchNo][ 9] = np.mean( teamResults[ awayTeamName][3])\n",
    "        \n",
    "        if len( teamResults[ awayTeamName][4]) >= 5:\n",
    "            data[matchNo][ 10] = np.sum( teamResults[ awayTeamName][4][-5:]) / 5.0\n",
    "        else:\n",
    "            data[matchNo][ 10] = np.sum( teamResults[ awayTeamName][4][-5:]) / len( teamResults[ awayTeamName][4])\n",
    "        \n",
    "        if len( teamResults[ homeTeamName][5]) >= 5:\n",
    "            data[matchNo][ 11] = np.sum( teamResults[ awayTeamName][5][-5:]) / 5.0\n",
    "        else:\n",
    "            data[matchNo][ 11] = np.sum( teamResults[ awayTeamName][5][-5:]) / len( teamResults[ awayTeamName][5])\n",
    "        \n",
    "        \n",
    "        homeTeamIndex = teamIndex[ homeTeamName]\n",
    "        awayTeamIndex = teamIndex[ awayTeamName]\n",
    "        \n",
    "        data[matchNo][12+homeTeamIndex] = 1.0\n",
    "        data[matchNo][32+awayTeamIndex] = 1.0\n",
    "        \n",
    "        label[ matchNo] = ( (homeTeamScore + awayTeamScore) >= 2.5 )\n",
    "        \n",
    "        matchNo += 1\n",
    "\n",
    "data = np.nan_to_num(data) # to handle division by 0's when no away games are played for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "o = label[label == 1.]\n",
    "u = label[label == 0.]\n",
    "\n",
    "g = sns.barplot( [\"Over 2.5 goals\", \"Under 2.5 goals\"], [len(o), len(u)])\n",
    "\n",
    "for p in g.patches:\n",
    "    g.annotate( format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
    "plt.title('Number of O2.5 and U2.5 Matches in EPL 2017-2018')\n",
    "plt.ylabel('Number of matches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "liv_homeMatches = np.empty([19])\n",
    "weekNumbers = np.arange(1,20)\n",
    "for weekNo in weekNumbers:\n",
    "    liv_homeMatches[weekNo-1] = (teamResults[\"LiverpoolFC\"][0][weekNo-1] + teamResults[\"LiverpoolFC\"][1][weekNo-1]) >= 2.5\n",
    "\n",
    "liv_awayMatches = np.empty([19])\n",
    "weekNumbers = np.arange(1,20)\n",
    "for weekNo in weekNumbers:\n",
    "    liv_awayMatches[weekNo-1] = (teamResults[\"LiverpoolFC\"][2][weekNo-1] + teamResults[\"LiverpoolFC\"][3][weekNo-1]) >= 2.5\n",
    "\n",
    "\n",
    "plt.scatter( weekNumbers, liv_homeMatches, c=\"r\")\n",
    "plt.xlabel(\"Home Weeks\")\n",
    "plt.title(\"Liverpool's Home Matches\")\n",
    "plt.xticks(np.arange(20))\n",
    "plt.yticks(np.arange(2), (\"U2.5\", \"O2.5\"))\n",
    "plt.show()\n",
    "\n",
    "plt.scatter( weekNumbers, liv_awayMatches, c=\"k\")\n",
    "plt.xlabel(\"Away Weeks\")\n",
    "plt.title(\"Liverpool's Away Matches\")\n",
    "plt.xticks(np.arange(20))\n",
    "plt.yticks(np.arange(2), (\"U2.5\", \"O2.5\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard first 5 weeks\n",
    "garbage_data = data[:10*5][:]\n",
    "garbage_label = label[:10*5]\n",
    "\n",
    "# weeks 6-23 are training data (18 matches for each team)\n",
    "x_train = data[10*5:10*23][:]\n",
    "y_train = label[10*5:10*23]\n",
    "\n",
    "# weeks 24-30 are validation data (7 matches for each team)\n",
    "x_val = data[10*23:10*30][:]\n",
    "y_val = label[10*23:10*30]\n",
    "\n",
    "# weeks 31-38 are test data (8 matches for each team)\n",
    "x_test = data[10*30:][:]\n",
    "y_test = label[10*30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add( layers.Dense(28, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add( layers.Dropout(0.1))\n",
    "model.add( layers.Dense(14, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add( layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/step - loss: 0.7819 - acc: 0.4778 - val_loss: 0.7517 - val_acc: 0.5143\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7409 - acc: 0.5611 - val_loss: 0.7468 - val_acc: 0.5143\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7451 - acc: 0.5333 - val_loss: 0.7447 - val_acc: 0.5429\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7334 - acc: 0.5389 - val_loss: 0.7448 - val_acc: 0.4714\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7316 - acc: 0.6000 - val_loss: 0.7450 - val_acc: 0.4857\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7316 - acc: 0.5667 - val_loss: 0.7452 - val_acc: 0.4857\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7207 - acc: 0.6056 - val_loss: 0.7446 - val_acc: 0.4714\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7156 - acc: 0.6000 - val_loss: 0.7451 - val_acc: 0.4429\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7207 - acc: 0.6444 - val_loss: 0.7434 - val_acc: 0.4286\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7159 - acc: 0.6222 - val_loss: 0.7443 - val_acc: 0.4714\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7092 - acc: 0.6278 - val_loss: 0.7446 - val_acc: 0.4857\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7058 - acc: 0.6333 - val_loss: 0.7439 - val_acc: 0.4857\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7041 - acc: 0.6278 - val_loss: 0.7420 - val_acc: 0.4857\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6980 - acc: 0.6667 - val_loss: 0.7399 - val_acc: 0.4714\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7094 - acc: 0.6500 - val_loss: 0.7396 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7002 - acc: 0.6389 - val_loss: 0.7409 - val_acc: 0.4714\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6914 - acc: 0.6333 - val_loss: 0.7393 - val_acc: 0.4714\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6943 - acc: 0.6444 - val_loss: 0.7368 - val_acc: 0.4714\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6987 - acc: 0.6389 - val_loss: 0.7343 - val_acc: 0.4714\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6925 - acc: 0.6667 - val_loss: 0.7349 - val_acc: 0.4571\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6922 - acc: 0.6611 - val_loss: 0.7360 - val_acc: 0.4857\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6859 - acc: 0.6667 - val_loss: 0.7347 - val_acc: 0.4857\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6844 - acc: 0.6556 - val_loss: 0.7341 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6888 - acc: 0.6556 - val_loss: 0.7343 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6883 - acc: 0.6500 - val_loss: 0.7313 - val_acc: 0.4857\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6691 - acc: 0.6833 - val_loss: 0.7317 - val_acc: 0.5429\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6619 - acc: 0.7000 - val_loss: 0.7281 - val_acc: 0.4857\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6657 - acc: 0.7222 - val_loss: 0.7302 - val_acc: 0.5429\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6593 - acc: 0.7056 - val_loss: 0.7287 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6652 - acc: 0.7000 - val_loss: 0.7283 - val_acc: 0.5143\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 119us/step - loss: 0.6701 - acc: 0.7111 - val_loss: 0.7300 - val_acc: 0.5286\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6584 - acc: 0.6667 - val_loss: 0.7281 - val_acc: 0.5286\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6522 - acc: 0.7000 - val_loss: 0.7246 - val_acc: 0.5286\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6606 - acc: 0.6833 - val_loss: 0.7251 - val_acc: 0.5286\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6585 - acc: 0.6889 - val_loss: 0.7252 - val_acc: 0.5143\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6465 - acc: 0.7056 - val_loss: 0.7204 - val_acc: 0.5571\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6493 - acc: 0.7167 - val_loss: 0.7224 - val_acc: 0.5429\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6553 - acc: 0.6778 - val_loss: 0.7222 - val_acc: 0.5429\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6444 - acc: 0.7222 - val_loss: 0.7229 - val_acc: 0.5429\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6302 - acc: 0.7611 - val_loss: 0.7235 - val_acc: 0.5429\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6361 - acc: 0.7278 - val_loss: 0.7259 - val_acc: 0.5429\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6344 - acc: 0.7167 - val_loss: 0.7196 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6337 - acc: 0.7222 - val_loss: 0.7211 - val_acc: 0.5714\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6318 - acc: 0.7222 - val_loss: 0.7220 - val_acc: 0.5571\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6261 - acc: 0.7222 - val_loss: 0.7238 - val_acc: 0.5286\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6293 - acc: 0.7389 - val_loss: 0.7192 - val_acc: 0.5571\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.6132 - acc: 0.7278 - val_loss: 0.7180 - val_acc: 0.5857\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6146 - acc: 0.7444 - val_loss: 0.7213 - val_acc: 0.5714\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6122 - acc: 0.7389 - val_loss: 0.7246 - val_acc: 0.5571\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6134 - acc: 0.7389 - val_loss: 0.7158 - val_acc: 0.5857\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6054 - acc: 0.7556 - val_loss: 0.7153 - val_acc: 0.5714\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6070 - acc: 0.7389 - val_loss: 0.7184 - val_acc: 0.5857\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6019 - acc: 0.7500 - val_loss: 0.7162 - val_acc: 0.5857\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6180 - acc: 0.7111 - val_loss: 0.7139 - val_acc: 0.5857\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5863 - acc: 0.7833 - val_loss: 0.7198 - val_acc: 0.6000\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5833 - acc: 0.7667 - val_loss: 0.7149 - val_acc: 0.5857\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6069 - acc: 0.7278 - val_loss: 0.7145 - val_acc: 0.5857\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6078 - acc: 0.7278 - val_loss: 0.7105 - val_acc: 0.6143\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5863 - acc: 0.7556 - val_loss: 0.7154 - val_acc: 0.5857\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5769 - acc: 0.7833 - val_loss: 0.7148 - val_acc: 0.5857\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 78us/step - loss: 0.5845 - acc: 0.7556 - val_loss: 0.7149 - val_acc: 0.5857\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5976 - acc: 0.7556 - val_loss: 0.7097 - val_acc: 0.6429\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5795 - acc: 0.7722 - val_loss: 0.7161 - val_acc: 0.6000\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5697 - acc: 0.7556 - val_loss: 0.7086 - val_acc: 0.6429\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5852 - acc: 0.7444 - val_loss: 0.7087 - val_acc: 0.6429\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5659 - acc: 0.7722 - val_loss: 0.7129 - val_acc: 0.6429\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5624 - acc: 0.7889 - val_loss: 0.7118 - val_acc: 0.6286\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5577 - acc: 0.7833 - val_loss: 0.7075 - val_acc: 0.6429\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5675 - acc: 0.7833 - val_loss: 0.7076 - val_acc: 0.6429\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5778 - acc: 0.7500 - val_loss: 0.7098 - val_acc: 0.6429\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 74us/step - loss: 0.5612 - acc: 0.7722 - val_loss: 0.7062 - val_acc: 0.6286\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5358 - acc: 0.8056 - val_loss: 0.7098 - val_acc: 0.6429\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5539 - acc: 0.7889 - val_loss: 0.7066 - val_acc: 0.6143\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5415 - acc: 0.8000 - val_loss: 0.7079 - val_acc: 0.6429\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5583 - acc: 0.7667 - val_loss: 0.7063 - val_acc: 0.6286\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 66us/step - loss: 0.5175 - acc: 0.8056 - val_loss: 0.7096 - val_acc: 0.6429\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5398 - acc: 0.8000 - val_loss: 0.7185 - val_acc: 0.6571\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 80us/step - loss: 0.5377 - acc: 0.7667 - val_loss: 0.7113 - val_acc: 0.6429\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5409 - acc: 0.7778 - val_loss: 0.7069 - val_acc: 0.5857\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5269 - acc: 0.8000 - val_loss: 0.7109 - val_acc: 0.6286\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5421 - acc: 0.7944 - val_loss: 0.7103 - val_acc: 0.6143\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5152 - acc: 0.8222 - val_loss: 0.7164 - val_acc: 0.6429\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5233 - acc: 0.7889 - val_loss: 0.7194 - val_acc: 0.6571\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5191 - acc: 0.8222 - val_loss: 0.7265 - val_acc: 0.6571\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5293 - acc: 0.8111 - val_loss: 0.7308 - val_acc: 0.6429\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5414 - acc: 0.7667 - val_loss: 0.7217 - val_acc: 0.6571\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5113 - acc: 0.8167 - val_loss: 0.7273 - val_acc: 0.6571\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5038 - acc: 0.8333 - val_loss: 0.7243 - val_acc: 0.6429\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5053 - acc: 0.8056 - val_loss: 0.7202 - val_acc: 0.6286\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5195 - acc: 0.7778 - val_loss: 0.7215 - val_acc: 0.6429\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.4992 - acc: 0.7944 - val_loss: 0.7228 - val_acc: 0.6429\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5095 - acc: 0.7889 - val_loss: 0.7197 - val_acc: 0.5857\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5064 - acc: 0.7889 - val_loss: 0.7258 - val_acc: 0.6143\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5036 - acc: 0.7833 - val_loss: 0.7373 - val_acc: 0.6429\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5043 - acc: 0.7889 - val_loss: 0.7380 - val_acc: 0.6429\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.4979 - acc: 0.7833 - val_loss: 0.7250 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.4883 - acc: 0.8111 - val_loss: 0.7324 - val_acc: 0.6143\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.4829 - acc: 0.8222 - val_loss: 0.7263 - val_acc: 0.6000\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.4917 - acc: 0.7889 - val_loss: 0.7405 - val_acc: 0.6429\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.4704 - acc: 0.8333 - val_loss: 0.7324 - val_acc: 0.6143\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 28)                1484      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 1,905\n",
      "Trainable params: 1,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7656 - acc: 0.5222 - val_loss: 0.7230 - val_acc: 0.5857\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7384 - acc: 0.5889 - val_loss: 0.7187 - val_acc: 0.6143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7305 - acc: 0.5611 - val_loss: 0.7180 - val_acc: 0.6714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7288 - acc: 0.5444 - val_loss: 0.7167 - val_acc: 0.6714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7203 - acc: 0.5833 - val_loss: 0.7161 - val_acc: 0.6286\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7304 - acc: 0.5667 - val_loss: 0.7168 - val_acc: 0.6000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7124 - acc: 0.5889 - val_loss: 0.7137 - val_acc: 0.6429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7053 - acc: 0.5944 - val_loss: 0.7128 - val_acc: 0.6429\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6989 - acc: 0.6278 - val_loss: 0.7138 - val_acc: 0.6286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7005 - acc: 0.6000 - val_loss: 0.7106 - val_acc: 0.6429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6927 - acc: 0.6222 - val_loss: 0.7101 - val_acc: 0.6571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6979 - acc: 0.6333 - val_loss: 0.7102 - val_acc: 0.6286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6964 - acc: 0.6167 - val_loss: 0.7113 - val_acc: 0.6000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6919 - acc: 0.6278 - val_loss: 0.7114 - val_acc: 0.5857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6870 - acc: 0.6500 - val_loss: 0.7095 - val_acc: 0.6000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6892 - acc: 0.6056 - val_loss: 0.7101 - val_acc: 0.6000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6870 - acc: 0.6111 - val_loss: 0.7113 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.6897 - acc: 0.6333 - val_loss: 0.7129 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6762 - acc: 0.6000 - val_loss: 0.7091 - val_acc: 0.6000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6633 - acc: 0.6667 - val_loss: 0.7046 - val_acc: 0.6286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6694 - acc: 0.6500 - val_loss: 0.7047 - val_acc: 0.6143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6684 - acc: 0.6556 - val_loss: 0.7025 - val_acc: 0.6286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6691 - acc: 0.7000 - val_loss: 0.7045 - val_acc: 0.6000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6686 - acc: 0.6722 - val_loss: 0.7034 - val_acc: 0.6000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6628 - acc: 0.6778 - val_loss: 0.7022 - val_acc: 0.6000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6491 - acc: 0.7333 - val_loss: 0.7024 - val_acc: 0.6000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6543 - acc: 0.6667 - val_loss: 0.7008 - val_acc: 0.6143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6488 - acc: 0.6944 - val_loss: 0.7002 - val_acc: 0.6286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.6598 - acc: 0.6944 - val_loss: 0.7030 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6476 - acc: 0.7000 - val_loss: 0.7024 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6489 - acc: 0.6556 - val_loss: 0.6996 - val_acc: 0.5857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6446 - acc: 0.7000 - val_loss: 0.6955 - val_acc: 0.6714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6316 - acc: 0.7222 - val_loss: 0.6929 - val_acc: 0.6857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6562 - acc: 0.6833 - val_loss: 0.6946 - val_acc: 0.6429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6553 - acc: 0.6556 - val_loss: 0.6926 - val_acc: 0.6571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6447 - acc: 0.7056 - val_loss: 0.6933 - val_acc: 0.6571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6327 - acc: 0.7333 - val_loss: 0.6935 - val_acc: 0.6571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6332 - acc: 0.7222 - val_loss: 0.6907 - val_acc: 0.6857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6316 - acc: 0.7556 - val_loss: 0.6937 - val_acc: 0.6571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6248 - acc: 0.7389 - val_loss: 0.6953 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6133 - acc: 0.7444 - val_loss: 0.6948 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6361 - acc: 0.7056 - val_loss: 0.6917 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6182 - acc: 0.7278 - val_loss: 0.6883 - val_acc: 0.6714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6170 - acc: 0.7500 - val_loss: 0.6914 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6260 - acc: 0.7278 - val_loss: 0.6915 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6073 - acc: 0.7389 - val_loss: 0.6950 - val_acc: 0.6429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6202 - acc: 0.6889 - val_loss: 0.6951 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6041 - acc: 0.7611 - val_loss: 0.6946 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6018 - acc: 0.7444 - val_loss: 0.6897 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5902 - acc: 0.7722 - val_loss: 0.6892 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5929 - acc: 0.7611 - val_loss: 0.6928 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5961 - acc: 0.7333 - val_loss: 0.6897 - val_acc: 0.6286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5884 - acc: 0.7833 - val_loss: 0.6897 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5971 - acc: 0.7611 - val_loss: 0.6941 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5875 - acc: 0.7611 - val_loss: 0.6899 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5912 - acc: 0.7722 - val_loss: 0.6895 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5712 - acc: 0.7667 - val_loss: 0.6911 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5704 - acc: 0.7778 - val_loss: 0.6879 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5526 - acc: 0.7833 - val_loss: 0.6950 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5672 - acc: 0.7667 - val_loss: 0.6998 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5896 - acc: 0.7389 - val_loss: 0.6937 - val_acc: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5783 - acc: 0.7444 - val_loss: 0.6889 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5734 - acc: 0.7667 - val_loss: 0.6866 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5599 - acc: 0.8222 - val_loss: 0.6877 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5644 - acc: 0.7944 - val_loss: 0.6890 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5722 - acc: 0.7611 - val_loss: 0.6872 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5600 - acc: 0.7889 - val_loss: 0.7020 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5425 - acc: 0.7889 - val_loss: 0.7002 - val_acc: 0.6286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5581 - acc: 0.7667 - val_loss: 0.6910 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5435 - acc: 0.7833 - val_loss: 0.6951 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5501 - acc: 0.7944 - val_loss: 0.6969 - val_acc: 0.6286\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5399 - acc: 0.7833 - val_loss: 0.6983 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5487 - acc: 0.7667 - val_loss: 0.6953 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5504 - acc: 0.7722 - val_loss: 0.6971 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5532 - acc: 0.7944 - val_loss: 0.6964 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5314 - acc: 0.7833 - val_loss: 0.6892 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5469 - acc: 0.7556 - val_loss: 0.6912 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5384 - acc: 0.7889 - val_loss: 0.6932 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5326 - acc: 0.7889 - val_loss: 0.6927 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5188 - acc: 0.8111 - val_loss: 0.6917 - val_acc: 0.6143\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add( layers.Dense(28, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add( layers.Dropout(0.1))\n",
    "model.add( layers.Dense(14, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add( layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=80,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 124us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6672247648239136, 0.6375]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate( x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7399 - acc: 0.5278 - val_loss: 0.7527 - val_acc: 0.5429\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7242 - acc: 0.5389 - val_loss: 0.7539 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7269 - acc: 0.5556 - val_loss: 0.7491 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7130 - acc: 0.5667 - val_loss: 0.7502 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7121 - acc: 0.5667 - val_loss: 0.7472 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7223 - acc: 0.5667 - val_loss: 0.7415 - val_acc: 0.5429\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7141 - acc: 0.5778 - val_loss: 0.7392 - val_acc: 0.5571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7012 - acc: 0.6056 - val_loss: 0.7359 - val_acc: 0.5714\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7062 - acc: 0.6000 - val_loss: 0.7376 - val_acc: 0.5571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7043 - acc: 0.5833 - val_loss: 0.7354 - val_acc: 0.5714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6899 - acc: 0.5833 - val_loss: 0.7377 - val_acc: 0.5857\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6993 - acc: 0.5778 - val_loss: 0.7341 - val_acc: 0.5714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6969 - acc: 0.6167 - val_loss: 0.7311 - val_acc: 0.5714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6980 - acc: 0.6056 - val_loss: 0.7291 - val_acc: 0.5714\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6999 - acc: 0.5944 - val_loss: 0.7304 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6851 - acc: 0.6333 - val_loss: 0.7268 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6791 - acc: 0.6389 - val_loss: 0.7297 - val_acc: 0.6000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6817 - acc: 0.6611 - val_loss: 0.7312 - val_acc: 0.6143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6757 - acc: 0.6333 - val_loss: 0.7292 - val_acc: 0.6143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6736 - acc: 0.6444 - val_loss: 0.7234 - val_acc: 0.6000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6718 - acc: 0.6889 - val_loss: 0.7228 - val_acc: 0.6143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6629 - acc: 0.6667 - val_loss: 0.7243 - val_acc: 0.6000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6646 - acc: 0.6556 - val_loss: 0.7216 - val_acc: 0.6143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6681 - acc: 0.6444 - val_loss: 0.7187 - val_acc: 0.6286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6732 - acc: 0.6556 - val_loss: 0.7223 - val_acc: 0.6000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6600 - acc: 0.6778 - val_loss: 0.7228 - val_acc: 0.6000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6617 - acc: 0.6611 - val_loss: 0.7226 - val_acc: 0.6000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6538 - acc: 0.6778 - val_loss: 0.7162 - val_acc: 0.6429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6525 - acc: 0.7222 - val_loss: 0.7170 - val_acc: 0.6286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6459 - acc: 0.6556 - val_loss: 0.7227 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6532 - acc: 0.6444 - val_loss: 0.7172 - val_acc: 0.6000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6406 - acc: 0.7389 - val_loss: 0.7234 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6304 - acc: 0.7000 - val_loss: 0.7178 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6280 - acc: 0.7056 - val_loss: 0.7115 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6267 - acc: 0.7722 - val_loss: 0.7117 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6121 - acc: 0.7556 - val_loss: 0.7134 - val_acc: 0.6000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6395 - acc: 0.7389 - val_loss: 0.7202 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6279 - acc: 0.7000 - val_loss: 0.7121 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6200 - acc: 0.7389 - val_loss: 0.7087 - val_acc: 0.6429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6309 - acc: 0.7278 - val_loss: 0.7105 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6127 - acc: 0.7333 - val_loss: 0.7101 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6046 - acc: 0.7611 - val_loss: 0.7095 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6158 - acc: 0.7444 - val_loss: 0.7102 - val_acc: 0.6286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6057 - acc: 0.7222 - val_loss: 0.7076 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5961 - acc: 0.7667 - val_loss: 0.6988 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6157 - acc: 0.7333 - val_loss: 0.7096 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5877 - acc: 0.7778 - val_loss: 0.7050 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5833 - acc: 0.7722 - val_loss: 0.7061 - val_acc: 0.6429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5882 - acc: 0.7611 - val_loss: 0.7088 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5920 - acc: 0.7611 - val_loss: 0.7001 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.5831 - acc: 0.8000 - val_loss: 0.7024 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5789 - acc: 0.7778 - val_loss: 0.6977 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5697 - acc: 0.7722 - val_loss: 0.6983 - val_acc: 0.5571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5898 - acc: 0.7611 - val_loss: 0.6982 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5774 - acc: 0.7722 - val_loss: 0.7048 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5767 - acc: 0.7611 - val_loss: 0.6963 - val_acc: 0.5857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5697 - acc: 0.7722 - val_loss: 0.7016 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5540 - acc: 0.8167 - val_loss: 0.7017 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5614 - acc: 0.7778 - val_loss: 0.6960 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5731 - acc: 0.8000 - val_loss: 0.7122 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5509 - acc: 0.7722 - val_loss: 0.7044 - val_acc: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5596 - acc: 0.7944 - val_loss: 0.6938 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5477 - acc: 0.8111 - val_loss: 0.6943 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5450 - acc: 0.7889 - val_loss: 0.7046 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5564 - acc: 0.7500 - val_loss: 0.6997 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5535 - acc: 0.7833 - val_loss: 0.7054 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5315 - acc: 0.8167 - val_loss: 0.7054 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5282 - acc: 0.7833 - val_loss: 0.6950 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5325 - acc: 0.7833 - val_loss: 0.7021 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5351 - acc: 0.8278 - val_loss: 0.7092 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5115 - acc: 0.8056 - val_loss: 0.6938 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5216 - acc: 0.7944 - val_loss: 0.6935 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5316 - acc: 0.8167 - val_loss: 0.7002 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5108 - acc: 0.8333 - val_loss: 0.7165 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 84us/step - loss: 0.5227 - acc: 0.7778 - val_loss: 0.7004 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5139 - acc: 0.8000 - val_loss: 0.6929 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5014 - acc: 0.8278 - val_loss: 0.7069 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5074 - acc: 0.8111 - val_loss: 0.7020 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5195 - acc: 0.8111 - val_loss: 0.6992 - val_acc: 0.6429\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5029 - acc: 0.8278 - val_loss: 0.7151 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.7418 - acc: 0.5500 - val_loss: 0.7580 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7304 - acc: 0.5444 - val_loss: 0.7600 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7267 - acc: 0.5722 - val_loss: 0.7553 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7296 - acc: 0.5333 - val_loss: 0.7546 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7197 - acc: 0.5778 - val_loss: 0.7563 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7351 - acc: 0.5278 - val_loss: 0.7527 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7244 - acc: 0.5500 - val_loss: 0.7503 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7064 - acc: 0.5944 - val_loss: 0.7488 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7172 - acc: 0.5444 - val_loss: 0.7457 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7045 - acc: 0.5833 - val_loss: 0.7455 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7156 - acc: 0.5444 - val_loss: 0.7422 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6932 - acc: 0.6278 - val_loss: 0.7379 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7013 - acc: 0.5889 - val_loss: 0.7361 - val_acc: 0.4857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6992 - acc: 0.6111 - val_loss: 0.7385 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7021 - acc: 0.5889 - val_loss: 0.7359 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6776 - acc: 0.6444 - val_loss: 0.7336 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6860 - acc: 0.6556 - val_loss: 0.7337 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7062 - acc: 0.5667 - val_loss: 0.7282 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6869 - acc: 0.6333 - val_loss: 0.7290 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6840 - acc: 0.6333 - val_loss: 0.7302 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6844 - acc: 0.6278 - val_loss: 0.7236 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6847 - acc: 0.6556 - val_loss: 0.7212 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6825 - acc: 0.6667 - val_loss: 0.7251 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6858 - acc: 0.6333 - val_loss: 0.7225 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6775 - acc: 0.6611 - val_loss: 0.7215 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6673 - acc: 0.6722 - val_loss: 0.7223 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6664 - acc: 0.6611 - val_loss: 0.7164 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6614 - acc: 0.6833 - val_loss: 0.7228 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6685 - acc: 0.6833 - val_loss: 0.7272 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6521 - acc: 0.6944 - val_loss: 0.7243 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6662 - acc: 0.6778 - val_loss: 0.7211 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6630 - acc: 0.6556 - val_loss: 0.7200 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6473 - acc: 0.6889 - val_loss: 0.7187 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6543 - acc: 0.6889 - val_loss: 0.7143 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6504 - acc: 0.6611 - val_loss: 0.7125 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6613 - acc: 0.6889 - val_loss: 0.7129 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6476 - acc: 0.7000 - val_loss: 0.7136 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6446 - acc: 0.7000 - val_loss: 0.7124 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6444 - acc: 0.6667 - val_loss: 0.7088 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6465 - acc: 0.6778 - val_loss: 0.7131 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6325 - acc: 0.6944 - val_loss: 0.7112 - val_acc: 0.6143\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6488 - acc: 0.6778 - val_loss: 0.7054 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6295 - acc: 0.7278 - val_loss: 0.7104 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6266 - acc: 0.7056 - val_loss: 0.7024 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6335 - acc: 0.7278 - val_loss: 0.7027 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6297 - acc: 0.7333 - val_loss: 0.6991 - val_acc: 0.5571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6203 - acc: 0.7444 - val_loss: 0.7053 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6158 - acc: 0.7389 - val_loss: 0.7110 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6214 - acc: 0.7389 - val_loss: 0.7077 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6262 - acc: 0.7056 - val_loss: 0.7000 - val_acc: 0.5571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6162 - acc: 0.7389 - val_loss: 0.6946 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 84us/step - loss: 0.6117 - acc: 0.7222 - val_loss: 0.6951 - val_acc: 0.5429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6037 - acc: 0.7444 - val_loss: 0.7012 - val_acc: 0.5571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6048 - acc: 0.7444 - val_loss: 0.6953 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6038 - acc: 0.7889 - val_loss: 0.6947 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6233 - acc: 0.7000 - val_loss: 0.6950 - val_acc: 0.5571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6024 - acc: 0.7333 - val_loss: 0.6936 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5932 - acc: 0.7333 - val_loss: 0.7023 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5984 - acc: 0.7167 - val_loss: 0.6996 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5921 - acc: 0.7556 - val_loss: 0.7031 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5872 - acc: 0.7444 - val_loss: 0.7090 - val_acc: 0.5857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5778 - acc: 0.7278 - val_loss: 0.6990 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5821 - acc: 0.7556 - val_loss: 0.7019 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5902 - acc: 0.7000 - val_loss: 0.6927 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5899 - acc: 0.7333 - val_loss: 0.6937 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5912 - acc: 0.7722 - val_loss: 0.6964 - val_acc: 0.5857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5779 - acc: 0.7333 - val_loss: 0.6938 - val_acc: 0.5857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5812 - acc: 0.7611 - val_loss: 0.6912 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 92us/step - loss: 0.5734 - acc: 0.7556 - val_loss: 0.6921 - val_acc: 0.5857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5839 - acc: 0.7833 - val_loss: 0.7008 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5704 - acc: 0.7778 - val_loss: 0.6904 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5638 - acc: 0.7722 - val_loss: 0.6921 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5637 - acc: 0.7500 - val_loss: 0.6984 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.5684 - acc: 0.742 - 0s 104us/step - loss: 0.5533 - acc: 0.7722 - val_loss: 0.6946 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5649 - acc: 0.7444 - val_loss: 0.6937 - val_acc: 0.5857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5551 - acc: 0.7556 - val_loss: 0.6925 - val_acc: 0.5857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5688 - acc: 0.7611 - val_loss: 0.6911 - val_acc: 0.5857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5440 - acc: 0.7722 - val_loss: 0.6954 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5580 - acc: 0.7389 - val_loss: 0.6968 - val_acc: 0.5857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5540 - acc: 0.7667 - val_loss: 0.6958 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.7958 - acc: 0.4667 - val_loss: 0.7543 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7612 - acc: 0.5167 - val_loss: 0.7522 - val_acc: 0.4857\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7452 - acc: 0.5611 - val_loss: 0.7508 - val_acc: 0.4857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7277 - acc: 0.5889 - val_loss: 0.7518 - val_acc: 0.4857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7313 - acc: 0.5667 - val_loss: 0.7491 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7126 - acc: 0.5889 - val_loss: 0.7516 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7059 - acc: 0.5944 - val_loss: 0.7517 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.7235 - acc: 0.5500 - val_loss: 0.7496 - val_acc: 0.5429\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7294 - acc: 0.5667 - val_loss: 0.7496 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7152 - acc: 0.5667 - val_loss: 0.7425 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7169 - acc: 0.5722 - val_loss: 0.7414 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7083 - acc: 0.5778 - val_loss: 0.7424 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7104 - acc: 0.5778 - val_loss: 0.7402 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 82us/step - loss: 0.7033 - acc: 0.6389 - val_loss: 0.7412 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7096 - acc: 0.5833 - val_loss: 0.7421 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7153 - acc: 0.5778 - val_loss: 0.7451 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7079 - acc: 0.5944 - val_loss: 0.7370 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7018 - acc: 0.6056 - val_loss: 0.7369 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6992 - acc: 0.6056 - val_loss: 0.7316 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6914 - acc: 0.6222 - val_loss: 0.7329 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6944 - acc: 0.6278 - val_loss: 0.7284 - val_acc: 0.5571\n",
      "Epoch 22/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6923 - acc: 0.6611 - val_loss: 0.7261 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6842 - acc: 0.6333 - val_loss: 0.7255 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6883 - acc: 0.6556 - val_loss: 0.7243 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6771 - acc: 0.7000 - val_loss: 0.7290 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6837 - acc: 0.6333 - val_loss: 0.7271 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 82us/step - loss: 0.6781 - acc: 0.6944 - val_loss: 0.7261 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6959 - acc: 0.6111 - val_loss: 0.7292 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6674 - acc: 0.6833 - val_loss: 0.7311 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6722 - acc: 0.6500 - val_loss: 0.7215 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6658 - acc: 0.6889 - val_loss: 0.7278 - val_acc: 0.5286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6645 - acc: 0.6778 - val_loss: 0.7284 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6619 - acc: 0.6667 - val_loss: 0.7208 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6641 - acc: 0.6889 - val_loss: 0.7186 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6652 - acc: 0.6944 - val_loss: 0.7192 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6654 - acc: 0.6833 - val_loss: 0.7203 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6655 - acc: 0.6778 - val_loss: 0.7165 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6655 - acc: 0.6778 - val_loss: 0.7218 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6546 - acc: 0.6667 - val_loss: 0.7169 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6502 - acc: 0.6833 - val_loss: 0.7229 - val_acc: 0.5429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6623 - acc: 0.6833 - val_loss: 0.7165 - val_acc: 0.5429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6450 - acc: 0.7056 - val_loss: 0.7250 - val_acc: 0.5429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6474 - acc: 0.7167 - val_loss: 0.7208 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6429 - acc: 0.6722 - val_loss: 0.7151 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6543 - acc: 0.6722 - val_loss: 0.7158 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6495 - acc: 0.6778 - val_loss: 0.7215 - val_acc: 0.5571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6404 - acc: 0.7111 - val_loss: 0.7141 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6437 - acc: 0.7111 - val_loss: 0.7099 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6319 - acc: 0.7167 - val_loss: 0.7145 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6289 - acc: 0.6944 - val_loss: 0.7094 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6324 - acc: 0.7389 - val_loss: 0.7108 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6222 - acc: 0.7611 - val_loss: 0.7122 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6262 - acc: 0.7056 - val_loss: 0.7103 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6194 - acc: 0.7611 - val_loss: 0.7122 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6136 - acc: 0.7333 - val_loss: 0.7064 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6056 - acc: 0.7667 - val_loss: 0.7174 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6046 - acc: 0.7278 - val_loss: 0.7196 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6117 - acc: 0.7222 - val_loss: 0.7088 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6161 - acc: 0.7556 - val_loss: 0.7045 - val_acc: 0.6714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5989 - acc: 0.8000 - val_loss: 0.7037 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5969 - acc: 0.7778 - val_loss: 0.7042 - val_acc: 0.6571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5910 - acc: 0.7778 - val_loss: 0.7018 - val_acc: 0.6714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6039 - acc: 0.7444 - val_loss: 0.6986 - val_acc: 0.6714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5980 - acc: 0.7500 - val_loss: 0.6985 - val_acc: 0.6714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5961 - acc: 0.7389 - val_loss: 0.7000 - val_acc: 0.6714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5701 - acc: 0.7889 - val_loss: 0.6998 - val_acc: 0.6714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5925 - acc: 0.7389 - val_loss: 0.7095 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5764 - acc: 0.7611 - val_loss: 0.6969 - val_acc: 0.6714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5911 - acc: 0.7667 - val_loss: 0.6977 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5907 - acc: 0.7667 - val_loss: 0.6973 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5883 - acc: 0.7833 - val_loss: 0.7078 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5897 - acc: 0.7778 - val_loss: 0.7171 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5704 - acc: 0.7722 - val_loss: 0.7096 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5747 - acc: 0.7444 - val_loss: 0.7098 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6076 - acc: 0.7556 - val_loss: 0.7018 - val_acc: 0.6571\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5851 - acc: 0.7556 - val_loss: 0.7101 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5738 - acc: 0.7611 - val_loss: 0.7070 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5737 - acc: 0.7556 - val_loss: 0.7095 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5752 - acc: 0.7611 - val_loss: 0.7065 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5697 - acc: 0.7722 - val_loss: 0.7130 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.7560 - acc: 0.5167 - val_loss: 0.7432 - val_acc: 0.5714\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 77us/step - loss: 0.7309 - acc: 0.5500 - val_loss: 0.7289 - val_acc: 0.5429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7293 - acc: 0.5889 - val_loss: 0.7290 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7192 - acc: 0.5722 - val_loss: 0.7288 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7096 - acc: 0.5778 - val_loss: 0.7248 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7107 - acc: 0.5611 - val_loss: 0.7179 - val_acc: 0.6143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7164 - acc: 0.5444 - val_loss: 0.7146 - val_acc: 0.5571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7209 - acc: 0.5500 - val_loss: 0.7113 - val_acc: 0.5714\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7156 - acc: 0.5667 - val_loss: 0.7170 - val_acc: 0.5857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6980 - acc: 0.6167 - val_loss: 0.7141 - val_acc: 0.5571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6974 - acc: 0.5722 - val_loss: 0.7159 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6951 - acc: 0.6167 - val_loss: 0.7085 - val_acc: 0.6000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6852 - acc: 0.6389 - val_loss: 0.7045 - val_acc: 0.5857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6899 - acc: 0.6278 - val_loss: 0.7036 - val_acc: 0.6000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6725 - acc: 0.6556 - val_loss: 0.7006 - val_acc: 0.6000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6736 - acc: 0.6667 - val_loss: 0.7004 - val_acc: 0.6143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6760 - acc: 0.6500 - val_loss: 0.6982 - val_acc: 0.6143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6731 - acc: 0.6500 - val_loss: 0.6990 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6778 - acc: 0.6167 - val_loss: 0.6979 - val_acc: 0.6000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6862 - acc: 0.6333 - val_loss: 0.7027 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6613 - acc: 0.6722 - val_loss: 0.6961 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6599 - acc: 0.6833 - val_loss: 0.6904 - val_acc: 0.6000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6585 - acc: 0.6667 - val_loss: 0.6956 - val_acc: 0.6000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6607 - acc: 0.6333 - val_loss: 0.6929 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6695 - acc: 0.6444 - val_loss: 0.6925 - val_acc: 0.5857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6346 - acc: 0.6833 - val_loss: 0.6899 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6353 - acc: 0.7000 - val_loss: 0.6938 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6427 - acc: 0.6722 - val_loss: 0.6819 - val_acc: 0.6000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6445 - acc: 0.6833 - val_loss: 0.6818 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6360 - acc: 0.7111 - val_loss: 0.6841 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6320 - acc: 0.7056 - val_loss: 0.6863 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6320 - acc: 0.7167 - val_loss: 0.6847 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6147 - acc: 0.7056 - val_loss: 0.6853 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6109 - acc: 0.7222 - val_loss: 0.6775 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6302 - acc: 0.7056 - val_loss: 0.6786 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6129 - acc: 0.7000 - val_loss: 0.6917 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6290 - acc: 0.6833 - val_loss: 0.6802 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6157 - acc: 0.7222 - val_loss: 0.6780 - val_acc: 0.6000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6127 - acc: 0.7278 - val_loss: 0.6831 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6127 - acc: 0.7056 - val_loss: 0.6841 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6034 - acc: 0.7333 - val_loss: 0.6774 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6215 - acc: 0.6722 - val_loss: 0.6719 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6190 - acc: 0.7000 - val_loss: 0.6861 - val_acc: 0.5857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6002 - acc: 0.6889 - val_loss: 0.6711 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5872 - acc: 0.7389 - val_loss: 0.6684 - val_acc: 0.6429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6048 - acc: 0.7111 - val_loss: 0.6692 - val_acc: 0.6429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5816 - acc: 0.7944 - val_loss: 0.6746 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5755 - acc: 0.7278 - val_loss: 0.6697 - val_acc: 0.6429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5852 - acc: 0.7444 - val_loss: 0.6769 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5865 - acc: 0.7611 - val_loss: 0.6740 - val_acc: 0.6429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5685 - acc: 0.7278 - val_loss: 0.6707 - val_acc: 0.6429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5756 - acc: 0.7556 - val_loss: 0.6704 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5695 - acc: 0.7722 - val_loss: 0.6839 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5733 - acc: 0.7444 - val_loss: 0.6775 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5568 - acc: 0.7722 - val_loss: 0.6866 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.5955 - acc: 0.710 - 0s 83us/step - loss: 0.5881 - acc: 0.7333 - val_loss: 0.6796 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5653 - acc: 0.7611 - val_loss: 0.6766 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5666 - acc: 0.7722 - val_loss: 0.6760 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5642 - acc: 0.7667 - val_loss: 0.6798 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5434 - acc: 0.7889 - val_loss: 0.6730 - val_acc: 0.6429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5506 - acc: 0.7611 - val_loss: 0.6742 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5576 - acc: 0.7444 - val_loss: 0.6893 - val_acc: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5373 - acc: 0.7722 - val_loss: 0.6841 - val_acc: 0.6286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5383 - acc: 0.7611 - val_loss: 0.6728 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5383 - acc: 0.7611 - val_loss: 0.6720 - val_acc: 0.6429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5293 - acc: 0.8000 - val_loss: 0.6789 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5316 - acc: 0.7556 - val_loss: 0.6825 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5276 - acc: 0.8167 - val_loss: 0.6837 - val_acc: 0.6286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5237 - acc: 0.8000 - val_loss: 0.6798 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5415 - acc: 0.7556 - val_loss: 0.6822 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5195 - acc: 0.8000 - val_loss: 0.6882 - val_acc: 0.6286\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5277 - acc: 0.8111 - val_loss: 0.6801 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5163 - acc: 0.7778 - val_loss: 0.6861 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5370 - acc: 0.7778 - val_loss: 0.6758 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5507 - acc: 0.7722 - val_loss: 0.6843 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5196 - acc: 0.8000 - val_loss: 0.6854 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5261 - acc: 0.7889 - val_loss: 0.6828 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5415 - acc: 0.7611 - val_loss: 0.6936 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5094 - acc: 0.8278 - val_loss: 0.6990 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5143 - acc: 0.7833 - val_loss: 0.6839 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.8561 - acc: 0.4611 - val_loss: 0.7795 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7992 - acc: 0.4278 - val_loss: 0.7570 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7631 - acc: 0.5056 - val_loss: 0.7502 - val_acc: 0.5571\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.7610 - acc: 0.4667 - val_loss: 0.7426 - val_acc: 0.5857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 255us/step - loss: 0.7577 - acc: 0.5056 - val_loss: 0.7395 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7303 - acc: 0.5722 - val_loss: 0.7375 - val_acc: 0.5429\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 152us/step - loss: 0.7286 - acc: 0.5722 - val_loss: 0.7358 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7424 - acc: 0.5389 - val_loss: 0.7341 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7166 - acc: 0.5889 - val_loss: 0.7313 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7198 - acc: 0.6000 - val_loss: 0.7294 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7214 - acc: 0.5944 - val_loss: 0.7289 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7107 - acc: 0.6056 - val_loss: 0.7269 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7182 - acc: 0.6167 - val_loss: 0.7257 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.7145 - acc: 0.5889 - val_loss: 0.7259 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.7080 - acc: 0.6056 - val_loss: 0.7247 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7206 - acc: 0.5667 - val_loss: 0.7228 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.7124 - acc: 0.5778 - val_loss: 0.7211 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 205us/step - loss: 0.7149 - acc: 0.5722 - val_loss: 0.7201 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7012 - acc: 0.5778 - val_loss: 0.7184 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6939 - acc: 0.6222 - val_loss: 0.7178 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.6868 - acc: 0.6167 - val_loss: 0.7165 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6889 - acc: 0.6167 - val_loss: 0.7138 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6984 - acc: 0.6444 - val_loss: 0.7128 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6831 - acc: 0.6556 - val_loss: 0.7128 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6876 - acc: 0.6222 - val_loss: 0.7115 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6860 - acc: 0.6222 - val_loss: 0.7120 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6958 - acc: 0.6111 - val_loss: 0.7127 - val_acc: 0.5286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6901 - acc: 0.6278 - val_loss: 0.7108 - val_acc: 0.5286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6784 - acc: 0.6333 - val_loss: 0.7073 - val_acc: 0.5429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6682 - acc: 0.6333 - val_loss: 0.7060 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6708 - acc: 0.6667 - val_loss: 0.7057 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6691 - acc: 0.6278 - val_loss: 0.7021 - val_acc: 0.6143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6722 - acc: 0.6889 - val_loss: 0.7005 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6689 - acc: 0.6556 - val_loss: 0.6977 - val_acc: 0.6286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6708 - acc: 0.6500 - val_loss: 0.6990 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6620 - acc: 0.6611 - val_loss: 0.6959 - val_acc: 0.6429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6553 - acc: 0.7278 - val_loss: 0.6963 - val_acc: 0.6429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6620 - acc: 0.6944 - val_loss: 0.6958 - val_acc: 0.6000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6527 - acc: 0.6833 - val_loss: 0.6950 - val_acc: 0.6286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6556 - acc: 0.6722 - val_loss: 0.6955 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6577 - acc: 0.6722 - val_loss: 0.6943 - val_acc: 0.6429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6544 - acc: 0.6444 - val_loss: 0.6930 - val_acc: 0.6286\n",
      "Epoch 43/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6592 - acc: 0.6556 - val_loss: 0.6939 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6436 - acc: 0.6500 - val_loss: 0.6895 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6346 - acc: 0.7000 - val_loss: 0.6901 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6409 - acc: 0.6667 - val_loss: 0.6869 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6323 - acc: 0.7000 - val_loss: 0.6849 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 205us/step - loss: 0.6205 - acc: 0.7389 - val_loss: 0.6834 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6247 - acc: 0.7167 - val_loss: 0.6809 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6176 - acc: 0.7556 - val_loss: 0.6812 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6343 - acc: 0.7056 - val_loss: 0.6813 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6188 - acc: 0.7389 - val_loss: 0.6792 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6176 - acc: 0.7000 - val_loss: 0.6813 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6162 - acc: 0.7278 - val_loss: 0.6765 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6082 - acc: 0.7278 - val_loss: 0.6749 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6205 - acc: 0.7056 - val_loss: 0.6742 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6018 - acc: 0.7833 - val_loss: 0.6759 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6034 - acc: 0.7722 - val_loss: 0.6782 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5964 - acc: 0.7556 - val_loss: 0.6789 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5861 - acc: 0.7222 - val_loss: 0.6751 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5936 - acc: 0.7111 - val_loss: 0.6695 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5998 - acc: 0.7222 - val_loss: 0.6707 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5851 - acc: 0.7389 - val_loss: 0.6661 - val_acc: 0.6571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5929 - acc: 0.7333 - val_loss: 0.6688 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5766 - acc: 0.7500 - val_loss: 0.6704 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5941 - acc: 0.7111 - val_loss: 0.6647 - val_acc: 0.6429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5620 - acc: 0.7778 - val_loss: 0.6626 - val_acc: 0.6571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5570 - acc: 0.8056 - val_loss: 0.6640 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5841 - acc: 0.7389 - val_loss: 0.6647 - val_acc: 0.6429\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5590 - acc: 0.7611 - val_loss: 0.6649 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5618 - acc: 0.7833 - val_loss: 0.6600 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5632 - acc: 0.7556 - val_loss: 0.6586 - val_acc: 0.6714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5810 - acc: 0.7889 - val_loss: 0.6635 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5647 - acc: 0.7778 - val_loss: 0.6622 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5658 - acc: 0.7722 - val_loss: 0.6587 - val_acc: 0.7000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5619 - acc: 0.7556 - val_loss: 0.6620 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5635 - acc: 0.7611 - val_loss: 0.6601 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5490 - acc: 0.7889 - val_loss: 0.6583 - val_acc: 0.7000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5639 - acc: 0.7778 - val_loss: 0.6611 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5520 - acc: 0.7500 - val_loss: 0.6574 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7839 - acc: 0.5000 - val_loss: 0.7599 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.7562 - acc: 0.4889 - val_loss: 0.7581 - val_acc: 0.4571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7445 - acc: 0.5278 - val_loss: 0.7521 - val_acc: 0.4714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7435 - acc: 0.5333 - val_loss: 0.7474 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7369 - acc: 0.5222 - val_loss: 0.7445 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7271 - acc: 0.5556 - val_loss: 0.7421 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7184 - acc: 0.5556 - val_loss: 0.7395 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7332 - acc: 0.5333 - val_loss: 0.7380 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7306 - acc: 0.5444 - val_loss: 0.7350 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7184 - acc: 0.5611 - val_loss: 0.7299 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7121 - acc: 0.5444 - val_loss: 0.7285 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7123 - acc: 0.5722 - val_loss: 0.7288 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7131 - acc: 0.5667 - val_loss: 0.7276 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7133 - acc: 0.5778 - val_loss: 0.7293 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6934 - acc: 0.5889 - val_loss: 0.7242 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7013 - acc: 0.5778 - val_loss: 0.7200 - val_acc: 0.5571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6984 - acc: 0.5833 - val_loss: 0.7194 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7006 - acc: 0.5944 - val_loss: 0.7180 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6918 - acc: 0.5944 - val_loss: 0.7168 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6900 - acc: 0.6056 - val_loss: 0.7127 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6992 - acc: 0.6000 - val_loss: 0.7103 - val_acc: 0.5714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 92us/step - loss: 0.6927 - acc: 0.6222 - val_loss: 0.7085 - val_acc: 0.5571\n",
      "Epoch 23/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6751 - acc: 0.6167 - val_loss: 0.7068 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6860 - acc: 0.6278 - val_loss: 0.7080 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6732 - acc: 0.6167 - val_loss: 0.7031 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6765 - acc: 0.6444 - val_loss: 0.6980 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6765 - acc: 0.6111 - val_loss: 0.6989 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6864 - acc: 0.6333 - val_loss: 0.6988 - val_acc: 0.6429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6744 - acc: 0.6667 - val_loss: 0.6989 - val_acc: 0.6143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6666 - acc: 0.6333 - val_loss: 0.6994 - val_acc: 0.6286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6637 - acc: 0.6667 - val_loss: 0.6991 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6684 - acc: 0.6611 - val_loss: 0.6976 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6553 - acc: 0.6556 - val_loss: 0.6965 - val_acc: 0.5857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6616 - acc: 0.6611 - val_loss: 0.6955 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6517 - acc: 0.6944 - val_loss: 0.6956 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6460 - acc: 0.7000 - val_loss: 0.6943 - val_acc: 0.6286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6504 - acc: 0.7000 - val_loss: 0.6969 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6459 - acc: 0.6944 - val_loss: 0.6973 - val_acc: 0.5857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6470 - acc: 0.6667 - val_loss: 0.6914 - val_acc: 0.6429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6428 - acc: 0.7167 - val_loss: 0.6943 - val_acc: 0.6000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.6331 - acc: 0.7167 - val_loss: 0.6962 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6321 - acc: 0.6556 - val_loss: 0.6914 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6352 - acc: 0.6833 - val_loss: 0.6898 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6422 - acc: 0.6611 - val_loss: 0.6927 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6413 - acc: 0.7000 - val_loss: 0.6923 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6296 - acc: 0.7111 - val_loss: 0.6897 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6115 - acc: 0.7000 - val_loss: 0.6873 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6260 - acc: 0.7056 - val_loss: 0.6898 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6149 - acc: 0.7500 - val_loss: 0.6890 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6133 - acc: 0.7333 - val_loss: 0.6870 - val_acc: 0.6571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6261 - acc: 0.7611 - val_loss: 0.6857 - val_acc: 0.6857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6128 - acc: 0.7556 - val_loss: 0.6864 - val_acc: 0.6714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6110 - acc: 0.7611 - val_loss: 0.6865 - val_acc: 0.6857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6009 - acc: 0.7556 - val_loss: 0.6851 - val_acc: 0.6857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 327us/step - loss: 0.5944 - acc: 0.7611 - val_loss: 0.6857 - val_acc: 0.6714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5996 - acc: 0.7444 - val_loss: 0.6835 - val_acc: 0.6857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6008 - acc: 0.7389 - val_loss: 0.6844 - val_acc: 0.6857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5929 - acc: 0.7444 - val_loss: 0.6859 - val_acc: 0.6714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5990 - acc: 0.7556 - val_loss: 0.6941 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5873 - acc: 0.7556 - val_loss: 0.6898 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5807 - acc: 0.7611 - val_loss: 0.6861 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5957 - acc: 0.7444 - val_loss: 0.6844 - val_acc: 0.6857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5724 - acc: 0.8000 - val_loss: 0.6850 - val_acc: 0.6571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5847 - acc: 0.7389 - val_loss: 0.6907 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5962 - acc: 0.7222 - val_loss: 0.6907 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5757 - acc: 0.7833 - val_loss: 0.6946 - val_acc: 0.6429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5743 - acc: 0.7611 - val_loss: 0.6834 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5660 - acc: 0.7778 - val_loss: 0.6880 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5656 - acc: 0.7611 - val_loss: 0.6827 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5745 - acc: 0.7778 - val_loss: 0.6835 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5568 - acc: 0.7944 - val_loss: 0.6821 - val_acc: 0.6714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5572 - acc: 0.8000 - val_loss: 0.6813 - val_acc: 0.6714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5547 - acc: 0.7722 - val_loss: 0.6809 - val_acc: 0.6714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5743 - acc: 0.7778 - val_loss: 0.6792 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5574 - acc: 0.7778 - val_loss: 0.6824 - val_acc: 0.6571\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5377 - acc: 0.7944 - val_loss: 0.6859 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5325 - acc: 0.8000 - val_loss: 0.6922 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5456 - acc: 0.7889 - val_loss: 0.6916 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5618 - acc: 0.7778 - val_loss: 0.6950 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5310 - acc: 0.8000 - val_loss: 0.6835 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 112us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7654 - acc: 0.4333 - val_loss: 0.7819 - val_acc: 0.3714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7477 - acc: 0.4944 - val_loss: 0.7789 - val_acc: 0.4429\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 78us/step - loss: 0.7451 - acc: 0.5056 - val_loss: 0.7788 - val_acc: 0.4571\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7349 - acc: 0.5611 - val_loss: 0.7777 - val_acc: 0.4714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7346 - acc: 0.5556 - val_loss: 0.7727 - val_acc: 0.4857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7372 - acc: 0.5167 - val_loss: 0.7722 - val_acc: 0.4714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7219 - acc: 0.5778 - val_loss: 0.7707 - val_acc: 0.4714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7229 - acc: 0.5389 - val_loss: 0.7659 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7212 - acc: 0.5833 - val_loss: 0.7646 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7120 - acc: 0.5556 - val_loss: 0.7639 - val_acc: 0.4714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7165 - acc: 0.5722 - val_loss: 0.7643 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7092 - acc: 0.5944 - val_loss: 0.7581 - val_acc: 0.4857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7149 - acc: 0.5722 - val_loss: 0.7545 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7063 - acc: 0.5667 - val_loss: 0.7574 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6975 - acc: 0.5944 - val_loss: 0.7551 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 80us/step - loss: 0.7010 - acc: 0.5833 - val_loss: 0.7533 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7017 - acc: 0.6333 - val_loss: 0.7516 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6883 - acc: 0.6389 - val_loss: 0.7484 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6879 - acc: 0.6778 - val_loss: 0.7441 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6823 - acc: 0.6556 - val_loss: 0.7472 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6838 - acc: 0.6333 - val_loss: 0.7419 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6838 - acc: 0.6556 - val_loss: 0.7402 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6799 - acc: 0.6833 - val_loss: 0.7380 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6734 - acc: 0.6778 - val_loss: 0.7405 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6885 - acc: 0.6389 - val_loss: 0.7385 - val_acc: 0.5000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6755 - acc: 0.6611 - val_loss: 0.7385 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6716 - acc: 0.6722 - val_loss: 0.7420 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6809 - acc: 0.6333 - val_loss: 0.7363 - val_acc: 0.5429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6670 - acc: 0.6833 - val_loss: 0.7375 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6680 - acc: 0.6556 - val_loss: 0.7298 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6844 - acc: 0.6500 - val_loss: 0.7307 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6575 - acc: 0.7000 - val_loss: 0.7298 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6533 - acc: 0.6944 - val_loss: 0.7367 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6668 - acc: 0.6333 - val_loss: 0.7347 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6492 - acc: 0.6556 - val_loss: 0.7380 - val_acc: 0.5143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6449 - acc: 0.7167 - val_loss: 0.7321 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6434 - acc: 0.6889 - val_loss: 0.7290 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6348 - acc: 0.6833 - val_loss: 0.7349 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6323 - acc: 0.7111 - val_loss: 0.7288 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 91us/step - loss: 0.6247 - acc: 0.7500 - val_loss: 0.7352 - val_acc: 0.5286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6299 - acc: 0.7111 - val_loss: 0.7304 - val_acc: 0.5571\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6209 - acc: 0.7500 - val_loss: 0.7299 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6184 - acc: 0.7278 - val_loss: 0.7286 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6374 - acc: 0.7111 - val_loss: 0.7261 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6324 - acc: 0.7111 - val_loss: 0.7264 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6178 - acc: 0.7500 - val_loss: 0.7337 - val_acc: 0.5429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6192 - acc: 0.7333 - val_loss: 0.7333 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6092 - acc: 0.7278 - val_loss: 0.7299 - val_acc: 0.5857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6148 - acc: 0.7611 - val_loss: 0.7259 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6020 - acc: 0.7611 - val_loss: 0.7310 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5946 - acc: 0.8000 - val_loss: 0.7233 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6020 - acc: 0.7611 - val_loss: 0.7277 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6116 - acc: 0.7389 - val_loss: 0.7292 - val_acc: 0.5714\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6045 - acc: 0.7389 - val_loss: 0.7227 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5972 - acc: 0.7722 - val_loss: 0.7190 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6101 - acc: 0.7556 - val_loss: 0.7147 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5940 - acc: 0.7667 - val_loss: 0.7222 - val_acc: 0.5857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5775 - acc: 0.7778 - val_loss: 0.7221 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5877 - acc: 0.7500 - val_loss: 0.7169 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5622 - acc: 0.8000 - val_loss: 0.7261 - val_acc: 0.5714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5839 - acc: 0.7500 - val_loss: 0.7223 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5674 - acc: 0.7833 - val_loss: 0.7237 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5587 - acc: 0.7667 - val_loss: 0.7186 - val_acc: 0.6429\n",
      "Epoch 64/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.5692 - acc: 0.7722 - val_loss: 0.7227 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5431 - acc: 0.8056 - val_loss: 0.7197 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5746 - acc: 0.7667 - val_loss: 0.7228 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5575 - acc: 0.8056 - val_loss: 0.7184 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5696 - acc: 0.7556 - val_loss: 0.7191 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5508 - acc: 0.7667 - val_loss: 0.7207 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5499 - acc: 0.8056 - val_loss: 0.7319 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5674 - acc: 0.7722 - val_loss: 0.7185 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5542 - acc: 0.7722 - val_loss: 0.7235 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5580 - acc: 0.7722 - val_loss: 0.7170 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5304 - acc: 0.8111 - val_loss: 0.7158 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5261 - acc: 0.8111 - val_loss: 0.7173 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5188 - acc: 0.7889 - val_loss: 0.7211 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5317 - acc: 0.8000 - val_loss: 0.7218 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5195 - acc: 0.8278 - val_loss: 0.7319 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5210 - acc: 0.7778 - val_loss: 0.7379 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5207 - acc: 0.8000 - val_loss: 0.7288 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.9326 - acc: 0.4556 - val_loss: 0.7972 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.8349 - acc: 0.4944 - val_loss: 0.7708 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.8113 - acc: 0.4889 - val_loss: 0.7560 - val_acc: 0.4857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7822 - acc: 0.4889 - val_loss: 0.7507 - val_acc: 0.4714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7520 - acc: 0.5889 - val_loss: 0.7451 - val_acc: 0.5286\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7529 - acc: 0.5222 - val_loss: 0.7451 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7269 - acc: 0.5444 - val_loss: 0.7455 - val_acc: 0.5714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7362 - acc: 0.5333 - val_loss: 0.7489 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7166 - acc: 0.5722 - val_loss: 0.7497 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7156 - acc: 0.5611 - val_loss: 0.7513 - val_acc: 0.4857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.7273 - acc: 0.5278 - val_loss: 0.7523 - val_acc: 0.4857\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7194 - acc: 0.5611 - val_loss: 0.7526 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7018 - acc: 0.5778 - val_loss: 0.7545 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7183 - acc: 0.5833 - val_loss: 0.7554 - val_acc: 0.4857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7129 - acc: 0.6000 - val_loss: 0.7554 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7048 - acc: 0.5944 - val_loss: 0.7539 - val_acc: 0.4714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6952 - acc: 0.6167 - val_loss: 0.7526 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6925 - acc: 0.6000 - val_loss: 0.7511 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7061 - acc: 0.5444 - val_loss: 0.7585 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6995 - acc: 0.6056 - val_loss: 0.7586 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6855 - acc: 0.5667 - val_loss: 0.7573 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 85us/step - loss: 0.6841 - acc: 0.6444 - val_loss: 0.7558 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6903 - acc: 0.6333 - val_loss: 0.7516 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6717 - acc: 0.6444 - val_loss: 0.7515 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6915 - acc: 0.6111 - val_loss: 0.7429 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6822 - acc: 0.6667 - val_loss: 0.7468 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6846 - acc: 0.6222 - val_loss: 0.7491 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 79us/step - loss: 0.6717 - acc: 0.6778 - val_loss: 0.7532 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6762 - acc: 0.6667 - val_loss: 0.7527 - val_acc: 0.5429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6549 - acc: 0.6833 - val_loss: 0.7498 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6617 - acc: 0.6611 - val_loss: 0.7507 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6653 - acc: 0.6611 - val_loss: 0.7510 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6681 - acc: 0.6389 - val_loss: 0.7532 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6542 - acc: 0.6667 - val_loss: 0.7479 - val_acc: 0.5143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6533 - acc: 0.6556 - val_loss: 0.7467 - val_acc: 0.5143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6484 - acc: 0.7056 - val_loss: 0.7558 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6529 - acc: 0.6889 - val_loss: 0.7559 - val_acc: 0.5571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6556 - acc: 0.6833 - val_loss: 0.7539 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6507 - acc: 0.6889 - val_loss: 0.7528 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 75us/step - loss: 0.6258 - acc: 0.6944 - val_loss: 0.7519 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6458 - acc: 0.6556 - val_loss: 0.7483 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6363 - acc: 0.7056 - val_loss: 0.7527 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6316 - acc: 0.7222 - val_loss: 0.7530 - val_acc: 0.5429\n",
      "Epoch 44/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6419 - acc: 0.7056 - val_loss: 0.7602 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6283 - acc: 0.7111 - val_loss: 0.7568 - val_acc: 0.5571\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6342 - acc: 0.7056 - val_loss: 0.7489 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6398 - acc: 0.6611 - val_loss: 0.7564 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6229 - acc: 0.7222 - val_loss: 0.7493 - val_acc: 0.5714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6105 - acc: 0.7000 - val_loss: 0.7645 - val_acc: 0.5429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5961 - acc: 0.7389 - val_loss: 0.7617 - val_acc: 0.5429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6033 - acc: 0.7500 - val_loss: 0.7530 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6101 - acc: 0.7278 - val_loss: 0.7473 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6209 - acc: 0.6667 - val_loss: 0.7575 - val_acc: 0.5571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5879 - acc: 0.7278 - val_loss: 0.7650 - val_acc: 0.5286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6147 - acc: 0.7111 - val_loss: 0.7639 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6119 - acc: 0.7167 - val_loss: 0.7589 - val_acc: 0.5857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6065 - acc: 0.7278 - val_loss: 0.7507 - val_acc: 0.5571\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5901 - acc: 0.7333 - val_loss: 0.7514 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5862 - acc: 0.7333 - val_loss: 0.7567 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5938 - acc: 0.7333 - val_loss: 0.7584 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5893 - acc: 0.7278 - val_loss: 0.7581 - val_acc: 0.5857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5839 - acc: 0.7222 - val_loss: 0.7517 - val_acc: 0.5714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.5868 - acc: 0.7278 - val_loss: 0.7481 - val_acc: 0.5714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5926 - acc: 0.7222 - val_loss: 0.7580 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5733 - acc: 0.7722 - val_loss: 0.7498 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5795 - acc: 0.7389 - val_loss: 0.7485 - val_acc: 0.5286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5800 - acc: 0.7222 - val_loss: 0.7562 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5729 - acc: 0.7500 - val_loss: 0.7661 - val_acc: 0.5571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 80us/step - loss: 0.5515 - acc: 0.7889 - val_loss: 0.7740 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5669 - acc: 0.7556 - val_loss: 0.7841 - val_acc: 0.5429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5630 - acc: 0.7833 - val_loss: 0.7700 - val_acc: 0.5714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5780 - acc: 0.7111 - val_loss: 0.7621 - val_acc: 0.5714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5644 - acc: 0.7389 - val_loss: 0.7707 - val_acc: 0.5714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5607 - acc: 0.7667 - val_loss: 0.7695 - val_acc: 0.5714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5759 - acc: 0.7278 - val_loss: 0.7694 - val_acc: 0.5571\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5393 - acc: 0.8111 - val_loss: 0.7651 - val_acc: 0.5429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5510 - acc: 0.7389 - val_loss: 0.7679 - val_acc: 0.5714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5545 - acc: 0.7278 - val_loss: 0.7659 - val_acc: 0.5571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5510 - acc: 0.7722 - val_loss: 0.7649 - val_acc: 0.5571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5330 - acc: 0.8000 - val_loss: 0.7645 - val_acc: 0.5286\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7380 - acc: 0.5500 - val_loss: 0.7419 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7267 - acc: 0.5611 - val_loss: 0.7386 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7274 - acc: 0.5667 - val_loss: 0.7374 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7212 - acc: 0.5611 - val_loss: 0.7383 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7101 - acc: 0.5889 - val_loss: 0.7370 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7143 - acc: 0.5889 - val_loss: 0.7402 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7213 - acc: 0.5889 - val_loss: 0.7372 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7223 - acc: 0.5556 - val_loss: 0.7333 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7062 - acc: 0.6056 - val_loss: 0.7322 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7172 - acc: 0.5667 - val_loss: 0.7322 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7038 - acc: 0.6111 - val_loss: 0.7310 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7049 - acc: 0.6222 - val_loss: 0.7307 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7055 - acc: 0.6111 - val_loss: 0.7313 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7031 - acc: 0.5889 - val_loss: 0.7286 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6933 - acc: 0.6333 - val_loss: 0.7308 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6874 - acc: 0.6389 - val_loss: 0.7284 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6943 - acc: 0.6167 - val_loss: 0.7250 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6897 - acc: 0.6611 - val_loss: 0.7254 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6806 - acc: 0.6444 - val_loss: 0.7240 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6796 - acc: 0.6667 - val_loss: 0.7222 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6785 - acc: 0.6722 - val_loss: 0.7256 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6806 - acc: 0.6444 - val_loss: 0.7254 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6762 - acc: 0.6278 - val_loss: 0.7218 - val_acc: 0.5143\n",
      "Epoch 24/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6807 - acc: 0.6444 - val_loss: 0.7208 - val_acc: 0.5143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6746 - acc: 0.6333 - val_loss: 0.7206 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6652 - acc: 0.6833 - val_loss: 0.7166 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6771 - acc: 0.6667 - val_loss: 0.7161 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6584 - acc: 0.6944 - val_loss: 0.7167 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6593 - acc: 0.6944 - val_loss: 0.7168 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6536 - acc: 0.7389 - val_loss: 0.7178 - val_acc: 0.5000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6508 - acc: 0.6667 - val_loss: 0.7134 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6459 - acc: 0.7278 - val_loss: 0.7124 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6439 - acc: 0.7278 - val_loss: 0.7171 - val_acc: 0.5000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6478 - acc: 0.6889 - val_loss: 0.7173 - val_acc: 0.5000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6418 - acc: 0.7167 - val_loss: 0.7164 - val_acc: 0.5143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6562 - acc: 0.7111 - val_loss: 0.7104 - val_acc: 0.5429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6447 - acc: 0.7333 - val_loss: 0.7099 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6335 - acc: 0.7667 - val_loss: 0.7096 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6255 - acc: 0.7778 - val_loss: 0.7101 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6365 - acc: 0.7111 - val_loss: 0.7047 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6398 - acc: 0.7333 - val_loss: 0.7076 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6299 - acc: 0.7500 - val_loss: 0.7033 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6320 - acc: 0.7333 - val_loss: 0.7040 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6285 - acc: 0.7222 - val_loss: 0.7069 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6188 - acc: 0.7667 - val_loss: 0.7044 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6134 - acc: 0.7444 - val_loss: 0.6982 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6179 - acc: 0.7444 - val_loss: 0.6982 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6163 - acc: 0.7833 - val_loss: 0.7035 - val_acc: 0.5714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6127 - acc: 0.7556 - val_loss: 0.7034 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5926 - acc: 0.7833 - val_loss: 0.7031 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6083 - acc: 0.7500 - val_loss: 0.6956 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6140 - acc: 0.7444 - val_loss: 0.6945 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6009 - acc: 0.7889 - val_loss: 0.6923 - val_acc: 0.5857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5937 - acc: 0.7778 - val_loss: 0.6945 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5918 - acc: 0.7667 - val_loss: 0.6931 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5927 - acc: 0.7722 - val_loss: 0.6985 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5822 - acc: 0.7667 - val_loss: 0.6979 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5868 - acc: 0.7444 - val_loss: 0.6995 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5760 - acc: 0.8056 - val_loss: 0.6931 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5691 - acc: 0.7722 - val_loss: 0.6965 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5714 - acc: 0.7833 - val_loss: 0.6928 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5584 - acc: 0.8000 - val_loss: 0.6969 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5620 - acc: 0.7944 - val_loss: 0.6947 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5747 - acc: 0.7722 - val_loss: 0.6938 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5704 - acc: 0.8111 - val_loss: 0.6930 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5607 - acc: 0.7944 - val_loss: 0.6964 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5698 - acc: 0.7389 - val_loss: 0.7005 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5567 - acc: 0.7778 - val_loss: 0.6929 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5525 - acc: 0.8278 - val_loss: 0.7012 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5502 - acc: 0.7833 - val_loss: 0.7134 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5443 - acc: 0.8056 - val_loss: 0.7012 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5344 - acc: 0.7722 - val_loss: 0.6964 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5424 - acc: 0.7833 - val_loss: 0.6969 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5413 - acc: 0.8167 - val_loss: 0.7003 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5431 - acc: 0.8056 - val_loss: 0.7006 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5239 - acc: 0.8000 - val_loss: 0.6950 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5494 - acc: 0.8056 - val_loss: 0.7009 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5251 - acc: 0.8111 - val_loss: 0.7001 - val_acc: 0.6429\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5312 - acc: 0.8111 - val_loss: 0.6964 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5170 - acc: 0.7556 - val_loss: 0.6956 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.8599 - acc: 0.4667 - val_loss: 0.7784 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.8099 - acc: 0.4889 - val_loss: 0.7649 - val_acc: 0.4429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7949 - acc: 0.4556 - val_loss: 0.7574 - val_acc: 0.4286\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.7905 - acc: 0.4722 - val_loss: 0.7544 - val_acc: 0.4429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7771 - acc: 0.4222 - val_loss: 0.7515 - val_acc: 0.4143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7607 - acc: 0.4944 - val_loss: 0.7494 - val_acc: 0.4000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7428 - acc: 0.5278 - val_loss: 0.7489 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7477 - acc: 0.5111 - val_loss: 0.7494 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7426 - acc: 0.5389 - val_loss: 0.7486 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7287 - acc: 0.5611 - val_loss: 0.7472 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7349 - acc: 0.5556 - val_loss: 0.7478 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7230 - acc: 0.5167 - val_loss: 0.7471 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7338 - acc: 0.5444 - val_loss: 0.7481 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7153 - acc: 0.5556 - val_loss: 0.7486 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7409 - acc: 0.5000 - val_loss: 0.7459 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7195 - acc: 0.5278 - val_loss: 0.7475 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7124 - acc: 0.5500 - val_loss: 0.7489 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 80us/step - loss: 0.7232 - acc: 0.5500 - val_loss: 0.7448 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7189 - acc: 0.5222 - val_loss: 0.7445 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7062 - acc: 0.6000 - val_loss: 0.7452 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7173 - acc: 0.5333 - val_loss: 0.7412 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7067 - acc: 0.6111 - val_loss: 0.7427 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7048 - acc: 0.5500 - val_loss: 0.7414 - val_acc: 0.5429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7198 - acc: 0.5222 - val_loss: 0.7403 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6937 - acc: 0.6111 - val_loss: 0.7379 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7050 - acc: 0.5944 - val_loss: 0.7366 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6921 - acc: 0.6278 - val_loss: 0.7361 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6991 - acc: 0.5722 - val_loss: 0.7367 - val_acc: 0.5429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6989 - acc: 0.5722 - val_loss: 0.7365 - val_acc: 0.5429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6912 - acc: 0.6000 - val_loss: 0.7365 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6925 - acc: 0.6278 - val_loss: 0.7360 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7032 - acc: 0.5667 - val_loss: 0.7319 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6724 - acc: 0.6889 - val_loss: 0.7314 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6738 - acc: 0.6778 - val_loss: 0.7293 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6856 - acc: 0.6333 - val_loss: 0.7297 - val_acc: 0.5429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6790 - acc: 0.6278 - val_loss: 0.7315 - val_acc: 0.5429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6771 - acc: 0.6389 - val_loss: 0.7316 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6771 - acc: 0.6556 - val_loss: 0.7316 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6737 - acc: 0.6333 - val_loss: 0.7341 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6652 - acc: 0.6389 - val_loss: 0.7322 - val_acc: 0.5429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6611 - acc: 0.6389 - val_loss: 0.7296 - val_acc: 0.5429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6615 - acc: 0.6556 - val_loss: 0.7272 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6588 - acc: 0.6722 - val_loss: 0.7276 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6518 - acc: 0.6833 - val_loss: 0.7272 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6495 - acc: 0.6667 - val_loss: 0.7267 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6466 - acc: 0.6611 - val_loss: 0.7274 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6428 - acc: 0.7167 - val_loss: 0.7267 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6461 - acc: 0.7111 - val_loss: 0.7253 - val_acc: 0.5714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6472 - acc: 0.6889 - val_loss: 0.7224 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6455 - acc: 0.6889 - val_loss: 0.7206 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6419 - acc: 0.6722 - val_loss: 0.7192 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6372 - acc: 0.7056 - val_loss: 0.7223 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6413 - acc: 0.6611 - val_loss: 0.7218 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6150 - acc: 0.7278 - val_loss: 0.7214 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6242 - acc: 0.7111 - val_loss: 0.7230 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6230 - acc: 0.6944 - val_loss: 0.7200 - val_acc: 0.5857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6281 - acc: 0.6944 - val_loss: 0.7227 - val_acc: 0.5857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6174 - acc: 0.7222 - val_loss: 0.7223 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6104 - acc: 0.7333 - val_loss: 0.7257 - val_acc: 0.6000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6035 - acc: 0.7444 - val_loss: 0.7253 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6018 - acc: 0.7611 - val_loss: 0.7234 - val_acc: 0.5857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5993 - acc: 0.7667 - val_loss: 0.7241 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5875 - acc: 0.7500 - val_loss: 0.7226 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6050 - acc: 0.7000 - val_loss: 0.7177 - val_acc: 0.5714\n",
      "Epoch 65/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.5984 - acc: 0.7222 - val_loss: 0.7179 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5879 - acc: 0.7500 - val_loss: 0.7169 - val_acc: 0.5857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6033 - acc: 0.6944 - val_loss: 0.7151 - val_acc: 0.5857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5911 - acc: 0.7278 - val_loss: 0.7172 - val_acc: 0.5857\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5822 - acc: 0.7667 - val_loss: 0.7206 - val_acc: 0.5857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5752 - acc: 0.7833 - val_loss: 0.7175 - val_acc: 0.5857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5855 - acc: 0.7611 - val_loss: 0.7245 - val_acc: 0.5857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5654 - acc: 0.7222 - val_loss: 0.7203 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5831 - acc: 0.7333 - val_loss: 0.7245 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5632 - acc: 0.7556 - val_loss: 0.7222 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5805 - acc: 0.7500 - val_loss: 0.7269 - val_acc: 0.5857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5409 - acc: 0.8000 - val_loss: 0.7260 - val_acc: 0.5857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5700 - acc: 0.7389 - val_loss: 0.7248 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5581 - acc: 0.7667 - val_loss: 0.7264 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 84us/step - loss: 0.5614 - acc: 0.7556 - val_loss: 0.7292 - val_acc: 0.5857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5603 - acc: 0.7556 - val_loss: 0.7266 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.8028 - acc: 0.4778 - val_loss: 0.7275 - val_acc: 0.5714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7618 - acc: 0.5000 - val_loss: 0.7253 - val_acc: 0.6286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7365 - acc: 0.5611 - val_loss: 0.7240 - val_acc: 0.6286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7439 - acc: 0.4889 - val_loss: 0.7238 - val_acc: 0.5714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7306 - acc: 0.5111 - val_loss: 0.7238 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 80us/step - loss: 0.7192 - acc: 0.5333 - val_loss: 0.7245 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7224 - acc: 0.5833 - val_loss: 0.7212 - val_acc: 0.5714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7189 - acc: 0.5500 - val_loss: 0.7198 - val_acc: 0.5714\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7161 - acc: 0.5722 - val_loss: 0.7171 - val_acc: 0.5857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7262 - acc: 0.5333 - val_loss: 0.7169 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7067 - acc: 0.5778 - val_loss: 0.7153 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7040 - acc: 0.6167 - val_loss: 0.7174 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7040 - acc: 0.5667 - val_loss: 0.7145 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7067 - acc: 0.5944 - val_loss: 0.7171 - val_acc: 0.5571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7066 - acc: 0.5833 - val_loss: 0.7137 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6904 - acc: 0.6278 - val_loss: 0.7128 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6869 - acc: 0.6000 - val_loss: 0.7144 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6943 - acc: 0.6000 - val_loss: 0.7096 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6933 - acc: 0.6167 - val_loss: 0.7093 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6820 - acc: 0.6778 - val_loss: 0.7075 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6826 - acc: 0.6611 - val_loss: 0.7118 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6827 - acc: 0.6278 - val_loss: 0.7112 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6826 - acc: 0.6500 - val_loss: 0.7107 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6721 - acc: 0.6556 - val_loss: 0.7063 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6724 - acc: 0.6722 - val_loss: 0.7105 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6520 - acc: 0.6444 - val_loss: 0.7107 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6664 - acc: 0.6222 - val_loss: 0.7075 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6475 - acc: 0.6722 - val_loss: 0.7021 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6655 - acc: 0.6556 - val_loss: 0.7005 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6621 - acc: 0.6722 - val_loss: 0.7018 - val_acc: 0.5429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6508 - acc: 0.6722 - val_loss: 0.7020 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6689 - acc: 0.6611 - val_loss: 0.6962 - val_acc: 0.6143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6597 - acc: 0.6611 - val_loss: 0.6996 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6683 - acc: 0.6833 - val_loss: 0.6966 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6531 - acc: 0.6778 - val_loss: 0.6930 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6485 - acc: 0.7222 - val_loss: 0.6893 - val_acc: 0.6429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6552 - acc: 0.7278 - val_loss: 0.6883 - val_acc: 0.6429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6503 - acc: 0.6722 - val_loss: 0.6899 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6500 - acc: 0.6833 - val_loss: 0.6946 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6384 - acc: 0.7167 - val_loss: 0.6983 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6572 - acc: 0.6667 - val_loss: 0.6902 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6369 - acc: 0.7000 - val_loss: 0.6915 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6402 - acc: 0.6778 - val_loss: 0.6940 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6433 - acc: 0.6889 - val_loss: 0.6929 - val_acc: 0.6143\n",
      "Epoch 45/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6337 - acc: 0.6889 - val_loss: 0.6910 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6315 - acc: 0.7111 - val_loss: 0.6887 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6306 - acc: 0.7444 - val_loss: 0.6922 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6260 - acc: 0.6944 - val_loss: 0.6934 - val_acc: 0.6000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6292 - acc: 0.6944 - val_loss: 0.6931 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6234 - acc: 0.7056 - val_loss: 0.6867 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6190 - acc: 0.7333 - val_loss: 0.6854 - val_acc: 0.6286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6015 - acc: 0.7722 - val_loss: 0.6906 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6158 - acc: 0.7000 - val_loss: 0.6828 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6080 - acc: 0.7556 - val_loss: 0.6816 - val_acc: 0.6714\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6033 - acc: 0.7667 - val_loss: 0.6854 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6067 - acc: 0.7222 - val_loss: 0.6806 - val_acc: 0.6714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6018 - acc: 0.7556 - val_loss: 0.6801 - val_acc: 0.6857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6018 - acc: 0.7500 - val_loss: 0.6816 - val_acc: 0.6571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5982 - acc: 0.7444 - val_loss: 0.6825 - val_acc: 0.6429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6010 - acc: 0.7333 - val_loss: 0.6793 - val_acc: 0.6857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6153 - acc: 0.7444 - val_loss: 0.6784 - val_acc: 0.6857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5888 - acc: 0.7611 - val_loss: 0.6787 - val_acc: 0.6857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5875 - acc: 0.7500 - val_loss: 0.6787 - val_acc: 0.6857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5813 - acc: 0.7444 - val_loss: 0.6817 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5835 - acc: 0.7833 - val_loss: 0.6895 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5688 - acc: 0.7944 - val_loss: 0.6867 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5999 - acc: 0.7278 - val_loss: 0.6886 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5737 - acc: 0.7944 - val_loss: 0.6863 - val_acc: 0.6286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5822 - acc: 0.7722 - val_loss: 0.6817 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5863 - acc: 0.7278 - val_loss: 0.6896 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5934 - acc: 0.7500 - val_loss: 0.6812 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5738 - acc: 0.7611 - val_loss: 0.6837 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5822 - acc: 0.7333 - val_loss: 0.6826 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5598 - acc: 0.7778 - val_loss: 0.6790 - val_acc: 0.7000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5604 - acc: 0.7833 - val_loss: 0.6847 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5683 - acc: 0.7611 - val_loss: 0.6922 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5669 - acc: 0.7667 - val_loss: 0.6977 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5584 - acc: 0.7667 - val_loss: 0.6833 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5556 - acc: 0.7833 - val_loss: 0.6878 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5621 - acc: 0.7722 - val_loss: 0.6916 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.8102 - acc: 0.4944 - val_loss: 0.7818 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7700 - acc: 0.5000 - val_loss: 0.7743 - val_acc: 0.4571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7319 - acc: 0.5667 - val_loss: 0.7737 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7454 - acc: 0.5611 - val_loss: 0.7720 - val_acc: 0.4714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7292 - acc: 0.5778 - val_loss: 0.7711 - val_acc: 0.4857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7362 - acc: 0.5611 - val_loss: 0.7662 - val_acc: 0.4857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7323 - acc: 0.6000 - val_loss: 0.7624 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7285 - acc: 0.5944 - val_loss: 0.7647 - val_acc: 0.4857\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7188 - acc: 0.6000 - val_loss: 0.7640 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7230 - acc: 0.5889 - val_loss: 0.7588 - val_acc: 0.4857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7155 - acc: 0.6333 - val_loss: 0.7523 - val_acc: 0.4857\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7079 - acc: 0.6167 - val_loss: 0.7509 - val_acc: 0.4857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7181 - acc: 0.5944 - val_loss: 0.7504 - val_acc: 0.4857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7016 - acc: 0.6000 - val_loss: 0.7504 - val_acc: 0.4571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7098 - acc: 0.6000 - val_loss: 0.7464 - val_acc: 0.4571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7073 - acc: 0.6278 - val_loss: 0.7462 - val_acc: 0.4857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6938 - acc: 0.6278 - val_loss: 0.7397 - val_acc: 0.4714\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6983 - acc: 0.6333 - val_loss: 0.7412 - val_acc: 0.4857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6892 - acc: 0.6389 - val_loss: 0.7357 - val_acc: 0.4714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6778 - acc: 0.6333 - val_loss: 0.7359 - val_acc: 0.4857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6882 - acc: 0.6167 - val_loss: 0.7350 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6902 - acc: 0.6222 - val_loss: 0.7338 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6811 - acc: 0.6389 - val_loss: 0.7240 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6699 - acc: 0.6722 - val_loss: 0.7242 - val_acc: 0.5429\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.6605 - acc: 0.6889 - val_loss: 0.7220 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6576 - acc: 0.7000 - val_loss: 0.7187 - val_acc: 0.5000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6576 - acc: 0.7167 - val_loss: 0.7122 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6521 - acc: 0.7222 - val_loss: 0.7137 - val_acc: 0.5286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6500 - acc: 0.7167 - val_loss: 0.7043 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6413 - acc: 0.7111 - val_loss: 0.7066 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6243 - acc: 0.7444 - val_loss: 0.7104 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6406 - acc: 0.6722 - val_loss: 0.7103 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6449 - acc: 0.7056 - val_loss: 0.7016 - val_acc: 0.6143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6371 - acc: 0.7167 - val_loss: 0.7070 - val_acc: 0.5429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6348 - acc: 0.6944 - val_loss: 0.7023 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6267 - acc: 0.7111 - val_loss: 0.6932 - val_acc: 0.6286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 87us/step - loss: 0.6240 - acc: 0.7556 - val_loss: 0.6901 - val_acc: 0.6429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6317 - acc: 0.7611 - val_loss: 0.6900 - val_acc: 0.6429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6203 - acc: 0.7444 - val_loss: 0.6914 - val_acc: 0.6571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6053 - acc: 0.7444 - val_loss: 0.6854 - val_acc: 0.6571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6050 - acc: 0.7611 - val_loss: 0.6947 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6116 - acc: 0.7667 - val_loss: 0.6981 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6120 - acc: 0.7556 - val_loss: 0.6887 - val_acc: 0.6714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5963 - acc: 0.7611 - val_loss: 0.6814 - val_acc: 0.6429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6075 - acc: 0.7611 - val_loss: 0.6835 - val_acc: 0.6429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6112 - acc: 0.7500 - val_loss: 0.6809 - val_acc: 0.6429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5898 - acc: 0.7722 - val_loss: 0.6788 - val_acc: 0.6714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5859 - acc: 0.7944 - val_loss: 0.6864 - val_acc: 0.6429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5944 - acc: 0.7833 - val_loss: 0.6871 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5923 - acc: 0.7500 - val_loss: 0.6857 - val_acc: 0.6429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5917 - acc: 0.7722 - val_loss: 0.6861 - val_acc: 0.6429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5716 - acc: 0.7778 - val_loss: 0.6850 - val_acc: 0.6286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5777 - acc: 0.7444 - val_loss: 0.6889 - val_acc: 0.6571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5898 - acc: 0.7278 - val_loss: 0.6908 - val_acc: 0.6571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5636 - acc: 0.7778 - val_loss: 0.6774 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5756 - acc: 0.7833 - val_loss: 0.6831 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5750 - acc: 0.7722 - val_loss: 0.6703 - val_acc: 0.6714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5613 - acc: 0.7833 - val_loss: 0.6665 - val_acc: 0.6857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5696 - acc: 0.7778 - val_loss: 0.6799 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5508 - acc: 0.8111 - val_loss: 0.6689 - val_acc: 0.6857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5501 - acc: 0.8111 - val_loss: 0.6710 - val_acc: 0.6857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5591 - acc: 0.8056 - val_loss: 0.6772 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5568 - acc: 0.7833 - val_loss: 0.6704 - val_acc: 0.6857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5486 - acc: 0.8167 - val_loss: 0.6704 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5478 - acc: 0.8111 - val_loss: 0.6786 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5315 - acc: 0.7944 - val_loss: 0.6760 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5241 - acc: 0.8333 - val_loss: 0.6640 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5157 - acc: 0.8278 - val_loss: 0.6635 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5323 - acc: 0.8056 - val_loss: 0.6806 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5214 - acc: 0.8000 - val_loss: 0.6734 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5131 - acc: 0.8500 - val_loss: 0.6703 - val_acc: 0.7143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5091 - acc: 0.8222 - val_loss: 0.6698 - val_acc: 0.6857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5189 - acc: 0.8278 - val_loss: 0.6653 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5305 - acc: 0.7944 - val_loss: 0.6719 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5108 - acc: 0.8278 - val_loss: 0.6696 - val_acc: 0.6857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5118 - acc: 0.8222 - val_loss: 0.6736 - val_acc: 0.6857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5235 - acc: 0.7611 - val_loss: 0.6779 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.4894 - acc: 0.8556 - val_loss: 0.6699 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5155 - acc: 0.8056 - val_loss: 0.6734 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.4986 - acc: 0.8444 - val_loss: 0.6832 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.7460 - acc: 0.5556 - val_loss: 0.7427 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7359 - acc: 0.5500 - val_loss: 0.7372 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7340 - acc: 0.5500 - val_loss: 0.7352 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7273 - acc: 0.5444 - val_loss: 0.7313 - val_acc: 0.5000\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.7206 - acc: 0.5500 - val_loss: 0.7269 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7169 - acc: 0.5944 - val_loss: 0.7267 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7184 - acc: 0.5667 - val_loss: 0.7268 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7035 - acc: 0.5667 - val_loss: 0.7228 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7059 - acc: 0.5611 - val_loss: 0.7216 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7159 - acc: 0.5611 - val_loss: 0.7189 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6976 - acc: 0.5556 - val_loss: 0.7178 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7011 - acc: 0.5889 - val_loss: 0.7164 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6991 - acc: 0.5889 - val_loss: 0.7148 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6966 - acc: 0.5889 - val_loss: 0.7133 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7063 - acc: 0.5944 - val_loss: 0.7113 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6975 - acc: 0.5833 - val_loss: 0.7101 - val_acc: 0.5571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6932 - acc: 0.6389 - val_loss: 0.7094 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6954 - acc: 0.6056 - val_loss: 0.7073 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6932 - acc: 0.6167 - val_loss: 0.7060 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6880 - acc: 0.6000 - val_loss: 0.7048 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6952 - acc: 0.6389 - val_loss: 0.7035 - val_acc: 0.5714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6867 - acc: 0.5833 - val_loss: 0.7020 - val_acc: 0.5857\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6809 - acc: 0.6222 - val_loss: 0.7001 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6762 - acc: 0.6556 - val_loss: 0.6989 - val_acc: 0.6000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6637 - acc: 0.6444 - val_loss: 0.7001 - val_acc: 0.6000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6795 - acc: 0.6333 - val_loss: 0.7003 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6746 - acc: 0.6111 - val_loss: 0.6978 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6707 - acc: 0.6444 - val_loss: 0.6966 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6616 - acc: 0.6444 - val_loss: 0.6936 - val_acc: 0.6286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6681 - acc: 0.6778 - val_loss: 0.6946 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6800 - acc: 0.6056 - val_loss: 0.6915 - val_acc: 0.6286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6598 - acc: 0.6278 - val_loss: 0.6903 - val_acc: 0.6286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6624 - acc: 0.6889 - val_loss: 0.6908 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6562 - acc: 0.6722 - val_loss: 0.6906 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6598 - acc: 0.6333 - val_loss: 0.6872 - val_acc: 0.6286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6540 - acc: 0.6556 - val_loss: 0.6813 - val_acc: 0.6571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6552 - acc: 0.6278 - val_loss: 0.6794 - val_acc: 0.6714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6415 - acc: 0.6889 - val_loss: 0.6779 - val_acc: 0.6857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6486 - acc: 0.6667 - val_loss: 0.6768 - val_acc: 0.7000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6419 - acc: 0.6889 - val_loss: 0.6738 - val_acc: 0.6714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6329 - acc: 0.6944 - val_loss: 0.6702 - val_acc: 0.6857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6350 - acc: 0.7111 - val_loss: 0.6728 - val_acc: 0.6714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6397 - acc: 0.6722 - val_loss: 0.6741 - val_acc: 0.6714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6338 - acc: 0.6944 - val_loss: 0.6726 - val_acc: 0.6714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6325 - acc: 0.6722 - val_loss: 0.6679 - val_acc: 0.7000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6318 - acc: 0.7278 - val_loss: 0.6705 - val_acc: 0.6714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6269 - acc: 0.6889 - val_loss: 0.6688 - val_acc: 0.6857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6133 - acc: 0.7167 - val_loss: 0.6653 - val_acc: 0.6714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6137 - acc: 0.7444 - val_loss: 0.6628 - val_acc: 0.7000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6214 - acc: 0.7278 - val_loss: 0.6636 - val_acc: 0.7143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6039 - acc: 0.7167 - val_loss: 0.6630 - val_acc: 0.7143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6138 - acc: 0.7111 - val_loss: 0.6594 - val_acc: 0.7000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6103 - acc: 0.7278 - val_loss: 0.6581 - val_acc: 0.7000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6136 - acc: 0.7278 - val_loss: 0.6552 - val_acc: 0.7000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6053 - acc: 0.7333 - val_loss: 0.6564 - val_acc: 0.7143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6041 - acc: 0.7333 - val_loss: 0.6549 - val_acc: 0.7143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5991 - acc: 0.7611 - val_loss: 0.6552 - val_acc: 0.7143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6000 - acc: 0.7389 - val_loss: 0.6542 - val_acc: 0.7000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5974 - acc: 0.7278 - val_loss: 0.6490 - val_acc: 0.7286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5976 - acc: 0.7667 - val_loss: 0.6489 - val_acc: 0.7143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5907 - acc: 0.7722 - val_loss: 0.6480 - val_acc: 0.7429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5930 - acc: 0.7500 - val_loss: 0.6487 - val_acc: 0.7143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5906 - acc: 0.7556 - val_loss: 0.6504 - val_acc: 0.7143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5926 - acc: 0.7389 - val_loss: 0.6477 - val_acc: 0.7143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5777 - acc: 0.7944 - val_loss: 0.6474 - val_acc: 0.7143\n",
      "Epoch 66/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.5832 - acc: 0.7889 - val_loss: 0.6486 - val_acc: 0.7143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5820 - acc: 0.7444 - val_loss: 0.6455 - val_acc: 0.6857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5855 - acc: 0.7611 - val_loss: 0.6455 - val_acc: 0.7000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5688 - acc: 0.8111 - val_loss: 0.6464 - val_acc: 0.7000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5675 - acc: 0.7556 - val_loss: 0.6454 - val_acc: 0.6857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5774 - acc: 0.8000 - val_loss: 0.6467 - val_acc: 0.7000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5776 - acc: 0.7944 - val_loss: 0.6445 - val_acc: 0.7000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5751 - acc: 0.7722 - val_loss: 0.6436 - val_acc: 0.6857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5940 - acc: 0.7389 - val_loss: 0.6458 - val_acc: 0.6857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5665 - acc: 0.7556 - val_loss: 0.6442 - val_acc: 0.6857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5660 - acc: 0.7778 - val_loss: 0.6425 - val_acc: 0.6857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 75us/step - loss: 0.5459 - acc: 0.8056 - val_loss: 0.6456 - val_acc: 0.7286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5563 - acc: 0.8111 - val_loss: 0.6447 - val_acc: 0.7143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5449 - acc: 0.8000 - val_loss: 0.6433 - val_acc: 0.6857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5510 - acc: 0.8056 - val_loss: 0.6386 - val_acc: 0.6857\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.7559 - acc: 0.4944 - val_loss: 0.7502 - val_acc: 0.4857\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7360 - acc: 0.5389 - val_loss: 0.7492 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7322 - acc: 0.5111 - val_loss: 0.7474 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7285 - acc: 0.5500 - val_loss: 0.7473 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7308 - acc: 0.5444 - val_loss: 0.7445 - val_acc: 0.5286\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7314 - acc: 0.5778 - val_loss: 0.7434 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7349 - acc: 0.5333 - val_loss: 0.7441 - val_acc: 0.5571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7266 - acc: 0.5833 - val_loss: 0.7428 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7158 - acc: 0.6000 - val_loss: 0.7389 - val_acc: 0.5714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7080 - acc: 0.6444 - val_loss: 0.7392 - val_acc: 0.5571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7000 - acc: 0.6000 - val_loss: 0.7372 - val_acc: 0.5714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7102 - acc: 0.5833 - val_loss: 0.7367 - val_acc: 0.5714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7036 - acc: 0.6056 - val_loss: 0.7348 - val_acc: 0.5714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7078 - acc: 0.6000 - val_loss: 0.7359 - val_acc: 0.5714\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7020 - acc: 0.6167 - val_loss: 0.7343 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7035 - acc: 0.6167 - val_loss: 0.7348 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7009 - acc: 0.6278 - val_loss: 0.7345 - val_acc: 0.6000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6951 - acc: 0.6056 - val_loss: 0.7311 - val_acc: 0.5714\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7113 - acc: 0.5944 - val_loss: 0.7309 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6957 - acc: 0.6167 - val_loss: 0.7292 - val_acc: 0.5857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6858 - acc: 0.6444 - val_loss: 0.7298 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6879 - acc: 0.6333 - val_loss: 0.7316 - val_acc: 0.6000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6798 - acc: 0.6056 - val_loss: 0.7290 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6838 - acc: 0.6222 - val_loss: 0.7254 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6785 - acc: 0.6611 - val_loss: 0.7270 - val_acc: 0.5857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6678 - acc: 0.7056 - val_loss: 0.7259 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6709 - acc: 0.6333 - val_loss: 0.7268 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6672 - acc: 0.6444 - val_loss: 0.7239 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 92us/step - loss: 0.6646 - acc: 0.6278 - val_loss: 0.7228 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6729 - acc: 0.6556 - val_loss: 0.7274 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6557 - acc: 0.6389 - val_loss: 0.7239 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6542 - acc: 0.6722 - val_loss: 0.7240 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6511 - acc: 0.6667 - val_loss: 0.7192 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6564 - acc: 0.6500 - val_loss: 0.7202 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 84us/step - loss: 0.6466 - acc: 0.6944 - val_loss: 0.7185 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6553 - acc: 0.6667 - val_loss: 0.7147 - val_acc: 0.6000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6349 - acc: 0.7333 - val_loss: 0.7183 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6577 - acc: 0.6667 - val_loss: 0.7139 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6346 - acc: 0.7056 - val_loss: 0.7143 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6330 - acc: 0.7222 - val_loss: 0.7137 - val_acc: 0.6000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 80us/step - loss: 0.6445 - acc: 0.6722 - val_loss: 0.7131 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6362 - acc: 0.7333 - val_loss: 0.7135 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6340 - acc: 0.6944 - val_loss: 0.7145 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6270 - acc: 0.6944 - val_loss: 0.7092 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6273 - acc: 0.7111 - val_loss: 0.7103 - val_acc: 0.6286\n",
      "Epoch 46/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.6251 - acc: 0.6833 - val_loss: 0.7081 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 91us/step - loss: 0.6232 - acc: 0.7556 - val_loss: 0.7139 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6247 - acc: 0.7222 - val_loss: 0.7066 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6147 - acc: 0.7444 - val_loss: 0.7036 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6094 - acc: 0.7611 - val_loss: 0.7064 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6155 - acc: 0.7222 - val_loss: 0.7056 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5990 - acc: 0.7222 - val_loss: 0.7093 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.5946 - acc: 0.7556 - val_loss: 0.7084 - val_acc: 0.6429\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5897 - acc: 0.7667 - val_loss: 0.7024 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5864 - acc: 0.7667 - val_loss: 0.7023 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5863 - acc: 0.7278 - val_loss: 0.7015 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5899 - acc: 0.7833 - val_loss: 0.7103 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.5832 - acc: 0.7444 - val_loss: 0.7011 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5862 - acc: 0.7778 - val_loss: 0.7026 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5998 - acc: 0.7444 - val_loss: 0.7048 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5628 - acc: 0.8389 - val_loss: 0.7070 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5637 - acc: 0.8222 - val_loss: 0.7074 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5706 - acc: 0.7611 - val_loss: 0.7154 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5718 - acc: 0.7333 - val_loss: 0.7061 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5801 - acc: 0.7722 - val_loss: 0.7066 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5736 - acc: 0.7667 - val_loss: 0.7058 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5654 - acc: 0.7667 - val_loss: 0.7055 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5526 - acc: 0.8056 - val_loss: 0.7113 - val_acc: 0.6286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5586 - acc: 0.7667 - val_loss: 0.7133 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5681 - acc: 0.8000 - val_loss: 0.7045 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5615 - acc: 0.7889 - val_loss: 0.7040 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5511 - acc: 0.7889 - val_loss: 0.7116 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5564 - acc: 0.7667 - val_loss: 0.7092 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5358 - acc: 0.8111 - val_loss: 0.7027 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5419 - acc: 0.7833 - val_loss: 0.7059 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5271 - acc: 0.8222 - val_loss: 0.7128 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5408 - acc: 0.7556 - val_loss: 0.7096 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5339 - acc: 0.7833 - val_loss: 0.7151 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5235 - acc: 0.8111 - val_loss: 0.7175 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5187 - acc: 0.8222 - val_loss: 0.7101 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.7750 - acc: 0.5000 - val_loss: 0.7694 - val_acc: 0.4857\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7441 - acc: 0.5056 - val_loss: 0.7796 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7443 - acc: 0.5111 - val_loss: 0.7725 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7312 - acc: 0.5389 - val_loss: 0.7696 - val_acc: 0.5429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7334 - acc: 0.5333 - val_loss: 0.7628 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7342 - acc: 0.5444 - val_loss: 0.7542 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7343 - acc: 0.5056 - val_loss: 0.7493 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7204 - acc: 0.5889 - val_loss: 0.7513 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7051 - acc: 0.5944 - val_loss: 0.7464 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7156 - acc: 0.5333 - val_loss: 0.7433 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7142 - acc: 0.5222 - val_loss: 0.7467 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7098 - acc: 0.5611 - val_loss: 0.7490 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7003 - acc: 0.6111 - val_loss: 0.7487 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7036 - acc: 0.5556 - val_loss: 0.7446 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6941 - acc: 0.5833 - val_loss: 0.7356 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6969 - acc: 0.5944 - val_loss: 0.7419 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6959 - acc: 0.5722 - val_loss: 0.7386 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7009 - acc: 0.5722 - val_loss: 0.7314 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6944 - acc: 0.6111 - val_loss: 0.7294 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6934 - acc: 0.6222 - val_loss: 0.7274 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6831 - acc: 0.6556 - val_loss: 0.7261 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6965 - acc: 0.6000 - val_loss: 0.7248 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6836 - acc: 0.6222 - val_loss: 0.7222 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6777 - acc: 0.6611 - val_loss: 0.7198 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6765 - acc: 0.6500 - val_loss: 0.7217 - val_acc: 0.5571\n",
      "Epoch 26/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.6660 - acc: 0.6333 - val_loss: 0.7217 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6713 - acc: 0.6389 - val_loss: 0.7155 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6738 - acc: 0.6556 - val_loss: 0.7166 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6601 - acc: 0.6722 - val_loss: 0.7148 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6654 - acc: 0.6556 - val_loss: 0.7179 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6628 - acc: 0.6611 - val_loss: 0.7210 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6657 - acc: 0.6556 - val_loss: 0.7192 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6587 - acc: 0.6889 - val_loss: 0.7208 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6552 - acc: 0.6556 - val_loss: 0.7161 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6539 - acc: 0.6556 - val_loss: 0.7128 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6643 - acc: 0.7000 - val_loss: 0.7161 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6537 - acc: 0.7056 - val_loss: 0.7135 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6430 - acc: 0.7333 - val_loss: 0.7166 - val_acc: 0.5857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6347 - acc: 0.7389 - val_loss: 0.7176 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6413 - acc: 0.7111 - val_loss: 0.7136 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6455 - acc: 0.6667 - val_loss: 0.7113 - val_acc: 0.5857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6524 - acc: 0.6833 - val_loss: 0.7051 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6464 - acc: 0.6944 - val_loss: 0.7092 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6244 - acc: 0.7000 - val_loss: 0.7051 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6217 - acc: 0.7111 - val_loss: 0.7091 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6142 - acc: 0.7389 - val_loss: 0.7061 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6194 - acc: 0.7500 - val_loss: 0.7035 - val_acc: 0.6571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6200 - acc: 0.7167 - val_loss: 0.6996 - val_acc: 0.6429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6227 - acc: 0.7500 - val_loss: 0.7037 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.6215 - acc: 0.7222 - val_loss: 0.7015 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6175 - acc: 0.7333 - val_loss: 0.6957 - val_acc: 0.6857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6138 - acc: 0.7389 - val_loss: 0.6983 - val_acc: 0.6857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5949 - acc: 0.7667 - val_loss: 0.7026 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5936 - acc: 0.7333 - val_loss: 0.7076 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5913 - acc: 0.7889 - val_loss: 0.6989 - val_acc: 0.6714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6098 - acc: 0.7500 - val_loss: 0.6947 - val_acc: 0.6571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5906 - acc: 0.7222 - val_loss: 0.6985 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5997 - acc: 0.7500 - val_loss: 0.7025 - val_acc: 0.6429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5778 - acc: 0.7667 - val_loss: 0.7034 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5811 - acc: 0.7611 - val_loss: 0.6983 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5902 - acc: 0.6944 - val_loss: 0.6978 - val_acc: 0.6571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5855 - acc: 0.7333 - val_loss: 0.7032 - val_acc: 0.6714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5769 - acc: 0.7500 - val_loss: 0.6900 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5734 - acc: 0.7500 - val_loss: 0.6981 - val_acc: 0.6857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5720 - acc: 0.7444 - val_loss: 0.6928 - val_acc: 0.6714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5591 - acc: 0.7611 - val_loss: 0.6921 - val_acc: 0.6714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5706 - acc: 0.7611 - val_loss: 0.6960 - val_acc: 0.6857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5463 - acc: 0.7833 - val_loss: 0.7014 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5665 - acc: 0.7556 - val_loss: 0.6931 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5567 - acc: 0.7667 - val_loss: 0.6965 - val_acc: 0.6714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5589 - acc: 0.7278 - val_loss: 0.6883 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5544 - acc: 0.7944 - val_loss: 0.6915 - val_acc: 0.6571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5594 - acc: 0.7444 - val_loss: 0.6946 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.5440 - acc: 0.7722 - val_loss: 0.6979 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5596 - acc: 0.7667 - val_loss: 0.7031 - val_acc: 0.6571\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5363 - acc: 0.7722 - val_loss: 0.6967 - val_acc: 0.6857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5376 - acc: 0.8056 - val_loss: 0.7032 - val_acc: 0.6857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5426 - acc: 0.7944 - val_loss: 0.6905 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5342 - acc: 0.7944 - val_loss: 0.7010 - val_acc: 0.6857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5294 - acc: 0.7778 - val_loss: 0.7010 - val_acc: 0.6857\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.9224 - acc: 0.4667 - val_loss: 0.7933 - val_acc: 0.4857\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.8135 - acc: 0.4889 - val_loss: 0.7596 - val_acc: 0.5429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7669 - acc: 0.5111 - val_loss: 0.7501 - val_acc: 0.4714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 138us/step - loss: 0.7371 - acc: 0.5778 - val_loss: 0.7464 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7344 - acc: 0.5667 - val_loss: 0.7453 - val_acc: 0.5429\n",
      "Epoch 6/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.7325 - acc: 0.5667 - val_loss: 0.7435 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7399 - acc: 0.5500 - val_loss: 0.7429 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7274 - acc: 0.5944 - val_loss: 0.7422 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7241 - acc: 0.5778 - val_loss: 0.7410 - val_acc: 0.5571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7004 - acc: 0.6722 - val_loss: 0.7427 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7089 - acc: 0.6222 - val_loss: 0.7437 - val_acc: 0.5571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7170 - acc: 0.5889 - val_loss: 0.7435 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7121 - acc: 0.5556 - val_loss: 0.7432 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7006 - acc: 0.5778 - val_loss: 0.7429 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6966 - acc: 0.6000 - val_loss: 0.7359 - val_acc: 0.5571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7003 - acc: 0.6222 - val_loss: 0.7365 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7061 - acc: 0.5833 - val_loss: 0.7325 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7094 - acc: 0.6000 - val_loss: 0.7382 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6988 - acc: 0.6000 - val_loss: 0.7365 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6900 - acc: 0.6278 - val_loss: 0.7385 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6898 - acc: 0.5833 - val_loss: 0.7323 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6781 - acc: 0.6167 - val_loss: 0.7288 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6844 - acc: 0.6222 - val_loss: 0.7311 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6809 - acc: 0.6278 - val_loss: 0.7226 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6932 - acc: 0.6222 - val_loss: 0.7239 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6768 - acc: 0.6389 - val_loss: 0.7233 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6888 - acc: 0.6444 - val_loss: 0.7271 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6734 - acc: 0.6222 - val_loss: 0.7227 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6670 - acc: 0.6556 - val_loss: 0.7233 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6597 - acc: 0.6500 - val_loss: 0.7135 - val_acc: 0.6143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6699 - acc: 0.6667 - val_loss: 0.7118 - val_acc: 0.6143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6742 - acc: 0.6500 - val_loss: 0.7150 - val_acc: 0.5857\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6652 - acc: 0.6389 - val_loss: 0.7143 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6597 - acc: 0.6389 - val_loss: 0.7107 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6651 - acc: 0.6500 - val_loss: 0.7086 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6691 - acc: 0.6778 - val_loss: 0.7052 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6467 - acc: 0.7056 - val_loss: 0.7020 - val_acc: 0.6000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6423 - acc: 0.7556 - val_loss: 0.7042 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6475 - acc: 0.6722 - val_loss: 0.7017 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6424 - acc: 0.7333 - val_loss: 0.7036 - val_acc: 0.6143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6226 - acc: 0.7278 - val_loss: 0.6987 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6492 - acc: 0.7167 - val_loss: 0.7000 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6312 - acc: 0.7056 - val_loss: 0.7033 - val_acc: 0.5857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6419 - acc: 0.7167 - val_loss: 0.6973 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6323 - acc: 0.7333 - val_loss: 0.6964 - val_acc: 0.6286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6269 - acc: 0.7500 - val_loss: 0.6973 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6203 - acc: 0.7444 - val_loss: 0.7005 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6189 - acc: 0.7333 - val_loss: 0.6973 - val_acc: 0.5857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6318 - acc: 0.7167 - val_loss: 0.6941 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6377 - acc: 0.7333 - val_loss: 0.7013 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6128 - acc: 0.7444 - val_loss: 0.6934 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6205 - acc: 0.7444 - val_loss: 0.6916 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6236 - acc: 0.7611 - val_loss: 0.6961 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6048 - acc: 0.7167 - val_loss: 0.7020 - val_acc: 0.5714\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6057 - acc: 0.7333 - val_loss: 0.6949 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5964 - acc: 0.7722 - val_loss: 0.6933 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6095 - acc: 0.7444 - val_loss: 0.7026 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6112 - acc: 0.7333 - val_loss: 0.6895 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5880 - acc: 0.7944 - val_loss: 0.6938 - val_acc: 0.6000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6050 - acc: 0.7278 - val_loss: 0.6877 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5815 - acc: 0.7778 - val_loss: 0.6875 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5901 - acc: 0.7722 - val_loss: 0.6873 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5891 - acc: 0.7833 - val_loss: 0.6876 - val_acc: 0.5857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5822 - acc: 0.7222 - val_loss: 0.6934 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5820 - acc: 0.7667 - val_loss: 0.6959 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5714 - acc: 0.7500 - val_loss: 0.6985 - val_acc: 0.5714\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 78us/step - loss: 0.5762 - acc: 0.7611 - val_loss: 0.6925 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5579 - acc: 0.7889 - val_loss: 0.7027 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5603 - acc: 0.7611 - val_loss: 0.6933 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5540 - acc: 0.7611 - val_loss: 0.6881 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5551 - acc: 0.8000 - val_loss: 0.6897 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5594 - acc: 0.8000 - val_loss: 0.6896 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5500 - acc: 0.7778 - val_loss: 0.6961 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5588 - acc: 0.7556 - val_loss: 0.6917 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5411 - acc: 0.8167 - val_loss: 0.6853 - val_acc: 0.6571\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5540 - acc: 0.8111 - val_loss: 0.6918 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5351 - acc: 0.7778 - val_loss: 0.6958 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5451 - acc: 0.7778 - val_loss: 0.7077 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5641 - acc: 0.7778 - val_loss: 0.6932 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5412 - acc: 0.7722 - val_loss: 0.6939 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.7796 - acc: 0.4889 - val_loss: 0.7465 - val_acc: 0.4857\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7612 - acc: 0.5333 - val_loss: 0.7421 - val_acc: 0.5714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7453 - acc: 0.5444 - val_loss: 0.7384 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7423 - acc: 0.5333 - val_loss: 0.7387 - val_acc: 0.4714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7379 - acc: 0.5167 - val_loss: 0.7385 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7230 - acc: 0.6111 - val_loss: 0.7379 - val_acc: 0.4714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7260 - acc: 0.5611 - val_loss: 0.7383 - val_acc: 0.4714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7179 - acc: 0.5944 - val_loss: 0.7384 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7210 - acc: 0.5667 - val_loss: 0.7386 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7214 - acc: 0.5500 - val_loss: 0.7380 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7216 - acc: 0.5833 - val_loss: 0.7377 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7142 - acc: 0.6056 - val_loss: 0.7357 - val_acc: 0.4857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7085 - acc: 0.6167 - val_loss: 0.7352 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7061 - acc: 0.6389 - val_loss: 0.7366 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7123 - acc: 0.5944 - val_loss: 0.7371 - val_acc: 0.4857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7022 - acc: 0.6222 - val_loss: 0.7369 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7048 - acc: 0.6111 - val_loss: 0.7371 - val_acc: 0.4714\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7028 - acc: 0.6389 - val_loss: 0.7367 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7082 - acc: 0.6056 - val_loss: 0.7352 - val_acc: 0.4571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6972 - acc: 0.6278 - val_loss: 0.7359 - val_acc: 0.4857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6914 - acc: 0.6333 - val_loss: 0.7345 - val_acc: 0.4714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6958 - acc: 0.6111 - val_loss: 0.7337 - val_acc: 0.4714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6888 - acc: 0.6611 - val_loss: 0.7312 - val_acc: 0.4857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6765 - acc: 0.6833 - val_loss: 0.7305 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6924 - acc: 0.6278 - val_loss: 0.7303 - val_acc: 0.4857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6856 - acc: 0.6444 - val_loss: 0.7315 - val_acc: 0.5000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6841 - acc: 0.6444 - val_loss: 0.7296 - val_acc: 0.4857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6770 - acc: 0.6444 - val_loss: 0.7303 - val_acc: 0.4857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6799 - acc: 0.6722 - val_loss: 0.7289 - val_acc: 0.5000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6731 - acc: 0.6722 - val_loss: 0.7281 - val_acc: 0.5000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6776 - acc: 0.6500 - val_loss: 0.7266 - val_acc: 0.5286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6761 - acc: 0.6833 - val_loss: 0.7269 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6640 - acc: 0.7056 - val_loss: 0.7250 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6609 - acc: 0.7056 - val_loss: 0.7247 - val_acc: 0.5429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6724 - acc: 0.6778 - val_loss: 0.7228 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6738 - acc: 0.6556 - val_loss: 0.7237 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6553 - acc: 0.6889 - val_loss: 0.7245 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6508 - acc: 0.7000 - val_loss: 0.7207 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6383 - acc: 0.7444 - val_loss: 0.7192 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6706 - acc: 0.6444 - val_loss: 0.7219 - val_acc: 0.5286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6612 - acc: 0.6722 - val_loss: 0.7221 - val_acc: 0.5429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6631 - acc: 0.6556 - val_loss: 0.7216 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6495 - acc: 0.7111 - val_loss: 0.7251 - val_acc: 0.5286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6417 - acc: 0.7000 - val_loss: 0.7193 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6488 - acc: 0.7222 - val_loss: 0.7177 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6473 - acc: 0.7222 - val_loss: 0.7178 - val_acc: 0.5571\n",
      "Epoch 47/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6485 - acc: 0.7111 - val_loss: 0.7172 - val_acc: 0.5429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6421 - acc: 0.7111 - val_loss: 0.7189 - val_acc: 0.5571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6399 - acc: 0.7167 - val_loss: 0.7229 - val_acc: 0.5000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6389 - acc: 0.7000 - val_loss: 0.7214 - val_acc: 0.5000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6409 - acc: 0.6833 - val_loss: 0.7166 - val_acc: 0.5429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6202 - acc: 0.7222 - val_loss: 0.7134 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6292 - acc: 0.7222 - val_loss: 0.7177 - val_acc: 0.5000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6131 - acc: 0.7500 - val_loss: 0.7164 - val_acc: 0.5286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6171 - acc: 0.7444 - val_loss: 0.7139 - val_acc: 0.5429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6214 - acc: 0.7000 - val_loss: 0.7084 - val_acc: 0.6000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6164 - acc: 0.7500 - val_loss: 0.7117 - val_acc: 0.5429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6111 - acc: 0.7556 - val_loss: 0.7080 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6187 - acc: 0.7500 - val_loss: 0.7076 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6381 - acc: 0.7056 - val_loss: 0.7119 - val_acc: 0.5571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6070 - acc: 0.7278 - val_loss: 0.7110 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5888 - acc: 0.7611 - val_loss: 0.7096 - val_acc: 0.5714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5961 - acc: 0.7333 - val_loss: 0.7129 - val_acc: 0.5571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5885 - acc: 0.7500 - val_loss: 0.7120 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6057 - acc: 0.7167 - val_loss: 0.7211 - val_acc: 0.5429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5986 - acc: 0.6944 - val_loss: 0.7143 - val_acc: 0.5571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6050 - acc: 0.7500 - val_loss: 0.7154 - val_acc: 0.5571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6053 - acc: 0.7500 - val_loss: 0.7192 - val_acc: 0.5429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5871 - acc: 0.7278 - val_loss: 0.7137 - val_acc: 0.5714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5929 - acc: 0.7056 - val_loss: 0.7145 - val_acc: 0.5857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5724 - acc: 0.7833 - val_loss: 0.7134 - val_acc: 0.5857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5687 - acc: 0.7889 - val_loss: 0.7122 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5786 - acc: 0.7444 - val_loss: 0.7126 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5680 - acc: 0.7889 - val_loss: 0.7119 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5820 - acc: 0.7611 - val_loss: 0.7105 - val_acc: 0.5857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5695 - acc: 0.8000 - val_loss: 0.7141 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5747 - acc: 0.7944 - val_loss: 0.7127 - val_acc: 0.5714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5664 - acc: 0.7667 - val_loss: 0.7106 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5685 - acc: 0.7556 - val_loss: 0.7112 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5668 - acc: 0.7722 - val_loss: 0.7135 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.8245 - acc: 0.4611 - val_loss: 0.7669 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7868 - acc: 0.4611 - val_loss: 0.7545 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7627 - acc: 0.4611 - val_loss: 0.7485 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7473 - acc: 0.5333 - val_loss: 0.7446 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7433 - acc: 0.5389 - val_loss: 0.7422 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7446 - acc: 0.5222 - val_loss: 0.7401 - val_acc: 0.5857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7264 - acc: 0.6000 - val_loss: 0.7391 - val_acc: 0.5714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7327 - acc: 0.5611 - val_loss: 0.7384 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7284 - acc: 0.5833 - val_loss: 0.7374 - val_acc: 0.5714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7229 - acc: 0.5778 - val_loss: 0.7374 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7230 - acc: 0.5889 - val_loss: 0.7381 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7187 - acc: 0.5833 - val_loss: 0.7373 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7120 - acc: 0.5944 - val_loss: 0.7356 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7192 - acc: 0.5556 - val_loss: 0.7353 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7156 - acc: 0.5611 - val_loss: 0.7326 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7086 - acc: 0.5778 - val_loss: 0.7340 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7113 - acc: 0.5611 - val_loss: 0.7322 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7109 - acc: 0.5944 - val_loss: 0.7335 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7038 - acc: 0.5944 - val_loss: 0.7333 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7073 - acc: 0.5778 - val_loss: 0.7304 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7065 - acc: 0.5500 - val_loss: 0.7289 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6994 - acc: 0.6000 - val_loss: 0.7272 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7017 - acc: 0.5944 - val_loss: 0.7275 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6937 - acc: 0.6111 - val_loss: 0.7248 - val_acc: 0.5143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6937 - acc: 0.6000 - val_loss: 0.7250 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6914 - acc: 0.6222 - val_loss: 0.7263 - val_acc: 0.5429\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6954 - acc: 0.6056 - val_loss: 0.7248 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6927 - acc: 0.6222 - val_loss: 0.7252 - val_acc: 0.5429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6911 - acc: 0.6056 - val_loss: 0.7229 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6818 - acc: 0.6556 - val_loss: 0.7215 - val_acc: 0.5286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6808 - acc: 0.6278 - val_loss: 0.7196 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6737 - acc: 0.6444 - val_loss: 0.7175 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6716 - acc: 0.7056 - val_loss: 0.7160 - val_acc: 0.6143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6742 - acc: 0.7000 - val_loss: 0.7167 - val_acc: 0.5429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6800 - acc: 0.6667 - val_loss: 0.7143 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6712 - acc: 0.6778 - val_loss: 0.7148 - val_acc: 0.5857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6615 - acc: 0.6833 - val_loss: 0.7131 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6532 - acc: 0.7056 - val_loss: 0.7126 - val_acc: 0.5857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6641 - acc: 0.6611 - val_loss: 0.7124 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6615 - acc: 0.6667 - val_loss: 0.7103 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6665 - acc: 0.6944 - val_loss: 0.7121 - val_acc: 0.5857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6593 - acc: 0.6611 - val_loss: 0.7103 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6533 - acc: 0.6833 - val_loss: 0.7080 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6468 - acc: 0.6944 - val_loss: 0.7078 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6515 - acc: 0.7111 - val_loss: 0.7101 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6499 - acc: 0.6778 - val_loss: 0.7050 - val_acc: 0.5857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6407 - acc: 0.7111 - val_loss: 0.7081 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6530 - acc: 0.6667 - val_loss: 0.7053 - val_acc: 0.5857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6448 - acc: 0.7000 - val_loss: 0.7054 - val_acc: 0.5571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6422 - acc: 0.6889 - val_loss: 0.7010 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6394 - acc: 0.6833 - val_loss: 0.7007 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6229 - acc: 0.7444 - val_loss: 0.7033 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6369 - acc: 0.6778 - val_loss: 0.7047 - val_acc: 0.5857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6291 - acc: 0.7278 - val_loss: 0.7051 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6467 - acc: 0.7056 - val_loss: 0.7012 - val_acc: 0.5714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6110 - acc: 0.7278 - val_loss: 0.6990 - val_acc: 0.5714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6042 - acc: 0.7500 - val_loss: 0.7005 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6221 - acc: 0.7389 - val_loss: 0.7013 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6143 - acc: 0.7389 - val_loss: 0.6991 - val_acc: 0.5714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6213 - acc: 0.7000 - val_loss: 0.6987 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6200 - acc: 0.7056 - val_loss: 0.6966 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6001 - acc: 0.7500 - val_loss: 0.7013 - val_acc: 0.5857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6139 - acc: 0.7111 - val_loss: 0.6998 - val_acc: 0.5857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6144 - acc: 0.7056 - val_loss: 0.6918 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5999 - acc: 0.7500 - val_loss: 0.6911 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5924 - acc: 0.7444 - val_loss: 0.6912 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6019 - acc: 0.7611 - val_loss: 0.6926 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5969 - acc: 0.7389 - val_loss: 0.6985 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5819 - acc: 0.7889 - val_loss: 0.6950 - val_acc: 0.5857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5788 - acc: 0.7722 - val_loss: 0.6935 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6019 - acc: 0.7167 - val_loss: 0.6926 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5803 - acc: 0.8000 - val_loss: 0.6916 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.5800 - acc: 0.7389 - val_loss: 0.6882 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5680 - acc: 0.8222 - val_loss: 0.6903 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5840 - acc: 0.7389 - val_loss: 0.6872 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5732 - acc: 0.7778 - val_loss: 0.6868 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5670 - acc: 0.8056 - val_loss: 0.6867 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5668 - acc: 0.7889 - val_loss: 0.6874 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5538 - acc: 0.8111 - val_loss: 0.6896 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5566 - acc: 0.7556 - val_loss: 0.6868 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.7531 - acc: 0.4944 - val_loss: 0.7399 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7364 - acc: 0.5222 - val_loss: 0.7372 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 92us/step - loss: 0.7334 - acc: 0.5333 - val_loss: 0.7392 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7270 - acc: 0.5611 - val_loss: 0.7391 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7264 - acc: 0.5389 - val_loss: 0.7379 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7240 - acc: 0.5444 - val_loss: 0.7367 - val_acc: 0.5143\n",
      "Epoch 7/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.7164 - acc: 0.5611 - val_loss: 0.7398 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7232 - acc: 0.5278 - val_loss: 0.7392 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7170 - acc: 0.5667 - val_loss: 0.7357 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7101 - acc: 0.5667 - val_loss: 0.7332 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7118 - acc: 0.5500 - val_loss: 0.7316 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7145 - acc: 0.5667 - val_loss: 0.7291 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7033 - acc: 0.5611 - val_loss: 0.7282 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6893 - acc: 0.6222 - val_loss: 0.7272 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7063 - acc: 0.5611 - val_loss: 0.7310 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6993 - acc: 0.5778 - val_loss: 0.7294 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7032 - acc: 0.5667 - val_loss: 0.7280 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6912 - acc: 0.6056 - val_loss: 0.7264 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6892 - acc: 0.6000 - val_loss: 0.7297 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6861 - acc: 0.6000 - val_loss: 0.7246 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6798 - acc: 0.6000 - val_loss: 0.7279 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6965 - acc: 0.5667 - val_loss: 0.7231 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6810 - acc: 0.6111 - val_loss: 0.7255 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6841 - acc: 0.6056 - val_loss: 0.7239 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6655 - acc: 0.6444 - val_loss: 0.7259 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6881 - acc: 0.5944 - val_loss: 0.7281 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6874 - acc: 0.5833 - val_loss: 0.7258 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6768 - acc: 0.6167 - val_loss: 0.7215 - val_acc: 0.5286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6691 - acc: 0.6500 - val_loss: 0.7230 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6712 - acc: 0.5833 - val_loss: 0.7196 - val_acc: 0.5286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6702 - acc: 0.6056 - val_loss: 0.7160 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6711 - acc: 0.6278 - val_loss: 0.7170 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6686 - acc: 0.6167 - val_loss: 0.7120 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6631 - acc: 0.6556 - val_loss: 0.7129 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6571 - acc: 0.6611 - val_loss: 0.7104 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6582 - acc: 0.6833 - val_loss: 0.7081 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6525 - acc: 0.6667 - val_loss: 0.7039 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6540 - acc: 0.7000 - val_loss: 0.7045 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6476 - acc: 0.6833 - val_loss: 0.7055 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6476 - acc: 0.7111 - val_loss: 0.7047 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6479 - acc: 0.6667 - val_loss: 0.7034 - val_acc: 0.5571\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6392 - acc: 0.6944 - val_loss: 0.7000 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6513 - acc: 0.6611 - val_loss: 0.6973 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6305 - acc: 0.7167 - val_loss: 0.6956 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6296 - acc: 0.7000 - val_loss: 0.6933 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6291 - acc: 0.7000 - val_loss: 0.6931 - val_acc: 0.5857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6291 - acc: 0.7222 - val_loss: 0.6931 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6211 - acc: 0.7389 - val_loss: 0.6929 - val_acc: 0.6000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6319 - acc: 0.7056 - val_loss: 0.6898 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6115 - acc: 0.7333 - val_loss: 0.6972 - val_acc: 0.5571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6184 - acc: 0.7111 - val_loss: 0.7002 - val_acc: 0.5286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6163 - acc: 0.7167 - val_loss: 0.7053 - val_acc: 0.5429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6196 - acc: 0.7167 - val_loss: 0.6984 - val_acc: 0.5571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6234 - acc: 0.7389 - val_loss: 0.7003 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6017 - acc: 0.7556 - val_loss: 0.7036 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6082 - acc: 0.7222 - val_loss: 0.6996 - val_acc: 0.5429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6138 - acc: 0.7278 - val_loss: 0.6972 - val_acc: 0.5429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6019 - acc: 0.7444 - val_loss: 0.6929 - val_acc: 0.5714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6048 - acc: 0.7333 - val_loss: 0.7034 - val_acc: 0.5429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.5967 - acc: 0.7167 - val_loss: 0.6963 - val_acc: 0.5429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6035 - acc: 0.7278 - val_loss: 0.7044 - val_acc: 0.5429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5829 - acc: 0.7667 - val_loss: 0.6975 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5870 - acc: 0.7556 - val_loss: 0.6935 - val_acc: 0.5714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5849 - acc: 0.7389 - val_loss: 0.7044 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5653 - acc: 0.7556 - val_loss: 0.6967 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5886 - acc: 0.7333 - val_loss: 0.6945 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5750 - acc: 0.7722 - val_loss: 0.7000 - val_acc: 0.5714\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.5744 - acc: 0.7778 - val_loss: 0.6965 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5808 - acc: 0.7444 - val_loss: 0.6974 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5758 - acc: 0.7611 - val_loss: 0.6930 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5701 - acc: 0.7889 - val_loss: 0.6922 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5663 - acc: 0.7722 - val_loss: 0.6992 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5776 - acc: 0.7278 - val_loss: 0.6963 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5661 - acc: 0.7944 - val_loss: 0.7074 - val_acc: 0.5714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5619 - acc: 0.7889 - val_loss: 0.6904 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.5535 - acc: 0.7833 - val_loss: 0.6904 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5752 - acc: 0.7333 - val_loss: 0.6956 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5627 - acc: 0.7778 - val_loss: 0.7090 - val_acc: 0.5571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.5477 - acc: 0.7944 - val_loss: 0.6964 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 164us/step - loss: 0.5538 - acc: 0.7500 - val_loss: 0.7037 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 212us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.9197 - acc: 0.4444 - val_loss: 0.8150 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.8603 - acc: 0.4500 - val_loss: 0.7801 - val_acc: 0.4714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.8151 - acc: 0.4722 - val_loss: 0.7629 - val_acc: 0.4286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7762 - acc: 0.4444 - val_loss: 0.7578 - val_acc: 0.4429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7734 - acc: 0.4611 - val_loss: 0.7535 - val_acc: 0.4429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7696 - acc: 0.4611 - val_loss: 0.7513 - val_acc: 0.4714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7645 - acc: 0.4722 - val_loss: 0.7492 - val_acc: 0.4714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7528 - acc: 0.4778 - val_loss: 0.7484 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7408 - acc: 0.5167 - val_loss: 0.7475 - val_acc: 0.5571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7517 - acc: 0.4500 - val_loss: 0.7472 - val_acc: 0.5571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7499 - acc: 0.4611 - val_loss: 0.7470 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7367 - acc: 0.5556 - val_loss: 0.7470 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7335 - acc: 0.5278 - val_loss: 0.7471 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 96us/step - loss: 0.7334 - acc: 0.5444 - val_loss: 0.7468 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7284 - acc: 0.5333 - val_loss: 0.7474 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7283 - acc: 0.5333 - val_loss: 0.7469 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7158 - acc: 0.5611 - val_loss: 0.7468 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7209 - acc: 0.5389 - val_loss: 0.7459 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7264 - acc: 0.5222 - val_loss: 0.7454 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.7201 - acc: 0.5444 - val_loss: 0.7446 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7086 - acc: 0.5722 - val_loss: 0.7437 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7174 - acc: 0.5333 - val_loss: 0.7432 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7092 - acc: 0.5611 - val_loss: 0.7432 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7144 - acc: 0.5556 - val_loss: 0.7413 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7082 - acc: 0.5722 - val_loss: 0.7404 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7175 - acc: 0.5278 - val_loss: 0.7414 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7034 - acc: 0.5944 - val_loss: 0.7401 - val_acc: 0.5000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7051 - acc: 0.5611 - val_loss: 0.7406 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7063 - acc: 0.6056 - val_loss: 0.7382 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6932 - acc: 0.6056 - val_loss: 0.7386 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6986 - acc: 0.5944 - val_loss: 0.7389 - val_acc: 0.5000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 91us/step - loss: 0.7000 - acc: 0.5889 - val_loss: 0.7391 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7044 - acc: 0.5556 - val_loss: 0.7392 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7087 - acc: 0.5278 - val_loss: 0.7370 - val_acc: 0.5143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6992 - acc: 0.5611 - val_loss: 0.7371 - val_acc: 0.5143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6937 - acc: 0.5611 - val_loss: 0.7363 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6852 - acc: 0.6278 - val_loss: 0.7358 - val_acc: 0.5143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6986 - acc: 0.5611 - val_loss: 0.7357 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6969 - acc: 0.5611 - val_loss: 0.7347 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6771 - acc: 0.6389 - val_loss: 0.7347 - val_acc: 0.5286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6831 - acc: 0.6056 - val_loss: 0.7347 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6771 - acc: 0.6222 - val_loss: 0.7322 - val_acc: 0.5429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6826 - acc: 0.6389 - val_loss: 0.7352 - val_acc: 0.5286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6711 - acc: 0.6278 - val_loss: 0.7352 - val_acc: 0.5286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6813 - acc: 0.6056 - val_loss: 0.7335 - val_acc: 0.5286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6834 - acc: 0.5833 - val_loss: 0.7327 - val_acc: 0.5429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6833 - acc: 0.5944 - val_loss: 0.7309 - val_acc: 0.5714\n",
      "Epoch 48/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6669 - acc: 0.6556 - val_loss: 0.7298 - val_acc: 0.5286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6794 - acc: 0.6000 - val_loss: 0.7302 - val_acc: 0.5571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6746 - acc: 0.6056 - val_loss: 0.7305 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6721 - acc: 0.6056 - val_loss: 0.7310 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6592 - acc: 0.6222 - val_loss: 0.7286 - val_acc: 0.5571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6628 - acc: 0.6389 - val_loss: 0.7280 - val_acc: 0.5286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6583 - acc: 0.6333 - val_loss: 0.7294 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6559 - acc: 0.6444 - val_loss: 0.7281 - val_acc: 0.5429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6573 - acc: 0.6611 - val_loss: 0.7265 - val_acc: 0.5429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6517 - acc: 0.6667 - val_loss: 0.7251 - val_acc: 0.5571\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6558 - acc: 0.6667 - val_loss: 0.7266 - val_acc: 0.5429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6570 - acc: 0.6389 - val_loss: 0.7269 - val_acc: 0.5429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6449 - acc: 0.6778 - val_loss: 0.7270 - val_acc: 0.5571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6605 - acc: 0.6278 - val_loss: 0.7235 - val_acc: 0.5429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6363 - acc: 0.7444 - val_loss: 0.7258 - val_acc: 0.5714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6428 - acc: 0.6722 - val_loss: 0.7250 - val_acc: 0.5429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6530 - acc: 0.6667 - val_loss: 0.7238 - val_acc: 0.5286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6420 - acc: 0.6833 - val_loss: 0.7235 - val_acc: 0.5571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6449 - acc: 0.7000 - val_loss: 0.7244 - val_acc: 0.5571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6318 - acc: 0.7000 - val_loss: 0.7268 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6246 - acc: 0.6889 - val_loss: 0.7256 - val_acc: 0.5857\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6261 - acc: 0.6889 - val_loss: 0.7251 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6163 - acc: 0.7056 - val_loss: 0.7250 - val_acc: 0.5571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6016 - acc: 0.7500 - val_loss: 0.7219 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6075 - acc: 0.7389 - val_loss: 0.7208 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6127 - acc: 0.7222 - val_loss: 0.7218 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6021 - acc: 0.7222 - val_loss: 0.7202 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6059 - acc: 0.7222 - val_loss: 0.7222 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5935 - acc: 0.7389 - val_loss: 0.7194 - val_acc: 0.5857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5932 - acc: 0.7611 - val_loss: 0.7221 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6052 - acc: 0.7222 - val_loss: 0.7192 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5959 - acc: 0.7222 - val_loss: 0.7199 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5858 - acc: 0.7444 - val_loss: 0.7208 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.9014 - acc: 0.5333 - val_loss: 0.8662 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.8291 - acc: 0.5389 - val_loss: 0.8139 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7798 - acc: 0.5333 - val_loss: 0.7793 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7566 - acc: 0.5389 - val_loss: 0.7583 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7272 - acc: 0.5556 - val_loss: 0.7473 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7216 - acc: 0.5889 - val_loss: 0.7469 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7409 - acc: 0.5333 - val_loss: 0.7420 - val_acc: 0.5571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7230 - acc: 0.5611 - val_loss: 0.7388 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7140 - acc: 0.5444 - val_loss: 0.7374 - val_acc: 0.5571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7179 - acc: 0.5778 - val_loss: 0.7350 - val_acc: 0.5571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7199 - acc: 0.5444 - val_loss: 0.7320 - val_acc: 0.5857\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7222 - acc: 0.5778 - val_loss: 0.7279 - val_acc: 0.5857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7155 - acc: 0.5500 - val_loss: 0.7255 - val_acc: 0.6000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7092 - acc: 0.5611 - val_loss: 0.7268 - val_acc: 0.6000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7103 - acc: 0.6000 - val_loss: 0.7296 - val_acc: 0.5857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7049 - acc: 0.5833 - val_loss: 0.7221 - val_acc: 0.5571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6927 - acc: 0.5889 - val_loss: 0.7235 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7026 - acc: 0.6000 - val_loss: 0.7184 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 81us/step - loss: 0.7001 - acc: 0.5722 - val_loss: 0.7151 - val_acc: 0.5857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6916 - acc: 0.6000 - val_loss: 0.7153 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6846 - acc: 0.6389 - val_loss: 0.7161 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7017 - acc: 0.6056 - val_loss: 0.7202 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6924 - acc: 0.6278 - val_loss: 0.7165 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6817 - acc: 0.6278 - val_loss: 0.7146 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6668 - acc: 0.6278 - val_loss: 0.7151 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6638 - acc: 0.6667 - val_loss: 0.7112 - val_acc: 0.6143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6822 - acc: 0.6278 - val_loss: 0.7110 - val_acc: 0.5857\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.6742 - acc: 0.6444 - val_loss: 0.7070 - val_acc: 0.6000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6677 - acc: 0.6944 - val_loss: 0.7061 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6645 - acc: 0.6611 - val_loss: 0.7035 - val_acc: 0.6286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.6710 - acc: 0.6444 - val_loss: 0.7066 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6661 - acc: 0.6556 - val_loss: 0.7036 - val_acc: 0.6143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6528 - acc: 0.6833 - val_loss: 0.7045 - val_acc: 0.5857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6723 - acc: 0.6389 - val_loss: 0.7022 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6547 - acc: 0.6833 - val_loss: 0.6991 - val_acc: 0.6429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6506 - acc: 0.6889 - val_loss: 0.7008 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6462 - acc: 0.7056 - val_loss: 0.6997 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 90us/step - loss: 0.6449 - acc: 0.6778 - val_loss: 0.7009 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6448 - acc: 0.7000 - val_loss: 0.7057 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6416 - acc: 0.6444 - val_loss: 0.6992 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6484 - acc: 0.7000 - val_loss: 0.6954 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6434 - acc: 0.7000 - val_loss: 0.6926 - val_acc: 0.6571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6440 - acc: 0.7167 - val_loss: 0.6973 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.6357 - acc: 0.7000 - val_loss: 0.6917 - val_acc: 0.6429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6369 - acc: 0.7389 - val_loss: 0.6905 - val_acc: 0.6286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6282 - acc: 0.7222 - val_loss: 0.6921 - val_acc: 0.6429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6341 - acc: 0.7000 - val_loss: 0.6930 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6279 - acc: 0.7111 - val_loss: 0.6899 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6370 - acc: 0.6722 - val_loss: 0.6925 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6210 - acc: 0.7111 - val_loss: 0.6929 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6270 - acc: 0.7278 - val_loss: 0.6975 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6092 - acc: 0.7333 - val_loss: 0.6958 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6158 - acc: 0.6833 - val_loss: 0.6912 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6196 - acc: 0.7278 - val_loss: 0.6968 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6078 - acc: 0.6944 - val_loss: 0.6885 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6031 - acc: 0.7278 - val_loss: 0.6892 - val_acc: 0.5857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6044 - acc: 0.7389 - val_loss: 0.6874 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6054 - acc: 0.7056 - val_loss: 0.6899 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5960 - acc: 0.7278 - val_loss: 0.6920 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5895 - acc: 0.7278 - val_loss: 0.6944 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5938 - acc: 0.7333 - val_loss: 0.6975 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5941 - acc: 0.7667 - val_loss: 0.6979 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5831 - acc: 0.7722 - val_loss: 0.6894 - val_acc: 0.6286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5850 - acc: 0.7333 - val_loss: 0.6933 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5743 - acc: 0.7722 - val_loss: 0.6908 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5944 - acc: 0.7167 - val_loss: 0.6967 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5869 - acc: 0.7056 - val_loss: 0.6879 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5868 - acc: 0.6944 - val_loss: 0.6898 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5638 - acc: 0.7611 - val_loss: 0.6935 - val_acc: 0.6429\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5873 - acc: 0.7167 - val_loss: 0.6955 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5806 - acc: 0.7444 - val_loss: 0.6845 - val_acc: 0.6286\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5787 - acc: 0.7444 - val_loss: 0.6869 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5703 - acc: 0.7556 - val_loss: 0.6870 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5710 - acc: 0.7556 - val_loss: 0.6899 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5641 - acc: 0.8000 - val_loss: 0.6897 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5576 - acc: 0.7833 - val_loss: 0.6923 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5852 - acc: 0.7667 - val_loss: 0.6850 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5556 - acc: 0.7944 - val_loss: 0.6849 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5463 - acc: 0.7944 - val_loss: 0.6862 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5629 - acc: 0.7389 - val_loss: 0.6866 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.8610 - acc: 0.4556 - val_loss: 0.7571 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7792 - acc: 0.4778 - val_loss: 0.7477 - val_acc: 0.4571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7407 - acc: 0.5444 - val_loss: 0.7513 - val_acc: 0.5571\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7450 - acc: 0.5222 - val_loss: 0.7523 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7295 - acc: 0.5667 - val_loss: 0.7520 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7494 - acc: 0.4944 - val_loss: 0.7549 - val_acc: 0.5429\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7233 - acc: 0.5278 - val_loss: 0.7573 - val_acc: 0.5286\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.7467 - acc: 0.4833 - val_loss: 0.7559 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7234 - acc: 0.5444 - val_loss: 0.7486 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7262 - acc: 0.5500 - val_loss: 0.7486 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7133 - acc: 0.5444 - val_loss: 0.7492 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 95us/step - loss: 0.7258 - acc: 0.5389 - val_loss: 0.7426 - val_acc: 0.5571\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7235 - acc: 0.5556 - val_loss: 0.7396 - val_acc: 0.5714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7213 - acc: 0.5444 - val_loss: 0.7405 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7114 - acc: 0.6222 - val_loss: 0.7419 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7052 - acc: 0.6167 - val_loss: 0.7411 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7133 - acc: 0.6000 - val_loss: 0.7374 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6831 - acc: 0.6556 - val_loss: 0.7414 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7111 - acc: 0.5889 - val_loss: 0.7442 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7028 - acc: 0.5944 - val_loss: 0.7360 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7157 - acc: 0.5722 - val_loss: 0.7305 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6926 - acc: 0.6056 - val_loss: 0.7340 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6890 - acc: 0.6222 - val_loss: 0.7348 - val_acc: 0.5429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6989 - acc: 0.6111 - val_loss: 0.7273 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6854 - acc: 0.6500 - val_loss: 0.7177 - val_acc: 0.5857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6992 - acc: 0.6278 - val_loss: 0.7259 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6887 - acc: 0.6333 - val_loss: 0.7222 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6933 - acc: 0.6278 - val_loss: 0.7209 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6841 - acc: 0.6444 - val_loss: 0.7188 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6790 - acc: 0.6611 - val_loss: 0.7141 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6709 - acc: 0.6389 - val_loss: 0.7078 - val_acc: 0.6143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6737 - acc: 0.6000 - val_loss: 0.7155 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6604 - acc: 0.6500 - val_loss: 0.7089 - val_acc: 0.6143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6682 - acc: 0.6667 - val_loss: 0.7029 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6562 - acc: 0.6500 - val_loss: 0.6986 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6485 - acc: 0.7056 - val_loss: 0.7089 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6523 - acc: 0.6500 - val_loss: 0.7024 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6484 - acc: 0.6667 - val_loss: 0.7034 - val_acc: 0.6000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6442 - acc: 0.7222 - val_loss: 0.6981 - val_acc: 0.6429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6505 - acc: 0.6667 - val_loss: 0.7075 - val_acc: 0.6143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6431 - acc: 0.6722 - val_loss: 0.7073 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 504us/step - loss: 0.6471 - acc: 0.6944 - val_loss: 0.7080 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6491 - acc: 0.6833 - val_loss: 0.7041 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6429 - acc: 0.7167 - val_loss: 0.7122 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6498 - acc: 0.6889 - val_loss: 0.6991 - val_acc: 0.6286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6329 - acc: 0.7056 - val_loss: 0.6973 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6309 - acc: 0.7222 - val_loss: 0.6970 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6217 - acc: 0.7056 - val_loss: 0.7060 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6300 - acc: 0.6889 - val_loss: 0.7033 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6338 - acc: 0.6833 - val_loss: 0.7045 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6164 - acc: 0.7333 - val_loss: 0.6993 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6125 - acc: 0.7222 - val_loss: 0.6937 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5919 - acc: 0.7722 - val_loss: 0.7012 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6066 - acc: 0.7611 - val_loss: 0.6946 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6250 - acc: 0.7389 - val_loss: 0.7043 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6124 - acc: 0.7278 - val_loss: 0.7003 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5990 - acc: 0.7278 - val_loss: 0.7080 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6121 - acc: 0.7111 - val_loss: 0.6943 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5887 - acc: 0.7667 - val_loss: 0.6924 - val_acc: 0.5571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 85us/step - loss: 0.5889 - acc: 0.7611 - val_loss: 0.6976 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5717 - acc: 0.7722 - val_loss: 0.6981 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5978 - acc: 0.7500 - val_loss: 0.6959 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5832 - acc: 0.7444 - val_loss: 0.7168 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5740 - acc: 0.7667 - val_loss: 0.7059 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6009 - acc: 0.7333 - val_loss: 0.6947 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 85us/step - loss: 0.5757 - acc: 0.7444 - val_loss: 0.6964 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5561 - acc: 0.7833 - val_loss: 0.7002 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5787 - acc: 0.7222 - val_loss: 0.7042 - val_acc: 0.6000\n",
      "Epoch 69/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.5697 - acc: 0.7333 - val_loss: 0.7049 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5618 - acc: 0.7833 - val_loss: 0.7157 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5820 - acc: 0.7722 - val_loss: 0.7106 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5647 - acc: 0.7444 - val_loss: 0.7062 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5685 - acc: 0.7889 - val_loss: 0.7076 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5498 - acc: 0.7667 - val_loss: 0.6981 - val_acc: 0.5714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5607 - acc: 0.7667 - val_loss: 0.7014 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5572 - acc: 0.7889 - val_loss: 0.7128 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5593 - acc: 0.7667 - val_loss: 0.7012 - val_acc: 0.5857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5605 - acc: 0.7667 - val_loss: 0.6989 - val_acc: 0.5714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5633 - acc: 0.7611 - val_loss: 0.7182 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5283 - acc: 0.8167 - val_loss: 0.6996 - val_acc: 0.5571\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.7434 - acc: 0.5667 - val_loss: 0.7519 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7359 - acc: 0.5389 - val_loss: 0.7482 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7250 - acc: 0.5333 - val_loss: 0.7462 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7180 - acc: 0.5722 - val_loss: 0.7417 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7183 - acc: 0.5722 - val_loss: 0.7394 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7177 - acc: 0.5833 - val_loss: 0.7346 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7129 - acc: 0.5611 - val_loss: 0.7342 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7047 - acc: 0.5944 - val_loss: 0.7306 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7148 - acc: 0.5611 - val_loss: 0.7271 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7102 - acc: 0.5944 - val_loss: 0.7270 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7087 - acc: 0.5833 - val_loss: 0.7273 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7037 - acc: 0.5722 - val_loss: 0.7254 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7016 - acc: 0.5889 - val_loss: 0.7272 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6904 - acc: 0.6111 - val_loss: 0.7282 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6971 - acc: 0.5944 - val_loss: 0.7253 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6888 - acc: 0.5944 - val_loss: 0.7225 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6937 - acc: 0.6000 - val_loss: 0.7220 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6714 - acc: 0.6278 - val_loss: 0.7231 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6777 - acc: 0.6278 - val_loss: 0.7179 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6766 - acc: 0.6389 - val_loss: 0.7187 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6823 - acc: 0.6222 - val_loss: 0.7177 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6803 - acc: 0.6444 - val_loss: 0.7162 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6760 - acc: 0.6167 - val_loss: 0.7124 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6642 - acc: 0.6333 - val_loss: 0.7131 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6694 - acc: 0.6389 - val_loss: 0.7129 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6635 - acc: 0.6833 - val_loss: 0.7113 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6723 - acc: 0.6278 - val_loss: 0.7114 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6625 - acc: 0.6333 - val_loss: 0.7059 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6532 - acc: 0.7000 - val_loss: 0.7031 - val_acc: 0.6143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6451 - acc: 0.6778 - val_loss: 0.7000 - val_acc: 0.6429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6539 - acc: 0.7222 - val_loss: 0.7028 - val_acc: 0.6000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6568 - acc: 0.6667 - val_loss: 0.7013 - val_acc: 0.6143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6540 - acc: 0.7111 - val_loss: 0.6976 - val_acc: 0.6429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6410 - acc: 0.7278 - val_loss: 0.6961 - val_acc: 0.6571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6362 - acc: 0.7167 - val_loss: 0.6926 - val_acc: 0.6286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6479 - acc: 0.7167 - val_loss: 0.6971 - val_acc: 0.6429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6346 - acc: 0.7389 - val_loss: 0.6939 - val_acc: 0.6429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6355 - acc: 0.7278 - val_loss: 0.6928 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6335 - acc: 0.7111 - val_loss: 0.6943 - val_acc: 0.6714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6357 - acc: 0.7000 - val_loss: 0.6883 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6345 - acc: 0.7167 - val_loss: 0.6883 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6414 - acc: 0.7000 - val_loss: 0.6899 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6329 - acc: 0.7500 - val_loss: 0.6964 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6420 - acc: 0.6778 - val_loss: 0.6925 - val_acc: 0.6714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6209 - acc: 0.7389 - val_loss: 0.6939 - val_acc: 0.6429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6250 - acc: 0.7278 - val_loss: 0.6911 - val_acc: 0.6429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6062 - acc: 0.7500 - val_loss: 0.6871 - val_acc: 0.6429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6020 - acc: 0.7556 - val_loss: 0.6848 - val_acc: 0.6429\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.6068 - acc: 0.7333 - val_loss: 0.6895 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6026 - acc: 0.7611 - val_loss: 0.6837 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5922 - acc: 0.7500 - val_loss: 0.6867 - val_acc: 0.6429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6002 - acc: 0.7667 - val_loss: 0.6873 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5981 - acc: 0.7222 - val_loss: 0.6949 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.6014 - acc: 0.7222 - val_loss: 0.6889 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6064 - acc: 0.7278 - val_loss: 0.6935 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5807 - acc: 0.7444 - val_loss: 0.6882 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5968 - acc: 0.7333 - val_loss: 0.6913 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5884 - acc: 0.7500 - val_loss: 0.6898 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5901 - acc: 0.7278 - val_loss: 0.6884 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5802 - acc: 0.7444 - val_loss: 0.6846 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5669 - acc: 0.7778 - val_loss: 0.6842 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5599 - acc: 0.8000 - val_loss: 0.6906 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5854 - acc: 0.7222 - val_loss: 0.6836 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5663 - acc: 0.7278 - val_loss: 0.6948 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5795 - acc: 0.7556 - val_loss: 0.6894 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5821 - acc: 0.7444 - val_loss: 0.6912 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5629 - acc: 0.7500 - val_loss: 0.6912 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5598 - acc: 0.7278 - val_loss: 0.6778 - val_acc: 0.6286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5621 - acc: 0.7833 - val_loss: 0.6797 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5604 - acc: 0.7389 - val_loss: 0.6825 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5601 - acc: 0.7556 - val_loss: 0.6903 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5420 - acc: 0.8056 - val_loss: 0.6830 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5460 - acc: 0.7889 - val_loss: 0.6868 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5404 - acc: 0.7778 - val_loss: 0.6776 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5611 - acc: 0.7444 - val_loss: 0.6803 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5547 - acc: 0.7611 - val_loss: 0.6904 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5469 - acc: 0.7833 - val_loss: 0.6902 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5358 - acc: 0.7667 - val_loss: 0.6893 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5333 - acc: 0.7944 - val_loss: 0.6955 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5282 - acc: 0.7667 - val_loss: 0.6825 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 8ms/step - loss: 0.7770 - acc: 0.5389 - val_loss: 0.8014 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7460 - acc: 0.5278 - val_loss: 0.7830 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7297 - acc: 0.5500 - val_loss: 0.7735 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7296 - acc: 0.5389 - val_loss: 0.7670 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7327 - acc: 0.5556 - val_loss: 0.7624 - val_acc: 0.4857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7256 - acc: 0.5667 - val_loss: 0.7594 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7211 - acc: 0.5722 - val_loss: 0.7574 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7189 - acc: 0.5556 - val_loss: 0.7542 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7194 - acc: 0.5722 - val_loss: 0.7531 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7192 - acc: 0.5056 - val_loss: 0.7532 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7143 - acc: 0.5444 - val_loss: 0.7504 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7078 - acc: 0.5944 - val_loss: 0.7514 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 90us/step - loss: 0.7124 - acc: 0.5611 - val_loss: 0.7522 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7091 - acc: 0.5667 - val_loss: 0.7522 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7111 - acc: 0.5778 - val_loss: 0.7500 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7055 - acc: 0.5778 - val_loss: 0.7467 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6967 - acc: 0.5667 - val_loss: 0.7462 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7029 - acc: 0.6000 - val_loss: 0.7446 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6954 - acc: 0.6056 - val_loss: 0.7446 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6961 - acc: 0.6222 - val_loss: 0.7475 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7013 - acc: 0.5833 - val_loss: 0.7452 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7020 - acc: 0.5889 - val_loss: 0.7422 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6859 - acc: 0.6278 - val_loss: 0.7424 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6841 - acc: 0.6278 - val_loss: 0.7435 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6878 - acc: 0.6056 - val_loss: 0.7431 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6775 - acc: 0.6111 - val_loss: 0.7442 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6801 - acc: 0.6444 - val_loss: 0.7453 - val_acc: 0.5286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6759 - acc: 0.6111 - val_loss: 0.7441 - val_acc: 0.5571\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6729 - acc: 0.6556 - val_loss: 0.7437 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6783 - acc: 0.6278 - val_loss: 0.7428 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6692 - acc: 0.6500 - val_loss: 0.7407 - val_acc: 0.5286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6773 - acc: 0.6333 - val_loss: 0.7415 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6750 - acc: 0.6556 - val_loss: 0.7405 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6638 - acc: 0.6611 - val_loss: 0.7405 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6594 - acc: 0.6333 - val_loss: 0.7387 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6589 - acc: 0.6722 - val_loss: 0.7400 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6611 - acc: 0.6278 - val_loss: 0.7382 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6568 - acc: 0.6500 - val_loss: 0.7394 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6633 - acc: 0.6500 - val_loss: 0.7397 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6532 - acc: 0.6667 - val_loss: 0.7403 - val_acc: 0.5143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6456 - acc: 0.6833 - val_loss: 0.7391 - val_acc: 0.5143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6436 - acc: 0.6833 - val_loss: 0.7383 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6492 - acc: 0.6556 - val_loss: 0.7382 - val_acc: 0.5429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6577 - acc: 0.6944 - val_loss: 0.7376 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6488 - acc: 0.6611 - val_loss: 0.7398 - val_acc: 0.5143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6372 - acc: 0.6667 - val_loss: 0.7394 - val_acc: 0.5286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6374 - acc: 0.6722 - val_loss: 0.7388 - val_acc: 0.5429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6251 - acc: 0.7056 - val_loss: 0.7422 - val_acc: 0.5286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6186 - acc: 0.6667 - val_loss: 0.7418 - val_acc: 0.5429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6278 - acc: 0.7056 - val_loss: 0.7395 - val_acc: 0.5429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6169 - acc: 0.7222 - val_loss: 0.7409 - val_acc: 0.5429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6323 - acc: 0.6833 - val_loss: 0.7375 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6210 - acc: 0.7278 - val_loss: 0.7399 - val_acc: 0.5429\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6184 - acc: 0.7278 - val_loss: 0.7405 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6218 - acc: 0.7222 - val_loss: 0.7408 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6128 - acc: 0.7389 - val_loss: 0.7436 - val_acc: 0.5571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6206 - acc: 0.6944 - val_loss: 0.7415 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6094 - acc: 0.7556 - val_loss: 0.7448 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6203 - acc: 0.6722 - val_loss: 0.7418 - val_acc: 0.5714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6113 - acc: 0.7000 - val_loss: 0.7365 - val_acc: 0.5714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6170 - acc: 0.7167 - val_loss: 0.7401 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6106 - acc: 0.7111 - val_loss: 0.7438 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6015 - acc: 0.7167 - val_loss: 0.7414 - val_acc: 0.5571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6096 - acc: 0.7222 - val_loss: 0.7402 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5890 - acc: 0.7722 - val_loss: 0.7389 - val_acc: 0.5857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5907 - acc: 0.7333 - val_loss: 0.7408 - val_acc: 0.5714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5806 - acc: 0.7611 - val_loss: 0.7423 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5741 - acc: 0.8056 - val_loss: 0.7493 - val_acc: 0.5571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5934 - acc: 0.7333 - val_loss: 0.7448 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5750 - acc: 0.7444 - val_loss: 0.7476 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5679 - acc: 0.7778 - val_loss: 0.7443 - val_acc: 0.5857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5569 - acc: 0.8056 - val_loss: 0.7438 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5944 - acc: 0.7000 - val_loss: 0.7404 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5618 - acc: 0.7944 - val_loss: 0.7500 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5776 - acc: 0.7444 - val_loss: 0.7516 - val_acc: 0.5857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5583 - acc: 0.7778 - val_loss: 0.7517 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5873 - acc: 0.7222 - val_loss: 0.7548 - val_acc: 0.5714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5643 - acc: 0.7778 - val_loss: 0.7511 - val_acc: 0.5714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.5638 - acc: 0.7444 - val_loss: 0.7528 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5503 - acc: 0.8000 - val_loss: 0.7538 - val_acc: 0.5571\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.7552 - acc: 0.5333 - val_loss: 0.7763 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7464 - acc: 0.5389 - val_loss: 0.7704 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7335 - acc: 0.5500 - val_loss: 0.7633 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7509 - acc: 0.5222 - val_loss: 0.7629 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.7378 - acc: 0.5389 - val_loss: 0.7592 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7254 - acc: 0.5611 - val_loss: 0.7562 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7204 - acc: 0.5556 - val_loss: 0.7533 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7111 - acc: 0.5722 - val_loss: 0.7518 - val_acc: 0.5143\n",
      "Epoch 9/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.7213 - acc: 0.5722 - val_loss: 0.7499 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7142 - acc: 0.5778 - val_loss: 0.7488 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 91us/step - loss: 0.6973 - acc: 0.6500 - val_loss: 0.7463 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7088 - acc: 0.6056 - val_loss: 0.7466 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7086 - acc: 0.6222 - val_loss: 0.7443 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7002 - acc: 0.5833 - val_loss: 0.7442 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7130 - acc: 0.5889 - val_loss: 0.7474 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6954 - acc: 0.6111 - val_loss: 0.7464 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.6872 - acc: 0.6167 - val_loss: 0.7454 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6906 - acc: 0.6111 - val_loss: 0.7464 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7018 - acc: 0.5722 - val_loss: 0.7435 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6904 - acc: 0.6000 - val_loss: 0.7413 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6794 - acc: 0.6000 - val_loss: 0.7364 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6730 - acc: 0.6722 - val_loss: 0.7331 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 80us/step - loss: 0.6881 - acc: 0.6722 - val_loss: 0.7350 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6803 - acc: 0.6500 - val_loss: 0.7332 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6784 - acc: 0.6611 - val_loss: 0.7362 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6746 - acc: 0.6889 - val_loss: 0.7344 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6765 - acc: 0.6444 - val_loss: 0.7294 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6712 - acc: 0.6556 - val_loss: 0.7291 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6654 - acc: 0.6500 - val_loss: 0.7282 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6631 - acc: 0.6667 - val_loss: 0.7272 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6555 - acc: 0.6778 - val_loss: 0.7281 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6660 - acc: 0.6556 - val_loss: 0.7273 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6570 - acc: 0.7111 - val_loss: 0.7264 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6689 - acc: 0.6611 - val_loss: 0.7267 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6612 - acc: 0.6944 - val_loss: 0.7273 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6342 - acc: 0.7333 - val_loss: 0.7257 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6405 - acc: 0.7056 - val_loss: 0.7273 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6381 - acc: 0.6944 - val_loss: 0.7226 - val_acc: 0.6000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6384 - acc: 0.7167 - val_loss: 0.7202 - val_acc: 0.6143\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6222 - acc: 0.7556 - val_loss: 0.7251 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6469 - acc: 0.7111 - val_loss: 0.7197 - val_acc: 0.5857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6384 - acc: 0.7000 - val_loss: 0.7191 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6186 - acc: 0.7222 - val_loss: 0.7240 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6088 - acc: 0.7667 - val_loss: 0.7224 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6112 - acc: 0.7278 - val_loss: 0.7198 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5952 - acc: 0.7667 - val_loss: 0.7198 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6126 - acc: 0.7444 - val_loss: 0.7259 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6073 - acc: 0.7333 - val_loss: 0.7209 - val_acc: 0.5714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6048 - acc: 0.7611 - val_loss: 0.7200 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6084 - acc: 0.7333 - val_loss: 0.7189 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5946 - acc: 0.7889 - val_loss: 0.7197 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6106 - acc: 0.7333 - val_loss: 0.7286 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5990 - acc: 0.7389 - val_loss: 0.7316 - val_acc: 0.5857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6076 - acc: 0.7444 - val_loss: 0.7339 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5894 - acc: 0.7500 - val_loss: 0.7204 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5787 - acc: 0.7611 - val_loss: 0.7156 - val_acc: 0.6000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5865 - acc: 0.7722 - val_loss: 0.7231 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5882 - acc: 0.7611 - val_loss: 0.7248 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5677 - acc: 0.7889 - val_loss: 0.7210 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5777 - acc: 0.7556 - val_loss: 0.7167 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5749 - acc: 0.7722 - val_loss: 0.7245 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5685 - acc: 0.7944 - val_loss: 0.7295 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5551 - acc: 0.7722 - val_loss: 0.7318 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5885 - acc: 0.7389 - val_loss: 0.7262 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5748 - acc: 0.7500 - val_loss: 0.7301 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5577 - acc: 0.7667 - val_loss: 0.7395 - val_acc: 0.5857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5667 - acc: 0.7500 - val_loss: 0.7329 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5468 - acc: 0.7667 - val_loss: 0.7206 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5524 - acc: 0.7944 - val_loss: 0.7251 - val_acc: 0.6000\n",
      "Epoch 70/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.5620 - acc: 0.7833 - val_loss: 0.7244 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5630 - acc: 0.7500 - val_loss: 0.7214 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5382 - acc: 0.8222 - val_loss: 0.7250 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5437 - acc: 0.7944 - val_loss: 0.7293 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5452 - acc: 0.7833 - val_loss: 0.7254 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5439 - acc: 0.8000 - val_loss: 0.7310 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5419 - acc: 0.8000 - val_loss: 0.7318 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5477 - acc: 0.7722 - val_loss: 0.7450 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5283 - acc: 0.8111 - val_loss: 0.7339 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5313 - acc: 0.7889 - val_loss: 0.7309 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5244 - acc: 0.8056 - val_loss: 0.7348 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.7566 - acc: 0.5389 - val_loss: 0.7527 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7334 - acc: 0.5278 - val_loss: 0.7499 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7370 - acc: 0.5167 - val_loss: 0.7475 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7232 - acc: 0.5556 - val_loss: 0.7452 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7014 - acc: 0.5944 - val_loss: 0.7419 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7197 - acc: 0.5833 - val_loss: 0.7417 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7025 - acc: 0.5944 - val_loss: 0.7412 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7021 - acc: 0.5833 - val_loss: 0.7422 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7020 - acc: 0.6222 - val_loss: 0.7428 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6989 - acc: 0.5889 - val_loss: 0.7367 - val_acc: 0.4857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7098 - acc: 0.5722 - val_loss: 0.7384 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7040 - acc: 0.6000 - val_loss: 0.7368 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7112 - acc: 0.5500 - val_loss: 0.7296 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6922 - acc: 0.6389 - val_loss: 0.7315 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6947 - acc: 0.6056 - val_loss: 0.7306 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6855 - acc: 0.6667 - val_loss: 0.7307 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6752 - acc: 0.6444 - val_loss: 0.7266 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6815 - acc: 0.6667 - val_loss: 0.7298 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6785 - acc: 0.6278 - val_loss: 0.7268 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6789 - acc: 0.6167 - val_loss: 0.7276 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6799 - acc: 0.6667 - val_loss: 0.7270 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6755 - acc: 0.6556 - val_loss: 0.7213 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6638 - acc: 0.6889 - val_loss: 0.7228 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6705 - acc: 0.6889 - val_loss: 0.7194 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6791 - acc: 0.6444 - val_loss: 0.7181 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6647 - acc: 0.6500 - val_loss: 0.7201 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6654 - acc: 0.6833 - val_loss: 0.7170 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6532 - acc: 0.6889 - val_loss: 0.7114 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 136us/step - loss: 0.6437 - acc: 0.7056 - val_loss: 0.7159 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6620 - acc: 0.7000 - val_loss: 0.7217 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6378 - acc: 0.7167 - val_loss: 0.7172 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6384 - acc: 0.7000 - val_loss: 0.7150 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6501 - acc: 0.7000 - val_loss: 0.7144 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6512 - acc: 0.6833 - val_loss: 0.7064 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6551 - acc: 0.6889 - val_loss: 0.7033 - val_acc: 0.6286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6295 - acc: 0.7222 - val_loss: 0.7026 - val_acc: 0.6429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6344 - acc: 0.7056 - val_loss: 0.6995 - val_acc: 0.6000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6373 - acc: 0.7167 - val_loss: 0.6996 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6181 - acc: 0.6889 - val_loss: 0.6958 - val_acc: 0.6286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6369 - acc: 0.7111 - val_loss: 0.6987 - val_acc: 0.6143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6239 - acc: 0.7222 - val_loss: 0.6944 - val_acc: 0.6429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6136 - acc: 0.7667 - val_loss: 0.6995 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6363 - acc: 0.6833 - val_loss: 0.6987 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6222 - acc: 0.7500 - val_loss: 0.7003 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6331 - acc: 0.7278 - val_loss: 0.6969 - val_acc: 0.6571\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6003 - acc: 0.7500 - val_loss: 0.7031 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6105 - acc: 0.7333 - val_loss: 0.6984 - val_acc: 0.6571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6162 - acc: 0.7278 - val_loss: 0.7010 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6088 - acc: 0.7389 - val_loss: 0.7002 - val_acc: 0.6429\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 104us/step - loss: 0.6002 - acc: 0.7611 - val_loss: 0.7017 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5901 - acc: 0.7611 - val_loss: 0.6942 - val_acc: 0.6429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6000 - acc: 0.7222 - val_loss: 0.7016 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5896 - acc: 0.7722 - val_loss: 0.6925 - val_acc: 0.6429\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5774 - acc: 0.8000 - val_loss: 0.6927 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5865 - acc: 0.7500 - val_loss: 0.6899 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5936 - acc: 0.7444 - val_loss: 0.6886 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5763 - acc: 0.7500 - val_loss: 0.6889 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5773 - acc: 0.7444 - val_loss: 0.6999 - val_acc: 0.6571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5891 - acc: 0.7611 - val_loss: 0.6992 - val_acc: 0.6571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5588 - acc: 0.7889 - val_loss: 0.6910 - val_acc: 0.6429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5768 - acc: 0.7500 - val_loss: 0.7002 - val_acc: 0.6714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5770 - acc: 0.7389 - val_loss: 0.6947 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5638 - acc: 0.7389 - val_loss: 0.6959 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5547 - acc: 0.7722 - val_loss: 0.6918 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5460 - acc: 0.7611 - val_loss: 0.7029 - val_acc: 0.6429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5475 - acc: 0.7944 - val_loss: 0.6969 - val_acc: 0.6429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5451 - acc: 0.7778 - val_loss: 0.7011 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5603 - acc: 0.7500 - val_loss: 0.7049 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5601 - acc: 0.7556 - val_loss: 0.7098 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5525 - acc: 0.7556 - val_loss: 0.6943 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5487 - acc: 0.7889 - val_loss: 0.7022 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5579 - acc: 0.7667 - val_loss: 0.7169 - val_acc: 0.6571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5374 - acc: 0.7778 - val_loss: 0.7127 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5409 - acc: 0.7944 - val_loss: 0.7019 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5388 - acc: 0.7778 - val_loss: 0.7112 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5360 - acc: 0.8000 - val_loss: 0.7082 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5393 - acc: 0.8222 - val_loss: 0.7133 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5384 - acc: 0.7667 - val_loss: 0.7039 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5051 - acc: 0.8111 - val_loss: 0.7001 - val_acc: 0.6429\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5218 - acc: 0.7944 - val_loss: 0.7131 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 11ms/step - loss: 0.7676 - acc: 0.5000 - val_loss: 0.7659 - val_acc: 0.4857\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.7432 - acc: 0.5556 - val_loss: 0.7701 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7392 - acc: 0.5333 - val_loss: 0.7717 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7498 - acc: 0.5667 - val_loss: 0.7635 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7248 - acc: 0.6111 - val_loss: 0.7618 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7286 - acc: 0.6000 - val_loss: 0.7606 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7214 - acc: 0.6167 - val_loss: 0.7598 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7172 - acc: 0.6278 - val_loss: 0.7617 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7230 - acc: 0.5833 - val_loss: 0.7561 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7105 - acc: 0.6222 - val_loss: 0.7548 - val_acc: 0.5571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7278 - acc: 0.6000 - val_loss: 0.7545 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7133 - acc: 0.6111 - val_loss: 0.7525 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7117 - acc: 0.6056 - val_loss: 0.7527 - val_acc: 0.5714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7107 - acc: 0.6333 - val_loss: 0.7550 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7081 - acc: 0.5889 - val_loss: 0.7560 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7083 - acc: 0.5889 - val_loss: 0.7483 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7056 - acc: 0.6222 - val_loss: 0.7477 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6890 - acc: 0.6333 - val_loss: 0.7452 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6870 - acc: 0.6389 - val_loss: 0.7480 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6912 - acc: 0.6333 - val_loss: 0.7449 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6910 - acc: 0.6333 - val_loss: 0.7434 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6924 - acc: 0.6333 - val_loss: 0.7466 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6911 - acc: 0.6333 - val_loss: 0.7480 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6805 - acc: 0.6444 - val_loss: 0.7510 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6757 - acc: 0.6333 - val_loss: 0.7473 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6775 - acc: 0.6333 - val_loss: 0.7429 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6741 - acc: 0.6722 - val_loss: 0.7398 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6694 - acc: 0.7000 - val_loss: 0.7407 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6669 - acc: 0.6667 - val_loss: 0.7441 - val_acc: 0.5571\n",
      "Epoch 30/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6649 - acc: 0.6722 - val_loss: 0.7400 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6716 - acc: 0.6389 - val_loss: 0.7413 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6596 - acc: 0.6778 - val_loss: 0.7390 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6562 - acc: 0.6778 - val_loss: 0.7375 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6436 - acc: 0.7167 - val_loss: 0.7366 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6565 - acc: 0.6889 - val_loss: 0.7356 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6416 - acc: 0.7167 - val_loss: 0.7363 - val_acc: 0.5857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6501 - acc: 0.7000 - val_loss: 0.7372 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6559 - acc: 0.6556 - val_loss: 0.7371 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6435 - acc: 0.6778 - val_loss: 0.7392 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6452 - acc: 0.6833 - val_loss: 0.7308 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6355 - acc: 0.7056 - val_loss: 0.7293 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6369 - acc: 0.7278 - val_loss: 0.7307 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6301 - acc: 0.7222 - val_loss: 0.7356 - val_acc: 0.5857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6311 - acc: 0.6944 - val_loss: 0.7321 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6258 - acc: 0.7333 - val_loss: 0.7329 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6277 - acc: 0.7167 - val_loss: 0.7305 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6237 - acc: 0.7111 - val_loss: 0.7266 - val_acc: 0.5429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6164 - acc: 0.7611 - val_loss: 0.7275 - val_acc: 0.5429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6246 - acc: 0.7222 - val_loss: 0.7279 - val_acc: 0.5571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6115 - acc: 0.7722 - val_loss: 0.7289 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6127 - acc: 0.7389 - val_loss: 0.7242 - val_acc: 0.5286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6151 - acc: 0.7556 - val_loss: 0.7246 - val_acc: 0.5571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6084 - acc: 0.7222 - val_loss: 0.7231 - val_acc: 0.5429\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6097 - acc: 0.7389 - val_loss: 0.7266 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6017 - acc: 0.7444 - val_loss: 0.7261 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 81us/step - loss: 0.5936 - acc: 0.7556 - val_loss: 0.7260 - val_acc: 0.5571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6004 - acc: 0.7389 - val_loss: 0.7242 - val_acc: 0.5429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5967 - acc: 0.7500 - val_loss: 0.7241 - val_acc: 0.5429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5971 - acc: 0.7222 - val_loss: 0.7239 - val_acc: 0.5429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5847 - acc: 0.7722 - val_loss: 0.7245 - val_acc: 0.5429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5796 - acc: 0.7944 - val_loss: 0.7274 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5747 - acc: 0.7778 - val_loss: 0.7250 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5838 - acc: 0.7722 - val_loss: 0.7283 - val_acc: 0.5286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5632 - acc: 0.8000 - val_loss: 0.7302 - val_acc: 0.5429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5790 - acc: 0.7833 - val_loss: 0.7341 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5704 - acc: 0.7500 - val_loss: 0.7244 - val_acc: 0.5714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5671 - acc: 0.7944 - val_loss: 0.7242 - val_acc: 0.5571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5520 - acc: 0.7944 - val_loss: 0.7283 - val_acc: 0.5429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5486 - acc: 0.8000 - val_loss: 0.7324 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.5651 - acc: 0.7556 - val_loss: 0.7289 - val_acc: 0.5429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5737 - acc: 0.7556 - val_loss: 0.7295 - val_acc: 0.5571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5650 - acc: 0.8111 - val_loss: 0.7263 - val_acc: 0.5571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5436 - acc: 0.7667 - val_loss: 0.7275 - val_acc: 0.5571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5453 - acc: 0.7778 - val_loss: 0.7287 - val_acc: 0.5714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 81us/step - loss: 0.5392 - acc: 0.8056 - val_loss: 0.7419 - val_acc: 0.5714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5489 - acc: 0.7833 - val_loss: 0.7311 - val_acc: 0.5571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5315 - acc: 0.8000 - val_loss: 0.7281 - val_acc: 0.5571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5480 - acc: 0.7778 - val_loss: 0.7394 - val_acc: 0.5714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5318 - acc: 0.7944 - val_loss: 0.7340 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5366 - acc: 0.7889 - val_loss: 0.7337 - val_acc: 0.5571\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 10ms/step - loss: 0.8530 - acc: 0.4500 - val_loss: 0.7615 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7881 - acc: 0.4000 - val_loss: 0.7533 - val_acc: 0.4714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7643 - acc: 0.4944 - val_loss: 0.7495 - val_acc: 0.4429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7566 - acc: 0.5056 - val_loss: 0.7486 - val_acc: 0.4857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7466 - acc: 0.5833 - val_loss: 0.7506 - val_acc: 0.5286\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7299 - acc: 0.5333 - val_loss: 0.7502 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7304 - acc: 0.5444 - val_loss: 0.7478 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7330 - acc: 0.5444 - val_loss: 0.7489 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7263 - acc: 0.5111 - val_loss: 0.7490 - val_acc: 0.5143\n",
      "Epoch 10/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.7203 - acc: 0.5444 - val_loss: 0.7439 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7120 - acc: 0.5944 - val_loss: 0.7446 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7256 - acc: 0.5500 - val_loss: 0.7390 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7157 - acc: 0.5778 - val_loss: 0.7423 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7086 - acc: 0.5667 - val_loss: 0.7451 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7119 - acc: 0.5444 - val_loss: 0.7357 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7151 - acc: 0.5611 - val_loss: 0.7335 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7168 - acc: 0.5778 - val_loss: 0.7301 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6944 - acc: 0.6167 - val_loss: 0.7326 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7022 - acc: 0.5722 - val_loss: 0.7292 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6892 - acc: 0.5944 - val_loss: 0.7275 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7064 - acc: 0.5944 - val_loss: 0.7233 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6831 - acc: 0.6333 - val_loss: 0.7205 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6774 - acc: 0.6278 - val_loss: 0.7221 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6769 - acc: 0.6222 - val_loss: 0.7206 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6774 - acc: 0.6278 - val_loss: 0.7191 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6731 - acc: 0.6667 - val_loss: 0.7211 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 84us/step - loss: 0.6647 - acc: 0.6278 - val_loss: 0.7149 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6684 - acc: 0.6444 - val_loss: 0.7126 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6569 - acc: 0.6722 - val_loss: 0.7222 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6603 - acc: 0.6500 - val_loss: 0.7138 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6680 - acc: 0.6556 - val_loss: 0.7105 - val_acc: 0.5857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6454 - acc: 0.6833 - val_loss: 0.7068 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6470 - acc: 0.6889 - val_loss: 0.7087 - val_acc: 0.5857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 80us/step - loss: 0.6539 - acc: 0.6833 - val_loss: 0.7089 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6626 - acc: 0.6222 - val_loss: 0.7135 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6418 - acc: 0.6611 - val_loss: 0.7140 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6465 - acc: 0.6667 - val_loss: 0.7056 - val_acc: 0.6429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6310 - acc: 0.7056 - val_loss: 0.7019 - val_acc: 0.6429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6214 - acc: 0.7167 - val_loss: 0.7090 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6229 - acc: 0.7222 - val_loss: 0.7041 - val_acc: 0.6429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6214 - acc: 0.7000 - val_loss: 0.6972 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6366 - acc: 0.6667 - val_loss: 0.6927 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6123 - acc: 0.7444 - val_loss: 0.6876 - val_acc: 0.6286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6003 - acc: 0.7556 - val_loss: 0.6957 - val_acc: 0.6429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6158 - acc: 0.7222 - val_loss: 0.6909 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6182 - acc: 0.7222 - val_loss: 0.7056 - val_acc: 0.6429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6105 - acc: 0.7056 - val_loss: 0.7020 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6120 - acc: 0.7111 - val_loss: 0.6965 - val_acc: 0.6429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6013 - acc: 0.7500 - val_loss: 0.6905 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6003 - acc: 0.7222 - val_loss: 0.6913 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6069 - acc: 0.6778 - val_loss: 0.6854 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5955 - acc: 0.7167 - val_loss: 0.6900 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5925 - acc: 0.7167 - val_loss: 0.6845 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5954 - acc: 0.7333 - val_loss: 0.6826 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5802 - acc: 0.7778 - val_loss: 0.6823 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5902 - acc: 0.7500 - val_loss: 0.6890 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5797 - acc: 0.7278 - val_loss: 0.6803 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5866 - acc: 0.7222 - val_loss: 0.6846 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5815 - acc: 0.7556 - val_loss: 0.6795 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5578 - acc: 0.8167 - val_loss: 0.6848 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5706 - acc: 0.7444 - val_loss: 0.6892 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5706 - acc: 0.7611 - val_loss: 0.6884 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5736 - acc: 0.7611 - val_loss: 0.6904 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5661 - acc: 0.7722 - val_loss: 0.6985 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5783 - acc: 0.7444 - val_loss: 0.6881 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5626 - acc: 0.7722 - val_loss: 0.6879 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5604 - acc: 0.7556 - val_loss: 0.6883 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5390 - acc: 0.7833 - val_loss: 0.6836 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5466 - acc: 0.7611 - val_loss: 0.6881 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5444 - acc: 0.8000 - val_loss: 0.6940 - val_acc: 0.6143\n",
      "Epoch 71/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.5611 - acc: 0.7611 - val_loss: 0.6893 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5416 - acc: 0.7889 - val_loss: 0.6866 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5427 - acc: 0.7667 - val_loss: 0.6868 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5425 - acc: 0.7500 - val_loss: 0.6948 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5470 - acc: 0.7667 - val_loss: 0.6885 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5357 - acc: 0.8056 - val_loss: 0.6862 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5256 - acc: 0.7667 - val_loss: 0.6834 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5218 - acc: 0.7722 - val_loss: 0.7054 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5317 - acc: 0.7944 - val_loss: 0.7104 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5300 - acc: 0.7611 - val_loss: 0.6868 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 10ms/step - loss: 0.7450 - acc: 0.5167 - val_loss: 0.7500 - val_acc: 0.5429\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7257 - acc: 0.5500 - val_loss: 0.7504 - val_acc: 0.5714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 81us/step - loss: 0.7225 - acc: 0.5333 - val_loss: 0.7491 - val_acc: 0.5714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7217 - acc: 0.5611 - val_loss: 0.7496 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7238 - acc: 0.5278 - val_loss: 0.7481 - val_acc: 0.5714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7148 - acc: 0.5444 - val_loss: 0.7466 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7170 - acc: 0.5556 - val_loss: 0.7446 - val_acc: 0.5714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7109 - acc: 0.5444 - val_loss: 0.7432 - val_acc: 0.5857\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7205 - acc: 0.5778 - val_loss: 0.7440 - val_acc: 0.5571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7099 - acc: 0.5667 - val_loss: 0.7426 - val_acc: 0.5571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7033 - acc: 0.5667 - val_loss: 0.7427 - val_acc: 0.5571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.7007 - acc: 0.5889 - val_loss: 0.7427 - val_acc: 0.5571\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7022 - acc: 0.5944 - val_loss: 0.7415 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7045 - acc: 0.5611 - val_loss: 0.7409 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7011 - acc: 0.5667 - val_loss: 0.7390 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7058 - acc: 0.5611 - val_loss: 0.7368 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6995 - acc: 0.5889 - val_loss: 0.7369 - val_acc: 0.5714\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6981 - acc: 0.5722 - val_loss: 0.7376 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6907 - acc: 0.6000 - val_loss: 0.7351 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6834 - acc: 0.5833 - val_loss: 0.7327 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6856 - acc: 0.6167 - val_loss: 0.7319 - val_acc: 0.5714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6838 - acc: 0.5944 - val_loss: 0.7308 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6835 - acc: 0.6278 - val_loss: 0.7285 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6834 - acc: 0.6222 - val_loss: 0.7268 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6792 - acc: 0.6444 - val_loss: 0.7251 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6783 - acc: 0.6611 - val_loss: 0.7259 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6681 - acc: 0.6333 - val_loss: 0.7242 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6761 - acc: 0.6500 - val_loss: 0.7219 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6752 - acc: 0.6389 - val_loss: 0.7206 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6655 - acc: 0.6444 - val_loss: 0.7217 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6629 - acc: 0.6500 - val_loss: 0.7195 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6611 - acc: 0.6722 - val_loss: 0.7181 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6562 - acc: 0.6722 - val_loss: 0.7169 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6643 - acc: 0.6556 - val_loss: 0.7194 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6533 - acc: 0.6889 - val_loss: 0.7175 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6495 - acc: 0.6889 - val_loss: 0.7183 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6522 - acc: 0.7000 - val_loss: 0.7172 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6425 - acc: 0.6778 - val_loss: 0.7171 - val_acc: 0.5857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6473 - acc: 0.6667 - val_loss: 0.7113 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6408 - acc: 0.7000 - val_loss: 0.7152 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6435 - acc: 0.6889 - val_loss: 0.7152 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6380 - acc: 0.6889 - val_loss: 0.7104 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6307 - acc: 0.7000 - val_loss: 0.7117 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6323 - acc: 0.7056 - val_loss: 0.7073 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6355 - acc: 0.6889 - val_loss: 0.7070 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6197 - acc: 0.7444 - val_loss: 0.7128 - val_acc: 0.5571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6333 - acc: 0.7333 - val_loss: 0.7068 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 266us/step - loss: 0.6077 - acc: 0.7667 - val_loss: 0.7103 - val_acc: 0.5571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6214 - acc: 0.7278 - val_loss: 0.7083 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6115 - acc: 0.7222 - val_loss: 0.7060 - val_acc: 0.5714\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.6205 - acc: 0.7500 - val_loss: 0.7058 - val_acc: 0.5571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6065 - acc: 0.7389 - val_loss: 0.7048 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6193 - acc: 0.7278 - val_loss: 0.7034 - val_acc: 0.5714\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6035 - acc: 0.7611 - val_loss: 0.7021 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6036 - acc: 0.7500 - val_loss: 0.7029 - val_acc: 0.5714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5990 - acc: 0.7722 - val_loss: 0.7005 - val_acc: 0.5714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6085 - acc: 0.7611 - val_loss: 0.7021 - val_acc: 0.5857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5930 - acc: 0.8111 - val_loss: 0.7006 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6020 - acc: 0.7667 - val_loss: 0.6976 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5859 - acc: 0.7722 - val_loss: 0.6982 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5855 - acc: 0.7611 - val_loss: 0.7031 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5857 - acc: 0.7722 - val_loss: 0.7037 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5748 - acc: 0.7778 - val_loss: 0.7060 - val_acc: 0.5857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 183us/step - loss: 0.5825 - acc: 0.7833 - val_loss: 0.6973 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5698 - acc: 0.7667 - val_loss: 0.7013 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5730 - acc: 0.7944 - val_loss: 0.6996 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5654 - acc: 0.7889 - val_loss: 0.6983 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 205us/step - loss: 0.5675 - acc: 0.7611 - val_loss: 0.7042 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 266us/step - loss: 0.5669 - acc: 0.7722 - val_loss: 0.7049 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 366us/step - loss: 0.5633 - acc: 0.7556 - val_loss: 0.7038 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 194us/step - loss: 0.5606 - acc: 0.7778 - val_loss: 0.7016 - val_acc: 0.5857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 172us/step - loss: 0.5546 - acc: 0.7833 - val_loss: 0.6999 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 222us/step - loss: 0.5594 - acc: 0.7556 - val_loss: 0.7077 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 216us/step - loss: 0.5467 - acc: 0.7889 - val_loss: 0.7042 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 194us/step - loss: 0.5434 - acc: 0.8167 - val_loss: 0.7009 - val_acc: 0.5857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 244us/step - loss: 0.5510 - acc: 0.8000 - val_loss: 0.7023 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 188us/step - loss: 0.5491 - acc: 0.7500 - val_loss: 0.7015 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 294us/step - loss: 0.5434 - acc: 0.7778 - val_loss: 0.7073 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 200us/step - loss: 0.5235 - acc: 0.8222 - val_loss: 0.7080 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 180us/step - loss: 0.5427 - acc: 0.7778 - val_loss: 0.7050 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 175us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 11ms/step - loss: 0.7491 - acc: 0.5278 - val_loss: 0.7723 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 82us/step - loss: 0.7350 - acc: 0.5278 - val_loss: 0.7652 - val_acc: 0.4857\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7344 - acc: 0.5444 - val_loss: 0.7656 - val_acc: 0.4857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7339 - acc: 0.5444 - val_loss: 0.7583 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7203 - acc: 0.5611 - val_loss: 0.7554 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7191 - acc: 0.5944 - val_loss: 0.7540 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7152 - acc: 0.5778 - val_loss: 0.7546 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 82us/step - loss: 0.7010 - acc: 0.5778 - val_loss: 0.7484 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6978 - acc: 0.5611 - val_loss: 0.7473 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7078 - acc: 0.5722 - val_loss: 0.7435 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6938 - acc: 0.5833 - val_loss: 0.7429 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6972 - acc: 0.5722 - val_loss: 0.7416 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6960 - acc: 0.6111 - val_loss: 0.7372 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6885 - acc: 0.6222 - val_loss: 0.7347 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 75us/step - loss: 0.6813 - acc: 0.6500 - val_loss: 0.7332 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6816 - acc: 0.6111 - val_loss: 0.7292 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6830 - acc: 0.6389 - val_loss: 0.7239 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6731 - acc: 0.6556 - val_loss: 0.7232 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6855 - acc: 0.6500 - val_loss: 0.7233 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6652 - acc: 0.6500 - val_loss: 0.7227 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6676 - acc: 0.6889 - val_loss: 0.7277 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 79us/step - loss: 0.6695 - acc: 0.6722 - val_loss: 0.7272 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6543 - acc: 0.6556 - val_loss: 0.7237 - val_acc: 0.5429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6515 - acc: 0.6722 - val_loss: 0.7257 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6625 - acc: 0.6222 - val_loss: 0.7202 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6605 - acc: 0.6667 - val_loss: 0.7236 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6508 - acc: 0.6944 - val_loss: 0.7217 - val_acc: 0.6000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6523 - acc: 0.6667 - val_loss: 0.7204 - val_acc: 0.6000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6305 - acc: 0.7222 - val_loss: 0.7256 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6441 - acc: 0.6833 - val_loss: 0.7252 - val_acc: 0.5857\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 78us/step - loss: 0.6572 - acc: 0.6500 - val_loss: 0.7252 - val_acc: 0.5857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6461 - acc: 0.6722 - val_loss: 0.7239 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6283 - acc: 0.6667 - val_loss: 0.7234 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6374 - acc: 0.7278 - val_loss: 0.7238 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6389 - acc: 0.6556 - val_loss: 0.7265 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6218 - acc: 0.6778 - val_loss: 0.7248 - val_acc: 0.5429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6200 - acc: 0.6944 - val_loss: 0.7242 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6216 - acc: 0.7167 - val_loss: 0.7228 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6239 - acc: 0.7000 - val_loss: 0.7176 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6258 - acc: 0.7056 - val_loss: 0.7202 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6254 - acc: 0.6833 - val_loss: 0.7237 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6213 - acc: 0.6833 - val_loss: 0.7250 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6226 - acc: 0.6944 - val_loss: 0.7198 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6040 - acc: 0.7222 - val_loss: 0.7188 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6080 - acc: 0.7333 - val_loss: 0.7171 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6022 - acc: 0.7278 - val_loss: 0.7181 - val_acc: 0.5857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6107 - acc: 0.7278 - val_loss: 0.7201 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6081 - acc: 0.7278 - val_loss: 0.7183 - val_acc: 0.5857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6019 - acc: 0.7222 - val_loss: 0.7214 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6032 - acc: 0.7056 - val_loss: 0.7201 - val_acc: 0.5571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5988 - acc: 0.7167 - val_loss: 0.7213 - val_acc: 0.5571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5898 - acc: 0.7333 - val_loss: 0.7212 - val_acc: 0.5571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5878 - acc: 0.7222 - val_loss: 0.7252 - val_acc: 0.5714\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5913 - acc: 0.7444 - val_loss: 0.7174 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 183us/step - loss: 0.5779 - acc: 0.7556 - val_loss: 0.7222 - val_acc: 0.5714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5847 - acc: 0.7556 - val_loss: 0.7224 - val_acc: 0.6000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5778 - acc: 0.7722 - val_loss: 0.7221 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5786 - acc: 0.7500 - val_loss: 0.7319 - val_acc: 0.5429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5801 - acc: 0.7444 - val_loss: 0.7221 - val_acc: 0.6000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5690 - acc: 0.7500 - val_loss: 0.7224 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5821 - acc: 0.7444 - val_loss: 0.7218 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5558 - acc: 0.7778 - val_loss: 0.7254 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5806 - acc: 0.7444 - val_loss: 0.7221 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5691 - acc: 0.7556 - val_loss: 0.7301 - val_acc: 0.5571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5672 - acc: 0.7611 - val_loss: 0.7219 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5587 - acc: 0.7667 - val_loss: 0.7301 - val_acc: 0.5714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5481 - acc: 0.7778 - val_loss: 0.7320 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5497 - acc: 0.7556 - val_loss: 0.7256 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5563 - acc: 0.7444 - val_loss: 0.7260 - val_acc: 0.5857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5400 - acc: 0.7889 - val_loss: 0.7320 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5473 - acc: 0.7556 - val_loss: 0.7381 - val_acc: 0.5714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5426 - acc: 0.7944 - val_loss: 0.7330 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5355 - acc: 0.7833 - val_loss: 0.7289 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5533 - acc: 0.7667 - val_loss: 0.7339 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5312 - acc: 0.7667 - val_loss: 0.7305 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5352 - acc: 0.7833 - val_loss: 0.7411 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5238 - acc: 0.7889 - val_loss: 0.7515 - val_acc: 0.5857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 66us/step - loss: 0.5458 - acc: 0.7611 - val_loss: 0.7521 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5299 - acc: 0.7667 - val_loss: 0.7396 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5386 - acc: 0.8000 - val_loss: 0.7494 - val_acc: 0.5714\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 10ms/step - loss: 0.8318 - acc: 0.4611 - val_loss: 0.7662 - val_acc: 0.4857\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7809 - acc: 0.4278 - val_loss: 0.7650 - val_acc: 0.4429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7631 - acc: 0.5167 - val_loss: 0.7680 - val_acc: 0.4429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7393 - acc: 0.5444 - val_loss: 0.7683 - val_acc: 0.4571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7511 - acc: 0.5056 - val_loss: 0.7688 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7300 - acc: 0.5556 - val_loss: 0.7698 - val_acc: 0.4857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7349 - acc: 0.5611 - val_loss: 0.7694 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7301 - acc: 0.5722 - val_loss: 0.7665 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7285 - acc: 0.5944 - val_loss: 0.7668 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7299 - acc: 0.6000 - val_loss: 0.7718 - val_acc: 0.5000\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.7202 - acc: 0.5889 - val_loss: 0.7691 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7323 - acc: 0.5556 - val_loss: 0.7698 - val_acc: 0.4857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7254 - acc: 0.5889 - val_loss: 0.7667 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7244 - acc: 0.5944 - val_loss: 0.7640 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7199 - acc: 0.5778 - val_loss: 0.7644 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7132 - acc: 0.5778 - val_loss: 0.7603 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7007 - acc: 0.6056 - val_loss: 0.7590 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7123 - acc: 0.5833 - val_loss: 0.7570 - val_acc: 0.4857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7006 - acc: 0.6222 - val_loss: 0.7580 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7045 - acc: 0.6056 - val_loss: 0.7565 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.7071 - acc: 0.5778 - val_loss: 0.7562 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6898 - acc: 0.6389 - val_loss: 0.7542 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.7030 - acc: 0.6111 - val_loss: 0.7538 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6873 - acc: 0.6611 - val_loss: 0.7502 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6904 - acc: 0.6667 - val_loss: 0.7500 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6822 - acc: 0.6444 - val_loss: 0.7518 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6869 - acc: 0.6500 - val_loss: 0.7472 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6705 - acc: 0.7056 - val_loss: 0.7485 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6730 - acc: 0.6833 - val_loss: 0.7479 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6734 - acc: 0.6333 - val_loss: 0.7540 - val_acc: 0.5286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6722 - acc: 0.6611 - val_loss: 0.7451 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6584 - acc: 0.7000 - val_loss: 0.7407 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6511 - acc: 0.7167 - val_loss: 0.7483 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6635 - acc: 0.6611 - val_loss: 0.7424 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6432 - acc: 0.6889 - val_loss: 0.7355 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6446 - acc: 0.7333 - val_loss: 0.7342 - val_acc: 0.5857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6468 - acc: 0.6778 - val_loss: 0.7370 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6373 - acc: 0.7056 - val_loss: 0.7361 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6584 - acc: 0.6778 - val_loss: 0.7344 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6433 - acc: 0.7222 - val_loss: 0.7374 - val_acc: 0.6429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6490 - acc: 0.6667 - val_loss: 0.7446 - val_acc: 0.5571\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6464 - acc: 0.7056 - val_loss: 0.7397 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6390 - acc: 0.6944 - val_loss: 0.7391 - val_acc: 0.6286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6437 - acc: 0.7000 - val_loss: 0.7354 - val_acc: 0.6571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6474 - acc: 0.6556 - val_loss: 0.7416 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6188 - acc: 0.7389 - val_loss: 0.7412 - val_acc: 0.5857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6215 - acc: 0.7167 - val_loss: 0.7385 - val_acc: 0.6429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6180 - acc: 0.7111 - val_loss: 0.7285 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6171 - acc: 0.7000 - val_loss: 0.7304 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6254 - acc: 0.6833 - val_loss: 0.7332 - val_acc: 0.6429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6147 - acc: 0.7111 - val_loss: 0.7279 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6239 - acc: 0.6611 - val_loss: 0.7243 - val_acc: 0.5571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5965 - acc: 0.6889 - val_loss: 0.7311 - val_acc: 0.6571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6097 - acc: 0.7389 - val_loss: 0.7365 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6232 - acc: 0.7000 - val_loss: 0.7367 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5980 - acc: 0.7056 - val_loss: 0.7257 - val_acc: 0.5714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6085 - acc: 0.7222 - val_loss: 0.7383 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6015 - acc: 0.7556 - val_loss: 0.7309 - val_acc: 0.5714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5999 - acc: 0.7389 - val_loss: 0.7402 - val_acc: 0.6429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 76us/step - loss: 0.5915 - acc: 0.7167 - val_loss: 0.7337 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5836 - acc: 0.7611 - val_loss: 0.7281 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6051 - acc: 0.7056 - val_loss: 0.7232 - val_acc: 0.5714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5870 - acc: 0.7222 - val_loss: 0.7180 - val_acc: 0.5714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5926 - acc: 0.7222 - val_loss: 0.7178 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5804 - acc: 0.7444 - val_loss: 0.7253 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5798 - acc: 0.7389 - val_loss: 0.7225 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.5619 - acc: 0.7722 - val_loss: 0.7221 - val_acc: 0.5857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5729 - acc: 0.7333 - val_loss: 0.7214 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5496 - acc: 0.7889 - val_loss: 0.7231 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5569 - acc: 0.7556 - val_loss: 0.7392 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5781 - acc: 0.7167 - val_loss: 0.7320 - val_acc: 0.6143\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 78us/step - loss: 0.5666 - acc: 0.7667 - val_loss: 0.7328 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 79us/step - loss: 0.5621 - acc: 0.7556 - val_loss: 0.7306 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5635 - acc: 0.7500 - val_loss: 0.7279 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5511 - acc: 0.7833 - val_loss: 0.7257 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5355 - acc: 0.7889 - val_loss: 0.7373 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5638 - acc: 0.7333 - val_loss: 0.7199 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5512 - acc: 0.7611 - val_loss: 0.7218 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5268 - acc: 0.7722 - val_loss: 0.7245 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5562 - acc: 0.7444 - val_loss: 0.7289 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 11ms/step - loss: 0.7992 - acc: 0.4889 - val_loss: 0.7330 - val_acc: 0.5571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7639 - acc: 0.5444 - val_loss: 0.7269 - val_acc: 0.6000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7583 - acc: 0.5333 - val_loss: 0.7255 - val_acc: 0.5857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7350 - acc: 0.5333 - val_loss: 0.7235 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7177 - acc: 0.5889 - val_loss: 0.7210 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7399 - acc: 0.5278 - val_loss: 0.7195 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7111 - acc: 0.5722 - val_loss: 0.7182 - val_acc: 0.5714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7224 - acc: 0.5556 - val_loss: 0.7203 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7035 - acc: 0.5889 - val_loss: 0.7168 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6872 - acc: 0.6556 - val_loss: 0.7156 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7028 - acc: 0.6056 - val_loss: 0.7142 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6909 - acc: 0.6167 - val_loss: 0.7123 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6841 - acc: 0.6556 - val_loss: 0.7145 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6913 - acc: 0.6222 - val_loss: 0.7133 - val_acc: 0.5571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6845 - acc: 0.6278 - val_loss: 0.7122 - val_acc: 0.5571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6954 - acc: 0.6333 - val_loss: 0.7138 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6690 - acc: 0.6722 - val_loss: 0.7073 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6933 - acc: 0.5944 - val_loss: 0.7098 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6614 - acc: 0.6778 - val_loss: 0.7033 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6694 - acc: 0.6333 - val_loss: 0.7000 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6795 - acc: 0.6111 - val_loss: 0.6972 - val_acc: 0.6000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6746 - acc: 0.6389 - val_loss: 0.6993 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6588 - acc: 0.6667 - val_loss: 0.6965 - val_acc: 0.6000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6631 - acc: 0.7000 - val_loss: 0.6898 - val_acc: 0.6143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6345 - acc: 0.7167 - val_loss: 0.6879 - val_acc: 0.6286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6564 - acc: 0.6833 - val_loss: 0.6911 - val_acc: 0.6000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6435 - acc: 0.6944 - val_loss: 0.6802 - val_acc: 0.6286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6319 - acc: 0.7000 - val_loss: 0.6814 - val_acc: 0.6429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6165 - acc: 0.7611 - val_loss: 0.6809 - val_acc: 0.6429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6406 - acc: 0.7000 - val_loss: 0.6797 - val_acc: 0.6571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6229 - acc: 0.7611 - val_loss: 0.6887 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6143 - acc: 0.7278 - val_loss: 0.6845 - val_acc: 0.6143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6255 - acc: 0.7444 - val_loss: 0.6783 - val_acc: 0.6714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6126 - acc: 0.7500 - val_loss: 0.6808 - val_acc: 0.6286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6186 - acc: 0.7444 - val_loss: 0.6814 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6174 - acc: 0.7333 - val_loss: 0.6693 - val_acc: 0.6571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6018 - acc: 0.7389 - val_loss: 0.6606 - val_acc: 0.6714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.6201 - acc: 0.7333 - val_loss: 0.6629 - val_acc: 0.6714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6304 - acc: 0.7111 - val_loss: 0.6621 - val_acc: 0.6714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6049 - acc: 0.7444 - val_loss: 0.6676 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6158 - acc: 0.7056 - val_loss: 0.6712 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6235 - acc: 0.7000 - val_loss: 0.6677 - val_acc: 0.6429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6017 - acc: 0.7500 - val_loss: 0.6748 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6022 - acc: 0.7222 - val_loss: 0.6633 - val_acc: 0.6571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5938 - acc: 0.7833 - val_loss: 0.6638 - val_acc: 0.6571\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6004 - acc: 0.7222 - val_loss: 0.6611 - val_acc: 0.6571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.5964 - acc: 0.7278 - val_loss: 0.6648 - val_acc: 0.6571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5767 - acc: 0.7833 - val_loss: 0.6629 - val_acc: 0.6571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5642 - acc: 0.7444 - val_loss: 0.6651 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.5789 - acc: 0.7778 - val_loss: 0.6542 - val_acc: 0.6571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.5778 - acc: 0.7833 - val_loss: 0.6579 - val_acc: 0.6571\n",
      "Epoch 52/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.5634 - acc: 0.7833 - val_loss: 0.6637 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5798 - acc: 0.7389 - val_loss: 0.6676 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5827 - acc: 0.7389 - val_loss: 0.6568 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5544 - acc: 0.7833 - val_loss: 0.6568 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5914 - acc: 0.7278 - val_loss: 0.6502 - val_acc: 0.7000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5633 - acc: 0.7833 - val_loss: 0.6633 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5546 - acc: 0.7722 - val_loss: 0.6531 - val_acc: 0.6857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5453 - acc: 0.7444 - val_loss: 0.6548 - val_acc: 0.6429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5578 - acc: 0.7556 - val_loss: 0.6570 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5641 - acc: 0.7667 - val_loss: 0.6644 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5400 - acc: 0.8000 - val_loss: 0.6527 - val_acc: 0.6714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5586 - acc: 0.7722 - val_loss: 0.6507 - val_acc: 0.6857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5322 - acc: 0.8111 - val_loss: 0.6592 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5460 - acc: 0.7889 - val_loss: 0.6624 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5165 - acc: 0.7889 - val_loss: 0.6624 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5376 - acc: 0.7833 - val_loss: 0.6616 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5519 - acc: 0.7333 - val_loss: 0.6611 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5130 - acc: 0.8278 - val_loss: 0.6657 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 75us/step - loss: 0.5423 - acc: 0.8000 - val_loss: 0.6677 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.5338 - acc: 0.8000 - val_loss: 0.6675 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5363 - acc: 0.7889 - val_loss: 0.6619 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5349 - acc: 0.7556 - val_loss: 0.6519 - val_acc: 0.6857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5252 - acc: 0.7944 - val_loss: 0.6669 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5242 - acc: 0.8000 - val_loss: 0.6650 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5111 - acc: 0.8111 - val_loss: 0.6561 - val_acc: 0.6714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5052 - acc: 0.8167 - val_loss: 0.6639 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.4965 - acc: 0.8000 - val_loss: 0.6606 - val_acc: 0.6714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.4979 - acc: 0.8222 - val_loss: 0.6586 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5013 - acc: 0.8167 - val_loss: 0.6575 - val_acc: 0.6857\n",
      "80/80 [==============================] - 0s 112us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 11ms/step - loss: 0.7734 - acc: 0.5389 - val_loss: 0.7803 - val_acc: 0.5429\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7455 - acc: 0.5611 - val_loss: 0.7627 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 72us/step - loss: 0.7229 - acc: 0.5444 - val_loss: 0.7532 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7365 - acc: 0.5556 - val_loss: 0.7469 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7035 - acc: 0.5833 - val_loss: 0.7455 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7035 - acc: 0.6222 - val_loss: 0.7424 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7047 - acc: 0.6333 - val_loss: 0.7425 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 81us/step - loss: 0.7163 - acc: 0.5722 - val_loss: 0.7389 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7033 - acc: 0.6333 - val_loss: 0.7380 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6869 - acc: 0.6111 - val_loss: 0.7367 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6945 - acc: 0.6278 - val_loss: 0.7358 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7031 - acc: 0.6000 - val_loss: 0.7398 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6804 - acc: 0.6722 - val_loss: 0.7385 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6928 - acc: 0.6500 - val_loss: 0.7383 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6811 - acc: 0.6556 - val_loss: 0.7332 - val_acc: 0.5571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6786 - acc: 0.6611 - val_loss: 0.7340 - val_acc: 0.5571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6583 - acc: 0.7056 - val_loss: 0.7290 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6573 - acc: 0.6944 - val_loss: 0.7289 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6612 - acc: 0.6833 - val_loss: 0.7277 - val_acc: 0.5857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6677 - acc: 0.6778 - val_loss: 0.7262 - val_acc: 0.5857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6777 - acc: 0.6778 - val_loss: 0.7256 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6590 - acc: 0.7167 - val_loss: 0.7325 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6556 - acc: 0.6833 - val_loss: 0.7250 - val_acc: 0.6000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6447 - acc: 0.7333 - val_loss: 0.7244 - val_acc: 0.6000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6483 - acc: 0.7167 - val_loss: 0.7259 - val_acc: 0.5857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6502 - acc: 0.6889 - val_loss: 0.7223 - val_acc: 0.6000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6389 - acc: 0.7222 - val_loss: 0.7206 - val_acc: 0.6143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6179 - acc: 0.7500 - val_loss: 0.7191 - val_acc: 0.6000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6281 - acc: 0.7444 - val_loss: 0.7196 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6171 - acc: 0.7444 - val_loss: 0.7259 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6140 - acc: 0.7333 - val_loss: 0.7178 - val_acc: 0.6000\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.6016 - acc: 0.7500 - val_loss: 0.7233 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6107 - acc: 0.7667 - val_loss: 0.7240 - val_acc: 0.5857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6090 - acc: 0.7278 - val_loss: 0.7146 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6035 - acc: 0.7889 - val_loss: 0.7172 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6011 - acc: 0.7667 - val_loss: 0.7126 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5878 - acc: 0.7944 - val_loss: 0.7178 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5954 - acc: 0.7889 - val_loss: 0.7225 - val_acc: 0.5857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6056 - acc: 0.7333 - val_loss: 0.7162 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5823 - acc: 0.8111 - val_loss: 0.7116 - val_acc: 0.6429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5999 - acc: 0.7500 - val_loss: 0.7105 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.5878 - acc: 0.7889 - val_loss: 0.7081 - val_acc: 0.6429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5927 - acc: 0.7444 - val_loss: 0.7114 - val_acc: 0.6429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5844 - acc: 0.7333 - val_loss: 0.7160 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5692 - acc: 0.8056 - val_loss: 0.7142 - val_acc: 0.6286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5921 - acc: 0.7444 - val_loss: 0.7114 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5778 - acc: 0.7833 - val_loss: 0.7201 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5724 - acc: 0.7667 - val_loss: 0.7111 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5842 - acc: 0.7556 - val_loss: 0.7116 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5601 - acc: 0.8111 - val_loss: 0.7166 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5747 - acc: 0.7778 - val_loss: 0.7231 - val_acc: 0.5571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5560 - acc: 0.7889 - val_loss: 0.7185 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5846 - acc: 0.7778 - val_loss: 0.7102 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5690 - acc: 0.7889 - val_loss: 0.7109 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5606 - acc: 0.7833 - val_loss: 0.7177 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5569 - acc: 0.7722 - val_loss: 0.7126 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5540 - acc: 0.8000 - val_loss: 0.7199 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5555 - acc: 0.7889 - val_loss: 0.7253 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5309 - acc: 0.8056 - val_loss: 0.7152 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 75us/step - loss: 0.5355 - acc: 0.8389 - val_loss: 0.7130 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5561 - acc: 0.7611 - val_loss: 0.7111 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5439 - acc: 0.7889 - val_loss: 0.7091 - val_acc: 0.6571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5379 - acc: 0.8000 - val_loss: 0.7155 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5276 - acc: 0.8111 - val_loss: 0.7167 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5172 - acc: 0.8333 - val_loss: 0.7227 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5275 - acc: 0.8000 - val_loss: 0.7287 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5163 - acc: 0.7889 - val_loss: 0.7153 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5172 - acc: 0.8111 - val_loss: 0.7268 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5200 - acc: 0.8222 - val_loss: 0.7214 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5021 - acc: 0.8333 - val_loss: 0.7213 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5025 - acc: 0.8444 - val_loss: 0.7171 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5187 - acc: 0.7944 - val_loss: 0.7214 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5048 - acc: 0.8333 - val_loss: 0.7167 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5108 - acc: 0.8111 - val_loss: 0.7155 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5099 - acc: 0.8000 - val_loss: 0.7281 - val_acc: 0.5857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.5210 - acc: 0.7778 - val_loss: 0.7271 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.4875 - acc: 0.8167 - val_loss: 0.7242 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5180 - acc: 0.7889 - val_loss: 0.7298 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.4819 - acc: 0.8056 - val_loss: 0.7267 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.4791 - acc: 0.8444 - val_loss: 0.7427 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 87us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.7670 - acc: 0.5389 - val_loss: 0.7711 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7426 - acc: 0.5389 - val_loss: 0.7604 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7480 - acc: 0.5278 - val_loss: 0.7539 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7344 - acc: 0.5333 - val_loss: 0.7524 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7413 - acc: 0.5222 - val_loss: 0.7499 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7351 - acc: 0.5333 - val_loss: 0.7503 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7262 - acc: 0.5556 - val_loss: 0.7489 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7280 - acc: 0.5444 - val_loss: 0.7485 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7304 - acc: 0.5500 - val_loss: 0.7455 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7209 - acc: 0.5444 - val_loss: 0.7427 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7164 - acc: 0.5556 - val_loss: 0.7408 - val_acc: 0.5000\n",
      "Epoch 12/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 77us/step - loss: 0.7190 - acc: 0.5833 - val_loss: 0.7423 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7210 - acc: 0.5611 - val_loss: 0.7380 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7234 - acc: 0.5556 - val_loss: 0.7366 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.7160 - acc: 0.5611 - val_loss: 0.7355 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.7057 - acc: 0.5889 - val_loss: 0.7335 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7092 - acc: 0.5889 - val_loss: 0.7325 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7046 - acc: 0.5889 - val_loss: 0.7331 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6991 - acc: 0.5722 - val_loss: 0.7312 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.7005 - acc: 0.5556 - val_loss: 0.7283 - val_acc: 0.4857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7033 - acc: 0.5833 - val_loss: 0.7275 - val_acc: 0.4857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6963 - acc: 0.5944 - val_loss: 0.7289 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 84us/step - loss: 0.6959 - acc: 0.5944 - val_loss: 0.7276 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6958 - acc: 0.6000 - val_loss: 0.7266 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6885 - acc: 0.5778 - val_loss: 0.7254 - val_acc: 0.5000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6894 - acc: 0.5944 - val_loss: 0.7236 - val_acc: 0.5000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6825 - acc: 0.5778 - val_loss: 0.7205 - val_acc: 0.4857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6809 - acc: 0.6389 - val_loss: 0.7179 - val_acc: 0.4857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.6829 - acc: 0.5889 - val_loss: 0.7155 - val_acc: 0.5000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6764 - acc: 0.6167 - val_loss: 0.7169 - val_acc: 0.4857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6753 - acc: 0.6333 - val_loss: 0.7175 - val_acc: 0.4857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6752 - acc: 0.6389 - val_loss: 0.7152 - val_acc: 0.4857\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6622 - acc: 0.6611 - val_loss: 0.7127 - val_acc: 0.5286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6721 - acc: 0.6556 - val_loss: 0.7161 - val_acc: 0.4857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6665 - acc: 0.6222 - val_loss: 0.7143 - val_acc: 0.4857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6604 - acc: 0.6556 - val_loss: 0.7120 - val_acc: 0.5000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6606 - acc: 0.7000 - val_loss: 0.7153 - val_acc: 0.4857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6608 - acc: 0.6278 - val_loss: 0.7094 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6489 - acc: 0.6944 - val_loss: 0.7084 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6521 - acc: 0.6778 - val_loss: 0.7051 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6449 - acc: 0.6944 - val_loss: 0.7051 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6477 - acc: 0.7111 - val_loss: 0.7068 - val_acc: 0.5429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6415 - acc: 0.6722 - val_loss: 0.7001 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6393 - acc: 0.7167 - val_loss: 0.6980 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6426 - acc: 0.7500 - val_loss: 0.7005 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 77us/step - loss: 0.6339 - acc: 0.7667 - val_loss: 0.7008 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6278 - acc: 0.7556 - val_loss: 0.7033 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 78us/step - loss: 0.6401 - acc: 0.6889 - val_loss: 0.7052 - val_acc: 0.5429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6380 - acc: 0.6778 - val_loss: 0.7041 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 188us/step - loss: 0.6410 - acc: 0.6722 - val_loss: 0.7011 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 194us/step - loss: 0.6278 - acc: 0.7222 - val_loss: 0.7037 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6277 - acc: 0.7000 - val_loss: 0.6975 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6274 - acc: 0.7222 - val_loss: 0.6928 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6111 - acc: 0.7667 - val_loss: 0.6912 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6194 - acc: 0.7778 - val_loss: 0.6961 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6167 - acc: 0.7556 - val_loss: 0.6985 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6183 - acc: 0.7333 - val_loss: 0.6960 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6216 - acc: 0.7333 - val_loss: 0.6935 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6070 - acc: 0.7444 - val_loss: 0.6899 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6004 - acc: 0.8111 - val_loss: 0.6914 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6018 - acc: 0.7889 - val_loss: 0.6950 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6070 - acc: 0.7667 - val_loss: 0.6887 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6080 - acc: 0.7889 - val_loss: 0.6917 - val_acc: 0.5857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5952 - acc: 0.7722 - val_loss: 0.6862 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5918 - acc: 0.7944 - val_loss: 0.6902 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5927 - acc: 0.7889 - val_loss: 0.6864 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5923 - acc: 0.7833 - val_loss: 0.6857 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5934 - acc: 0.7722 - val_loss: 0.6817 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5917 - acc: 0.7778 - val_loss: 0.6810 - val_acc: 0.6429\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5857 - acc: 0.8000 - val_loss: 0.6804 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5880 - acc: 0.7556 - val_loss: 0.6821 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5814 - acc: 0.8000 - val_loss: 0.6825 - val_acc: 0.6286\n",
      "Epoch 73/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.5816 - acc: 0.7778 - val_loss: 0.6857 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5802 - acc: 0.7944 - val_loss: 0.6840 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5726 - acc: 0.7889 - val_loss: 0.6783 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5746 - acc: 0.7722 - val_loss: 0.6792 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5726 - acc: 0.8056 - val_loss: 0.6870 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5696 - acc: 0.7944 - val_loss: 0.6796 - val_acc: 0.6429\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5624 - acc: 0.7667 - val_loss: 0.6824 - val_acc: 0.6429\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5551 - acc: 0.8167 - val_loss: 0.6860 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 100us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.8075 - acc: 0.4833 - val_loss: 0.7507 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7612 - acc: 0.5444 - val_loss: 0.7414 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7384 - acc: 0.5000 - val_loss: 0.7400 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7332 - acc: 0.5500 - val_loss: 0.7386 - val_acc: 0.5714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7231 - acc: 0.5500 - val_loss: 0.7382 - val_acc: 0.5857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7124 - acc: 0.5778 - val_loss: 0.7395 - val_acc: 0.5857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7117 - acc: 0.5889 - val_loss: 0.7416 - val_acc: 0.5857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6996 - acc: 0.6000 - val_loss: 0.7451 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7105 - acc: 0.5611 - val_loss: 0.7428 - val_acc: 0.5429\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6990 - acc: 0.6056 - val_loss: 0.7379 - val_acc: 0.6143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7031 - acc: 0.5722 - val_loss: 0.7371 - val_acc: 0.6000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6912 - acc: 0.6222 - val_loss: 0.7365 - val_acc: 0.6000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6863 - acc: 0.6222 - val_loss: 0.7335 - val_acc: 0.5857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6854 - acc: 0.6167 - val_loss: 0.7328 - val_acc: 0.6000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6818 - acc: 0.6556 - val_loss: 0.7339 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6874 - acc: 0.6000 - val_loss: 0.7376 - val_acc: 0.5857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6826 - acc: 0.5944 - val_loss: 0.7331 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6734 - acc: 0.6222 - val_loss: 0.7331 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6670 - acc: 0.6611 - val_loss: 0.7271 - val_acc: 0.6000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6755 - acc: 0.6556 - val_loss: 0.7268 - val_acc: 0.6143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6790 - acc: 0.6333 - val_loss: 0.7257 - val_acc: 0.5714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6689 - acc: 0.6611 - val_loss: 0.7251 - val_acc: 0.6143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6621 - acc: 0.6500 - val_loss: 0.7239 - val_acc: 0.6143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6752 - acc: 0.6333 - val_loss: 0.7203 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6684 - acc: 0.6389 - val_loss: 0.7214 - val_acc: 0.6143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6620 - acc: 0.6722 - val_loss: 0.7202 - val_acc: 0.6143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6582 - acc: 0.6667 - val_loss: 0.7158 - val_acc: 0.6000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6581 - acc: 0.6611 - val_loss: 0.7148 - val_acc: 0.6143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6566 - acc: 0.6389 - val_loss: 0.7155 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6464 - acc: 0.7167 - val_loss: 0.7137 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6526 - acc: 0.6944 - val_loss: 0.7170 - val_acc: 0.5857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6448 - acc: 0.6722 - val_loss: 0.7125 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6386 - acc: 0.7056 - val_loss: 0.7122 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6368 - acc: 0.6944 - val_loss: 0.7049 - val_acc: 0.6286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6245 - acc: 0.7389 - val_loss: 0.7035 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6273 - acc: 0.7333 - val_loss: 0.7054 - val_acc: 0.6286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6382 - acc: 0.7056 - val_loss: 0.7062 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6323 - acc: 0.7278 - val_loss: 0.7081 - val_acc: 0.6000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6231 - acc: 0.7111 - val_loss: 0.7029 - val_acc: 0.6286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6224 - acc: 0.7056 - val_loss: 0.7091 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 91us/step - loss: 0.6229 - acc: 0.6667 - val_loss: 0.7062 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6074 - acc: 0.7611 - val_loss: 0.7001 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6119 - acc: 0.7222 - val_loss: 0.7063 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6114 - acc: 0.7500 - val_loss: 0.6968 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5989 - acc: 0.7333 - val_loss: 0.7014 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6102 - acc: 0.7444 - val_loss: 0.6949 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5962 - acc: 0.7500 - val_loss: 0.6928 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6001 - acc: 0.7167 - val_loss: 0.6917 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6006 - acc: 0.7500 - val_loss: 0.6909 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6018 - acc: 0.7556 - val_loss: 0.6953 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5812 - acc: 0.7500 - val_loss: 0.6999 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 92us/step - loss: 0.5788 - acc: 0.7500 - val_loss: 0.7008 - val_acc: 0.6000\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 83us/step - loss: 0.5875 - acc: 0.7500 - val_loss: 0.6983 - val_acc: 0.5857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5962 - acc: 0.7278 - val_loss: 0.6981 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5910 - acc: 0.7278 - val_loss: 0.6888 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5530 - acc: 0.8056 - val_loss: 0.6939 - val_acc: 0.6000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5825 - acc: 0.7611 - val_loss: 0.6983 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5765 - acc: 0.7667 - val_loss: 0.6958 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5836 - acc: 0.7611 - val_loss: 0.6892 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5701 - acc: 0.7667 - val_loss: 0.7015 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5693 - acc: 0.7667 - val_loss: 0.6936 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5431 - acc: 0.7833 - val_loss: 0.6946 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5766 - acc: 0.7278 - val_loss: 0.6896 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5590 - acc: 0.7778 - val_loss: 0.6940 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5662 - acc: 0.7611 - val_loss: 0.6932 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5559 - acc: 0.7667 - val_loss: 0.6917 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5491 - acc: 0.7667 - val_loss: 0.6929 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5478 - acc: 0.7833 - val_loss: 0.6872 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 99us/step - loss: 0.5656 - acc: 0.7389 - val_loss: 0.6928 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5568 - acc: 0.7500 - val_loss: 0.6971 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5348 - acc: 0.8056 - val_loss: 0.6888 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5331 - acc: 0.7778 - val_loss: 0.6888 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5338 - acc: 0.7889 - val_loss: 0.6858 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5330 - acc: 0.7889 - val_loss: 0.6934 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5327 - acc: 0.7722 - val_loss: 0.6856 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5488 - acc: 0.7944 - val_loss: 0.7031 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5120 - acc: 0.8222 - val_loss: 0.6921 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5404 - acc: 0.7833 - val_loss: 0.6900 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5323 - acc: 0.7833 - val_loss: 0.7023 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5213 - acc: 0.7944 - val_loss: 0.6908 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 107us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.8310 - acc: 0.4556 - val_loss: 0.7579 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7824 - acc: 0.4611 - val_loss: 0.7459 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 99us/step - loss: 0.7696 - acc: 0.4778 - val_loss: 0.7418 - val_acc: 0.5429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7638 - acc: 0.4444 - val_loss: 0.7379 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7555 - acc: 0.5556 - val_loss: 0.7364 - val_acc: 0.5714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7559 - acc: 0.5056 - val_loss: 0.7358 - val_acc: 0.6286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7375 - acc: 0.5500 - val_loss: 0.7344 - val_acc: 0.6000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7400 - acc: 0.4944 - val_loss: 0.7344 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7353 - acc: 0.5444 - val_loss: 0.7337 - val_acc: 0.5571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7387 - acc: 0.5333 - val_loss: 0.7350 - val_acc: 0.5714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7334 - acc: 0.5556 - val_loss: 0.7340 - val_acc: 0.5714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7288 - acc: 0.5833 - val_loss: 0.7329 - val_acc: 0.5714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 537us/step - loss: 0.7249 - acc: 0.5611 - val_loss: 0.7311 - val_acc: 0.5857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7226 - acc: 0.5556 - val_loss: 0.7330 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7173 - acc: 0.6167 - val_loss: 0.7339 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7239 - acc: 0.5500 - val_loss: 0.7352 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7089 - acc: 0.5889 - val_loss: 0.7361 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7089 - acc: 0.5889 - val_loss: 0.7368 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7035 - acc: 0.6111 - val_loss: 0.7372 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7033 - acc: 0.6111 - val_loss: 0.7387 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7025 - acc: 0.6167 - val_loss: 0.7325 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6978 - acc: 0.6167 - val_loss: 0.7306 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6982 - acc: 0.5944 - val_loss: 0.7290 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6867 - acc: 0.6389 - val_loss: 0.7243 - val_acc: 0.6000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6860 - acc: 0.6611 - val_loss: 0.7229 - val_acc: 0.5857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6787 - acc: 0.7000 - val_loss: 0.7249 - val_acc: 0.6143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6880 - acc: 0.6056 - val_loss: 0.7248 - val_acc: 0.6143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6832 - acc: 0.6278 - val_loss: 0.7289 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6793 - acc: 0.6611 - val_loss: 0.7282 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6701 - acc: 0.6667 - val_loss: 0.7287 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6766 - acc: 0.6056 - val_loss: 0.7253 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6619 - acc: 0.6556 - val_loss: 0.7259 - val_acc: 0.5857\n",
      "Epoch 33/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6576 - acc: 0.6833 - val_loss: 0.7200 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6679 - acc: 0.6500 - val_loss: 0.7271 - val_acc: 0.5429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6548 - acc: 0.6722 - val_loss: 0.7181 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6652 - acc: 0.6500 - val_loss: 0.7171 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6666 - acc: 0.6833 - val_loss: 0.7143 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6560 - acc: 0.6889 - val_loss: 0.7183 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 113us/step - loss: 0.6524 - acc: 0.7000 - val_loss: 0.7180 - val_acc: 0.6143\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6447 - acc: 0.6778 - val_loss: 0.7095 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6438 - acc: 0.7222 - val_loss: 0.7107 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6412 - acc: 0.7056 - val_loss: 0.7159 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6277 - acc: 0.7056 - val_loss: 0.7155 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6383 - acc: 0.6722 - val_loss: 0.7147 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6192 - acc: 0.7111 - val_loss: 0.7057 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6368 - acc: 0.7000 - val_loss: 0.7041 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6233 - acc: 0.7389 - val_loss: 0.7077 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6311 - acc: 0.7056 - val_loss: 0.6978 - val_acc: 0.6571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6225 - acc: 0.7556 - val_loss: 0.7010 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6222 - acc: 0.7389 - val_loss: 0.7035 - val_acc: 0.6429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6172 - acc: 0.7556 - val_loss: 0.7042 - val_acc: 0.6286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6174 - acc: 0.7500 - val_loss: 0.7060 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6120 - acc: 0.7111 - val_loss: 0.6985 - val_acc: 0.6571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6240 - acc: 0.7222 - val_loss: 0.6996 - val_acc: 0.6571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5988 - acc: 0.7833 - val_loss: 0.7074 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5999 - acc: 0.7278 - val_loss: 0.7079 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6019 - acc: 0.7556 - val_loss: 0.6969 - val_acc: 0.6714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5957 - acc: 0.7722 - val_loss: 0.7033 - val_acc: 0.6429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5877 - acc: 0.7278 - val_loss: 0.7094 - val_acc: 0.6429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6039 - acc: 0.7389 - val_loss: 0.7009 - val_acc: 0.6571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6008 - acc: 0.7500 - val_loss: 0.7066 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5918 - acc: 0.7778 - val_loss: 0.7013 - val_acc: 0.6571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5793 - acc: 0.7889 - val_loss: 0.6994 - val_acc: 0.6571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5844 - acc: 0.7778 - val_loss: 0.7038 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5921 - acc: 0.7333 - val_loss: 0.6948 - val_acc: 0.6714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5741 - acc: 0.7833 - val_loss: 0.6916 - val_acc: 0.6571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5911 - acc: 0.7556 - val_loss: 0.6926 - val_acc: 0.6571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5604 - acc: 0.7833 - val_loss: 0.6947 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5745 - acc: 0.7778 - val_loss: 0.6894 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5560 - acc: 0.8000 - val_loss: 0.7033 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5726 - acc: 0.7500 - val_loss: 0.7059 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5623 - acc: 0.7889 - val_loss: 0.6905 - val_acc: 0.6571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5735 - acc: 0.7722 - val_loss: 0.6898 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5571 - acc: 0.8111 - val_loss: 0.6894 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5586 - acc: 0.7722 - val_loss: 0.6866 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5590 - acc: 0.7778 - val_loss: 0.6888 - val_acc: 0.6714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5475 - acc: 0.8056 - val_loss: 0.6942 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5609 - acc: 0.7556 - val_loss: 0.7079 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5498 - acc: 0.7778 - val_loss: 0.6925 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5423 - acc: 0.7889 - val_loss: 0.6909 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.7710 - acc: 0.4889 - val_loss: 0.7617 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7547 - acc: 0.4833 - val_loss: 0.7572 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.7421 - acc: 0.5222 - val_loss: 0.7523 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7349 - acc: 0.5278 - val_loss: 0.7482 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.7134 - acc: 0.6000 - val_loss: 0.7442 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7144 - acc: 0.5444 - val_loss: 0.7413 - val_acc: 0.4857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7182 - acc: 0.5444 - val_loss: 0.7404 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6990 - acc: 0.5778 - val_loss: 0.7386 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7039 - acc: 0.6278 - val_loss: 0.7394 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6972 - acc: 0.6111 - val_loss: 0.7394 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7074 - acc: 0.5389 - val_loss: 0.7356 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6889 - acc: 0.6278 - val_loss: 0.7310 - val_acc: 0.5571\n",
      "Epoch 13/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.6913 - acc: 0.6333 - val_loss: 0.7289 - val_acc: 0.5857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6884 - acc: 0.6222 - val_loss: 0.7293 - val_acc: 0.5571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6905 - acc: 0.5944 - val_loss: 0.7260 - val_acc: 0.5857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6799 - acc: 0.6278 - val_loss: 0.7255 - val_acc: 0.6000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6866 - acc: 0.6278 - val_loss: 0.7237 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6827 - acc: 0.6278 - val_loss: 0.7228 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6754 - acc: 0.6444 - val_loss: 0.7213 - val_acc: 0.5857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6783 - acc: 0.6333 - val_loss: 0.7231 - val_acc: 0.6143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6691 - acc: 0.6389 - val_loss: 0.7227 - val_acc: 0.6143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6760 - acc: 0.6111 - val_loss: 0.7207 - val_acc: 0.6143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6627 - acc: 0.6444 - val_loss: 0.7212 - val_acc: 0.6143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6601 - acc: 0.6500 - val_loss: 0.7188 - val_acc: 0.6143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6542 - acc: 0.6389 - val_loss: 0.7170 - val_acc: 0.6000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6529 - acc: 0.6556 - val_loss: 0.7147 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6498 - acc: 0.7111 - val_loss: 0.7130 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6578 - acc: 0.6833 - val_loss: 0.7143 - val_acc: 0.6143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6412 - acc: 0.6889 - val_loss: 0.7130 - val_acc: 0.6286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6549 - acc: 0.6722 - val_loss: 0.7160 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6496 - acc: 0.6722 - val_loss: 0.7166 - val_acc: 0.6000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6403 - acc: 0.6722 - val_loss: 0.7117 - val_acc: 0.6286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6241 - acc: 0.7667 - val_loss: 0.7132 - val_acc: 0.6286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6135 - acc: 0.7167 - val_loss: 0.7105 - val_acc: 0.6286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6378 - acc: 0.7056 - val_loss: 0.7109 - val_acc: 0.6286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6386 - acc: 0.7167 - val_loss: 0.7086 - val_acc: 0.6000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6166 - acc: 0.7556 - val_loss: 0.7110 - val_acc: 0.6000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6233 - acc: 0.7111 - val_loss: 0.7113 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6161 - acc: 0.7389 - val_loss: 0.7091 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6181 - acc: 0.7389 - val_loss: 0.7077 - val_acc: 0.6000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6237 - acc: 0.7278 - val_loss: 0.7074 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6117 - acc: 0.7333 - val_loss: 0.7070 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6094 - acc: 0.7444 - val_loss: 0.7083 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5980 - acc: 0.7444 - val_loss: 0.7093 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6100 - acc: 0.7000 - val_loss: 0.7062 - val_acc: 0.6429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5976 - acc: 0.7833 - val_loss: 0.7057 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6000 - acc: 0.7611 - val_loss: 0.7079 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5983 - acc: 0.7667 - val_loss: 0.7070 - val_acc: 0.6429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5850 - acc: 0.7611 - val_loss: 0.7064 - val_acc: 0.6571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5778 - acc: 0.7778 - val_loss: 0.7058 - val_acc: 0.6714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5925 - acc: 0.7333 - val_loss: 0.7058 - val_acc: 0.6714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5908 - acc: 0.7389 - val_loss: 0.7071 - val_acc: 0.6571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5880 - acc: 0.7167 - val_loss: 0.7071 - val_acc: 0.6571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5715 - acc: 0.7556 - val_loss: 0.7094 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5712 - acc: 0.7444 - val_loss: 0.7079 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5742 - acc: 0.7611 - val_loss: 0.7076 - val_acc: 0.6571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5677 - acc: 0.7889 - val_loss: 0.7108 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5691 - acc: 0.7500 - val_loss: 0.7107 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5617 - acc: 0.7889 - val_loss: 0.7128 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5543 - acc: 0.7667 - val_loss: 0.7117 - val_acc: 0.6429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5708 - acc: 0.7389 - val_loss: 0.7128 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5547 - acc: 0.8056 - val_loss: 0.7085 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5529 - acc: 0.7889 - val_loss: 0.7126 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5491 - acc: 0.7889 - val_loss: 0.7119 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5534 - acc: 0.7611 - val_loss: 0.7134 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5453 - acc: 0.7833 - val_loss: 0.7145 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5455 - acc: 0.7722 - val_loss: 0.7135 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5390 - acc: 0.8056 - val_loss: 0.7175 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5323 - acc: 0.7722 - val_loss: 0.7166 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5357 - acc: 0.7944 - val_loss: 0.7136 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5456 - acc: 0.7667 - val_loss: 0.7159 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5420 - acc: 0.7389 - val_loss: 0.7215 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5290 - acc: 0.7889 - val_loss: 0.7230 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5280 - acc: 0.7889 - val_loss: 0.7191 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5264 - acc: 0.8000 - val_loss: 0.7246 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5338 - acc: 0.7722 - val_loss: 0.7220 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5199 - acc: 0.8000 - val_loss: 0.7240 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5178 - acc: 0.8000 - val_loss: 0.7251 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5257 - acc: 0.8000 - val_loss: 0.7248 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 109us/step - loss: 0.4999 - acc: 0.8278 - val_loss: 0.7296 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.8354 - acc: 0.5333 - val_loss: 0.7721 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7556 - acc: 0.5444 - val_loss: 0.7483 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7428 - acc: 0.5389 - val_loss: 0.7424 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7388 - acc: 0.5333 - val_loss: 0.7405 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7389 - acc: 0.5556 - val_loss: 0.7378 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7344 - acc: 0.5333 - val_loss: 0.7372 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7286 - acc: 0.5833 - val_loss: 0.7371 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7327 - acc: 0.5444 - val_loss: 0.7362 - val_acc: 0.5429\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7178 - acc: 0.5833 - val_loss: 0.7355 - val_acc: 0.5429\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7251 - acc: 0.5611 - val_loss: 0.7360 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.7097 - acc: 0.5611 - val_loss: 0.7343 - val_acc: 0.5571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7223 - acc: 0.5667 - val_loss: 0.7359 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7133 - acc: 0.5722 - val_loss: 0.7349 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7165 - acc: 0.5444 - val_loss: 0.7323 - val_acc: 0.5714\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7091 - acc: 0.5944 - val_loss: 0.7316 - val_acc: 0.5857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7060 - acc: 0.5778 - val_loss: 0.7305 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.7047 - acc: 0.5944 - val_loss: 0.7294 - val_acc: 0.5714\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7025 - acc: 0.6111 - val_loss: 0.7284 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6887 - acc: 0.6444 - val_loss: 0.7264 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6980 - acc: 0.6167 - val_loss: 0.7283 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6926 - acc: 0.6056 - val_loss: 0.7253 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6745 - acc: 0.6556 - val_loss: 0.7241 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6854 - acc: 0.6611 - val_loss: 0.7236 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6917 - acc: 0.6222 - val_loss: 0.7254 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6793 - acc: 0.6333 - val_loss: 0.7227 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6819 - acc: 0.6333 - val_loss: 0.7195 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6783 - acc: 0.6333 - val_loss: 0.7182 - val_acc: 0.6000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6711 - acc: 0.6944 - val_loss: 0.7182 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6641 - acc: 0.6611 - val_loss: 0.7169 - val_acc: 0.6143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6652 - acc: 0.6667 - val_loss: 0.7168 - val_acc: 0.6143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6459 - acc: 0.6778 - val_loss: 0.7136 - val_acc: 0.6000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6618 - acc: 0.6389 - val_loss: 0.7154 - val_acc: 0.5857\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6555 - acc: 0.6778 - val_loss: 0.7135 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6485 - acc: 0.6944 - val_loss: 0.7178 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6392 - acc: 0.7111 - val_loss: 0.7145 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6511 - acc: 0.6778 - val_loss: 0.7119 - val_acc: 0.6000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6380 - acc: 0.7222 - val_loss: 0.7132 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6314 - acc: 0.7222 - val_loss: 0.7117 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6407 - acc: 0.7000 - val_loss: 0.7155 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6349 - acc: 0.6833 - val_loss: 0.7176 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6229 - acc: 0.7278 - val_loss: 0.7146 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6176 - acc: 0.7167 - val_loss: 0.7093 - val_acc: 0.6857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6180 - acc: 0.7278 - val_loss: 0.7109 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6381 - acc: 0.6833 - val_loss: 0.7094 - val_acc: 0.6714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6241 - acc: 0.7111 - val_loss: 0.7063 - val_acc: 0.6857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6310 - acc: 0.7222 - val_loss: 0.7048 - val_acc: 0.6429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6068 - acc: 0.7778 - val_loss: 0.7043 - val_acc: 0.7000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6306 - acc: 0.6889 - val_loss: 0.7092 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6096 - acc: 0.7444 - val_loss: 0.7061 - val_acc: 0.6714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6261 - acc: 0.6944 - val_loss: 0.7100 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6138 - acc: 0.7389 - val_loss: 0.7056 - val_acc: 0.6857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6139 - acc: 0.7056 - val_loss: 0.7026 - val_acc: 0.6714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6020 - acc: 0.7500 - val_loss: 0.7030 - val_acc: 0.7000\n",
      "Epoch 54/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.5977 - acc: 0.7222 - val_loss: 0.7022 - val_acc: 0.6857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5901 - acc: 0.7667 - val_loss: 0.7045 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5948 - acc: 0.7667 - val_loss: 0.7015 - val_acc: 0.7000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5861 - acc: 0.7833 - val_loss: 0.7003 - val_acc: 0.6857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5915 - acc: 0.7611 - val_loss: 0.7016 - val_acc: 0.7000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5667 - acc: 0.7722 - val_loss: 0.7024 - val_acc: 0.7000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5867 - acc: 0.7444 - val_loss: 0.7022 - val_acc: 0.6857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5827 - acc: 0.7444 - val_loss: 0.7122 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5575 - acc: 0.7778 - val_loss: 0.7019 - val_acc: 0.7000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5822 - acc: 0.7667 - val_loss: 0.7050 - val_acc: 0.6571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5719 - acc: 0.7611 - val_loss: 0.6992 - val_acc: 0.6714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5481 - acc: 0.8111 - val_loss: 0.7030 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5889 - acc: 0.7278 - val_loss: 0.6952 - val_acc: 0.7000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5642 - acc: 0.7500 - val_loss: 0.7008 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5776 - acc: 0.7500 - val_loss: 0.6985 - val_acc: 0.6714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5632 - acc: 0.7389 - val_loss: 0.6982 - val_acc: 0.6857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5518 - acc: 0.7556 - val_loss: 0.6969 - val_acc: 0.6857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5709 - acc: 0.7444 - val_loss: 0.6948 - val_acc: 0.7143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5474 - acc: 0.7889 - val_loss: 0.6956 - val_acc: 0.6857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5514 - acc: 0.8222 - val_loss: 0.6981 - val_acc: 0.6857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5497 - acc: 0.7778 - val_loss: 0.6925 - val_acc: 0.7000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5347 - acc: 0.8167 - val_loss: 0.6914 - val_acc: 0.6857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.5192 - acc: 0.8222 - val_loss: 0.6935 - val_acc: 0.6857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5384 - acc: 0.7778 - val_loss: 0.6949 - val_acc: 0.6857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5303 - acc: 0.8000 - val_loss: 0.6941 - val_acc: 0.6857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5240 - acc: 0.8111 - val_loss: 0.6974 - val_acc: 0.7000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5357 - acc: 0.7833 - val_loss: 0.6991 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 112us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.7579 - acc: 0.5556 - val_loss: 0.7515 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7549 - acc: 0.5389 - val_loss: 0.7400 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7237 - acc: 0.5389 - val_loss: 0.7400 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7183 - acc: 0.5611 - val_loss: 0.7366 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7117 - acc: 0.5722 - val_loss: 0.7341 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7059 - acc: 0.5778 - val_loss: 0.7349 - val_acc: 0.5429\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7088 - acc: 0.5500 - val_loss: 0.7304 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7070 - acc: 0.6111 - val_loss: 0.7269 - val_acc: 0.5429\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6960 - acc: 0.5944 - val_loss: 0.7241 - val_acc: 0.5857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7012 - acc: 0.5667 - val_loss: 0.7220 - val_acc: 0.5714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7098 - acc: 0.5611 - val_loss: 0.7213 - val_acc: 0.5857\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7001 - acc: 0.6000 - val_loss: 0.7268 - val_acc: 0.5714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6991 - acc: 0.5889 - val_loss: 0.7217 - val_acc: 0.5857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6876 - acc: 0.6389 - val_loss: 0.7252 - val_acc: 0.5857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6818 - acc: 0.6056 - val_loss: 0.7221 - val_acc: 0.5857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6886 - acc: 0.5833 - val_loss: 0.7182 - val_acc: 0.6000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6747 - acc: 0.6444 - val_loss: 0.7162 - val_acc: 0.6000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6941 - acc: 0.6167 - val_loss: 0.7106 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6787 - acc: 0.6278 - val_loss: 0.7115 - val_acc: 0.5857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6635 - acc: 0.7000 - val_loss: 0.7069 - val_acc: 0.5857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6729 - acc: 0.6500 - val_loss: 0.7069 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6546 - acc: 0.6722 - val_loss: 0.7053 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6742 - acc: 0.6611 - val_loss: 0.7079 - val_acc: 0.6000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6557 - acc: 0.6667 - val_loss: 0.7093 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6565 - acc: 0.6444 - val_loss: 0.7014 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6586 - acc: 0.6611 - val_loss: 0.7020 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6597 - acc: 0.6500 - val_loss: 0.6975 - val_acc: 0.6286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6483 - acc: 0.6611 - val_loss: 0.6963 - val_acc: 0.6143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6463 - acc: 0.6556 - val_loss: 0.6992 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6655 - acc: 0.6444 - val_loss: 0.6999 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.6246 - acc: 0.7111 - val_loss: 0.6984 - val_acc: 0.6143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6404 - acc: 0.6778 - val_loss: 0.6996 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6386 - acc: 0.7000 - val_loss: 0.6984 - val_acc: 0.6000\n",
      "Epoch 34/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.6227 - acc: 0.7333 - val_loss: 0.6966 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6290 - acc: 0.7111 - val_loss: 0.6949 - val_acc: 0.6571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6267 - acc: 0.7000 - val_loss: 0.6923 - val_acc: 0.6571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6203 - acc: 0.7000 - val_loss: 0.6949 - val_acc: 0.6429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6272 - acc: 0.6889 - val_loss: 0.6997 - val_acc: 0.5857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6281 - acc: 0.7000 - val_loss: 0.6950 - val_acc: 0.6286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6082 - acc: 0.7111 - val_loss: 0.6899 - val_acc: 0.6857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6196 - acc: 0.7222 - val_loss: 0.6874 - val_acc: 0.6714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6038 - acc: 0.7611 - val_loss: 0.6905 - val_acc: 0.6429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6154 - acc: 0.7111 - val_loss: 0.6865 - val_acc: 0.6714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5966 - acc: 0.7667 - val_loss: 0.6901 - val_acc: 0.6714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6065 - acc: 0.7056 - val_loss: 0.6880 - val_acc: 0.6857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6002 - acc: 0.7389 - val_loss: 0.6897 - val_acc: 0.6571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5890 - acc: 0.7278 - val_loss: 0.6878 - val_acc: 0.7000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6136 - acc: 0.7056 - val_loss: 0.6849 - val_acc: 0.7000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5787 - acc: 0.7444 - val_loss: 0.6866 - val_acc: 0.6857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5818 - acc: 0.7333 - val_loss: 0.6799 - val_acc: 0.6714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5850 - acc: 0.7556 - val_loss: 0.6795 - val_acc: 0.6857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5777 - acc: 0.7611 - val_loss: 0.6785 - val_acc: 0.6714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5831 - acc: 0.7722 - val_loss: 0.6806 - val_acc: 0.6857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5782 - acc: 0.7389 - val_loss: 0.6781 - val_acc: 0.7000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5755 - acc: 0.7500 - val_loss: 0.6773 - val_acc: 0.6857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5751 - acc: 0.7667 - val_loss: 0.6759 - val_acc: 0.6714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5891 - acc: 0.7444 - val_loss: 0.6857 - val_acc: 0.7000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5547 - acc: 0.7611 - val_loss: 0.6735 - val_acc: 0.6571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5633 - acc: 0.7611 - val_loss: 0.6745 - val_acc: 0.6857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5589 - acc: 0.7778 - val_loss: 0.6815 - val_acc: 0.7143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5584 - acc: 0.7833 - val_loss: 0.6785 - val_acc: 0.7000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5496 - acc: 0.7944 - val_loss: 0.6795 - val_acc: 0.7000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.5512 - acc: 0.7889 - val_loss: 0.6828 - val_acc: 0.7143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5542 - acc: 0.7556 - val_loss: 0.6745 - val_acc: 0.6571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5344 - acc: 0.7722 - val_loss: 0.6769 - val_acc: 0.6714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5445 - acc: 0.7889 - val_loss: 0.6797 - val_acc: 0.6714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5453 - acc: 0.7667 - val_loss: 0.6777 - val_acc: 0.6571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5505 - acc: 0.7833 - val_loss: 0.6865 - val_acc: 0.7000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5302 - acc: 0.8111 - val_loss: 0.6741 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5268 - acc: 0.8333 - val_loss: 0.6763 - val_acc: 0.6714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5363 - acc: 0.7889 - val_loss: 0.6756 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5397 - acc: 0.8000 - val_loss: 0.6817 - val_acc: 0.6857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5270 - acc: 0.7889 - val_loss: 0.6877 - val_acc: 0.7000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5273 - acc: 0.7778 - val_loss: 0.6844 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5206 - acc: 0.7944 - val_loss: 0.6825 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5179 - acc: 0.8000 - val_loss: 0.6780 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5238 - acc: 0.7944 - val_loss: 0.6810 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5234 - acc: 0.7889 - val_loss: 0.6799 - val_acc: 0.6714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5305 - acc: 0.8167 - val_loss: 0.6819 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5156 - acc: 0.7889 - val_loss: 0.6813 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.7540 - acc: 0.4889 - val_loss: 0.7286 - val_acc: 0.5857\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7412 - acc: 0.5111 - val_loss: 0.7287 - val_acc: 0.5714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7447 - acc: 0.5056 - val_loss: 0.7317 - val_acc: 0.5714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7279 - acc: 0.5611 - val_loss: 0.7287 - val_acc: 0.5714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7185 - acc: 0.6056 - val_loss: 0.7288 - val_acc: 0.5714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7153 - acc: 0.5889 - val_loss: 0.7256 - val_acc: 0.6000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7108 - acc: 0.6111 - val_loss: 0.7264 - val_acc: 0.5857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7216 - acc: 0.5889 - val_loss: 0.7264 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6963 - acc: 0.6333 - val_loss: 0.7261 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7075 - acc: 0.6111 - val_loss: 0.7268 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7006 - acc: 0.6000 - val_loss: 0.7228 - val_acc: 0.5714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6884 - acc: 0.6556 - val_loss: 0.7202 - val_acc: 0.6000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6983 - acc: 0.6222 - val_loss: 0.7152 - val_acc: 0.6143\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6899 - acc: 0.6667 - val_loss: 0.7123 - val_acc: 0.6143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6786 - acc: 0.6778 - val_loss: 0.7098 - val_acc: 0.6143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6824 - acc: 0.6611 - val_loss: 0.7132 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6756 - acc: 0.6611 - val_loss: 0.7126 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6642 - acc: 0.6722 - val_loss: 0.7132 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6776 - acc: 0.6389 - val_loss: 0.7067 - val_acc: 0.6286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6637 - acc: 0.6667 - val_loss: 0.7036 - val_acc: 0.6429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6640 - acc: 0.6778 - val_loss: 0.7087 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6573 - acc: 0.6611 - val_loss: 0.7109 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6706 - acc: 0.6111 - val_loss: 0.7039 - val_acc: 0.6286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6514 - acc: 0.6889 - val_loss: 0.7042 - val_acc: 0.6143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6396 - acc: 0.7278 - val_loss: 0.7057 - val_acc: 0.6143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6580 - acc: 0.6667 - val_loss: 0.7029 - val_acc: 0.6143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6355 - acc: 0.7333 - val_loss: 0.7068 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6473 - acc: 0.7167 - val_loss: 0.7079 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6277 - acc: 0.7389 - val_loss: 0.7106 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6463 - acc: 0.7111 - val_loss: 0.7031 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6436 - acc: 0.7222 - val_loss: 0.7038 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6384 - acc: 0.7333 - val_loss: 0.7020 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6426 - acc: 0.6778 - val_loss: 0.6983 - val_acc: 0.5857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6407 - acc: 0.7000 - val_loss: 0.6970 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.6273 - acc: 0.7444 - val_loss: 0.6961 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.6468 - acc: 0.7167 - val_loss: 0.7011 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6146 - acc: 0.7000 - val_loss: 0.6974 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6292 - acc: 0.7056 - val_loss: 0.6978 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 95us/step - loss: 0.6109 - acc: 0.7278 - val_loss: 0.7022 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6099 - acc: 0.7444 - val_loss: 0.7038 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6223 - acc: 0.7000 - val_loss: 0.6961 - val_acc: 0.5857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6152 - acc: 0.7389 - val_loss: 0.6953 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6109 - acc: 0.7500 - val_loss: 0.6983 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 101us/step - loss: 0.5876 - acc: 0.7333 - val_loss: 0.7002 - val_acc: 0.5714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6000 - acc: 0.7444 - val_loss: 0.7044 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6067 - acc: 0.7056 - val_loss: 0.7033 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5907 - acc: 0.7611 - val_loss: 0.6988 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5934 - acc: 0.7389 - val_loss: 0.6991 - val_acc: 0.5571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5852 - acc: 0.7667 - val_loss: 0.7012 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5914 - acc: 0.7722 - val_loss: 0.7013 - val_acc: 0.5429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5865 - acc: 0.7667 - val_loss: 0.6953 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5596 - acc: 0.8056 - val_loss: 0.6937 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5818 - acc: 0.8000 - val_loss: 0.7023 - val_acc: 0.5571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5922 - acc: 0.7333 - val_loss: 0.6973 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5820 - acc: 0.7556 - val_loss: 0.6970 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5777 - acc: 0.7778 - val_loss: 0.7006 - val_acc: 0.5429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5685 - acc: 0.7722 - val_loss: 0.6950 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5686 - acc: 0.7611 - val_loss: 0.7019 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5652 - acc: 0.7667 - val_loss: 0.7025 - val_acc: 0.5571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5704 - acc: 0.7889 - val_loss: 0.6982 - val_acc: 0.5571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5461 - acc: 0.7778 - val_loss: 0.6929 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5625 - acc: 0.7611 - val_loss: 0.6920 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5468 - acc: 0.7833 - val_loss: 0.6993 - val_acc: 0.5429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5488 - acc: 0.7944 - val_loss: 0.6962 - val_acc: 0.5571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5443 - acc: 0.7889 - val_loss: 0.6995 - val_acc: 0.5571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5408 - acc: 0.7889 - val_loss: 0.7078 - val_acc: 0.5714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5294 - acc: 0.7889 - val_loss: 0.7112 - val_acc: 0.5571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5434 - acc: 0.7556 - val_loss: 0.6973 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5368 - acc: 0.7944 - val_loss: 0.6944 - val_acc: 0.5857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5360 - acc: 0.7889 - val_loss: 0.6951 - val_acc: 0.5714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5413 - acc: 0.7833 - val_loss: 0.6985 - val_acc: 0.5571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5371 - acc: 0.7889 - val_loss: 0.6995 - val_acc: 0.5714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5460 - acc: 0.7889 - val_loss: 0.6941 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5366 - acc: 0.8167 - val_loss: 0.6943 - val_acc: 0.5857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5220 - acc: 0.7944 - val_loss: 0.6947 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5404 - acc: 0.7944 - val_loss: 0.7006 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5160 - acc: 0.8167 - val_loss: 0.6976 - val_acc: 0.5857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5176 - acc: 0.8000 - val_loss: 0.7084 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5282 - acc: 0.8000 - val_loss: 0.7096 - val_acc: 0.5857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5199 - acc: 0.8167 - val_loss: 0.7085 - val_acc: 0.5714\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.7359 - acc: 0.5389 - val_loss: 0.7426 - val_acc: 0.5571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7316 - acc: 0.5833 - val_loss: 0.7411 - val_acc: 0.5571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7221 - acc: 0.5889 - val_loss: 0.7424 - val_acc: 0.5571\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7134 - acc: 0.5944 - val_loss: 0.7393 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7119 - acc: 0.6056 - val_loss: 0.7344 - val_acc: 0.5714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7042 - acc: 0.6222 - val_loss: 0.7327 - val_acc: 0.5714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7166 - acc: 0.5889 - val_loss: 0.7316 - val_acc: 0.5571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7043 - acc: 0.5778 - val_loss: 0.7311 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7005 - acc: 0.6000 - val_loss: 0.7283 - val_acc: 0.5714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6996 - acc: 0.5944 - val_loss: 0.7266 - val_acc: 0.5857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6991 - acc: 0.6167 - val_loss: 0.7237 - val_acc: 0.6000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6944 - acc: 0.6389 - val_loss: 0.7224 - val_acc: 0.6000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6947 - acc: 0.6389 - val_loss: 0.7221 - val_acc: 0.6000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6961 - acc: 0.6000 - val_loss: 0.7223 - val_acc: 0.6000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6834 - acc: 0.6444 - val_loss: 0.7220 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6987 - acc: 0.6389 - val_loss: 0.7228 - val_acc: 0.5857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6755 - acc: 0.6722 - val_loss: 0.7226 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6779 - acc: 0.6667 - val_loss: 0.7193 - val_acc: 0.6000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6676 - acc: 0.6722 - val_loss: 0.7190 - val_acc: 0.6000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6796 - acc: 0.6389 - val_loss: 0.7166 - val_acc: 0.5857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6786 - acc: 0.6500 - val_loss: 0.7153 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6737 - acc: 0.6611 - val_loss: 0.7169 - val_acc: 0.6143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6685 - acc: 0.6500 - val_loss: 0.7135 - val_acc: 0.6143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6605 - acc: 0.6833 - val_loss: 0.7129 - val_acc: 0.6000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6662 - acc: 0.6556 - val_loss: 0.7105 - val_acc: 0.6000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6599 - acc: 0.7167 - val_loss: 0.7125 - val_acc: 0.6286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6717 - acc: 0.6667 - val_loss: 0.7131 - val_acc: 0.6143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6536 - acc: 0.6833 - val_loss: 0.7134 - val_acc: 0.6143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6492 - acc: 0.7167 - val_loss: 0.7127 - val_acc: 0.6143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6509 - acc: 0.6556 - val_loss: 0.7094 - val_acc: 0.6143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6477 - acc: 0.6667 - val_loss: 0.7083 - val_acc: 0.6143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6353 - acc: 0.7278 - val_loss: 0.7085 - val_acc: 0.6143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6404 - acc: 0.7111 - val_loss: 0.7072 - val_acc: 0.6143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6439 - acc: 0.6444 - val_loss: 0.7112 - val_acc: 0.6286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6415 - acc: 0.6889 - val_loss: 0.7038 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6310 - acc: 0.7167 - val_loss: 0.7082 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6247 - acc: 0.7056 - val_loss: 0.7136 - val_acc: 0.6286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6466 - acc: 0.6889 - val_loss: 0.7110 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6273 - acc: 0.7222 - val_loss: 0.7074 - val_acc: 0.6143\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6216 - acc: 0.7278 - val_loss: 0.7105 - val_acc: 0.6143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6184 - acc: 0.7222 - val_loss: 0.7085 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6179 - acc: 0.7167 - val_loss: 0.7120 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6158 - acc: 0.7222 - val_loss: 0.7041 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6066 - acc: 0.7333 - val_loss: 0.7004 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6116 - acc: 0.7056 - val_loss: 0.7041 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5902 - acc: 0.7556 - val_loss: 0.6987 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6148 - acc: 0.7000 - val_loss: 0.6967 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6002 - acc: 0.7667 - val_loss: 0.6959 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6014 - acc: 0.7667 - val_loss: 0.6962 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6005 - acc: 0.7444 - val_loss: 0.6941 - val_acc: 0.6429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6035 - acc: 0.7333 - val_loss: 0.6997 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5938 - acc: 0.7667 - val_loss: 0.6933 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5967 - acc: 0.7333 - val_loss: 0.6965 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5940 - acc: 0.7333 - val_loss: 0.6927 - val_acc: 0.6143\n",
      "Epoch 55/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.5869 - acc: 0.7500 - val_loss: 0.6936 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5727 - acc: 0.7278 - val_loss: 0.6936 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5784 - acc: 0.7500 - val_loss: 0.6916 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5792 - acc: 0.7278 - val_loss: 0.6898 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5630 - acc: 0.7778 - val_loss: 0.6918 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5729 - acc: 0.7667 - val_loss: 0.6907 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5711 - acc: 0.7278 - val_loss: 0.6896 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5747 - acc: 0.7389 - val_loss: 0.6884 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5591 - acc: 0.7389 - val_loss: 0.6897 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5621 - acc: 0.7778 - val_loss: 0.7031 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5445 - acc: 0.7611 - val_loss: 0.6969 - val_acc: 0.6429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5768 - acc: 0.7611 - val_loss: 0.6866 - val_acc: 0.6429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5442 - acc: 0.7667 - val_loss: 0.6892 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5680 - acc: 0.7556 - val_loss: 0.6875 - val_acc: 0.6286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 86us/step - loss: 0.5695 - acc: 0.7889 - val_loss: 0.6885 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5462 - acc: 0.7778 - val_loss: 0.6946 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5540 - acc: 0.7444 - val_loss: 0.6893 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.5480 - acc: 0.7889 - val_loss: 0.6901 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.5334 - acc: 0.8000 - val_loss: 0.6920 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5442 - acc: 0.7611 - val_loss: 0.7003 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 96us/step - loss: 0.5365 - acc: 0.8056 - val_loss: 0.7000 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5460 - acc: 0.7611 - val_loss: 0.7004 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5161 - acc: 0.7722 - val_loss: 0.6937 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.5390 - acc: 0.7722 - val_loss: 0.6981 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5104 - acc: 0.8056 - val_loss: 0.7031 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5284 - acc: 0.8111 - val_loss: 0.7010 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.8972 - acc: 0.4722 - val_loss: 0.8109 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.8141 - acc: 0.4722 - val_loss: 0.7864 - val_acc: 0.3857\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 95us/step - loss: 0.7906 - acc: 0.4222 - val_loss: 0.7766 - val_acc: 0.4286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7586 - acc: 0.5444 - val_loss: 0.7735 - val_acc: 0.4000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7577 - acc: 0.5333 - val_loss: 0.7684 - val_acc: 0.4143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7441 - acc: 0.5333 - val_loss: 0.7664 - val_acc: 0.4286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7438 - acc: 0.5389 - val_loss: 0.7659 - val_acc: 0.4143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.7422 - acc: 0.5389 - val_loss: 0.7663 - val_acc: 0.4143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7325 - acc: 0.5667 - val_loss: 0.7642 - val_acc: 0.4143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7316 - acc: 0.5611 - val_loss: 0.7648 - val_acc: 0.4286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7308 - acc: 0.5444 - val_loss: 0.7639 - val_acc: 0.4429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7378 - acc: 0.5611 - val_loss: 0.7638 - val_acc: 0.4143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7202 - acc: 0.5667 - val_loss: 0.7637 - val_acc: 0.4000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7163 - acc: 0.5778 - val_loss: 0.7643 - val_acc: 0.4143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7160 - acc: 0.5944 - val_loss: 0.7635 - val_acc: 0.4286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7120 - acc: 0.6000 - val_loss: 0.7637 - val_acc: 0.4857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7104 - acc: 0.5833 - val_loss: 0.7636 - val_acc: 0.4571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7104 - acc: 0.5667 - val_loss: 0.7608 - val_acc: 0.4714\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7029 - acc: 0.5889 - val_loss: 0.7591 - val_acc: 0.4429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7052 - acc: 0.5833 - val_loss: 0.7563 - val_acc: 0.4429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6971 - acc: 0.6278 - val_loss: 0.7559 - val_acc: 0.4571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7033 - acc: 0.6167 - val_loss: 0.7527 - val_acc: 0.4429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7008 - acc: 0.6000 - val_loss: 0.7527 - val_acc: 0.4571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6974 - acc: 0.5833 - val_loss: 0.7493 - val_acc: 0.4714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6949 - acc: 0.6111 - val_loss: 0.7479 - val_acc: 0.4714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6946 - acc: 0.6056 - val_loss: 0.7440 - val_acc: 0.4857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6755 - acc: 0.6611 - val_loss: 0.7448 - val_acc: 0.4571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6766 - acc: 0.6556 - val_loss: 0.7445 - val_acc: 0.4857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6728 - acc: 0.6667 - val_loss: 0.7454 - val_acc: 0.4714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6778 - acc: 0.6333 - val_loss: 0.7432 - val_acc: 0.4857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6849 - acc: 0.6222 - val_loss: 0.7425 - val_acc: 0.4714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6708 - acc: 0.6500 - val_loss: 0.7406 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6778 - acc: 0.6667 - val_loss: 0.7408 - val_acc: 0.5000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6798 - acc: 0.6444 - val_loss: 0.7403 - val_acc: 0.4857\n",
      "Epoch 35/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.6495 - acc: 0.7111 - val_loss: 0.7386 - val_acc: 0.4857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6559 - acc: 0.7000 - val_loss: 0.7379 - val_acc: 0.4857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6653 - acc: 0.6833 - val_loss: 0.7373 - val_acc: 0.5000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6544 - acc: 0.6833 - val_loss: 0.7379 - val_acc: 0.4857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6526 - acc: 0.6778 - val_loss: 0.7383 - val_acc: 0.4857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6558 - acc: 0.6667 - val_loss: 0.7364 - val_acc: 0.5000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6523 - acc: 0.6833 - val_loss: 0.7375 - val_acc: 0.4857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6542 - acc: 0.6944 - val_loss: 0.7362 - val_acc: 0.4857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6438 - acc: 0.7000 - val_loss: 0.7362 - val_acc: 0.5000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6328 - acc: 0.7000 - val_loss: 0.7337 - val_acc: 0.5143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6455 - acc: 0.6833 - val_loss: 0.7353 - val_acc: 0.5143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6421 - acc: 0.6889 - val_loss: 0.7346 - val_acc: 0.5143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6231 - acc: 0.7278 - val_loss: 0.7321 - val_acc: 0.5143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6278 - acc: 0.7167 - val_loss: 0.7319 - val_acc: 0.5286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6266 - acc: 0.7556 - val_loss: 0.7352 - val_acc: 0.5429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6288 - acc: 0.6833 - val_loss: 0.7341 - val_acc: 0.5286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6237 - acc: 0.7000 - val_loss: 0.7288 - val_acc: 0.5286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6119 - acc: 0.7333 - val_loss: 0.7289 - val_acc: 0.5000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6143 - acc: 0.7333 - val_loss: 0.7284 - val_acc: 0.5429\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6240 - acc: 0.7111 - val_loss: 0.7283 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6165 - acc: 0.7278 - val_loss: 0.7226 - val_acc: 0.5429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6214 - acc: 0.7167 - val_loss: 0.7187 - val_acc: 0.5429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6092 - acc: 0.7611 - val_loss: 0.7213 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6013 - acc: 0.7389 - val_loss: 0.7193 - val_acc: 0.5429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6005 - acc: 0.7500 - val_loss: 0.7216 - val_acc: 0.5714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6110 - acc: 0.7222 - val_loss: 0.7159 - val_acc: 0.5571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6005 - acc: 0.7222 - val_loss: 0.7148 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6021 - acc: 0.7444 - val_loss: 0.7220 - val_acc: 0.5857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5872 - acc: 0.7722 - val_loss: 0.7159 - val_acc: 0.5429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5967 - acc: 0.7500 - val_loss: 0.7216 - val_acc: 0.5857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5856 - acc: 0.7500 - val_loss: 0.7243 - val_acc: 0.5857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5867 - acc: 0.7500 - val_loss: 0.7293 - val_acc: 0.5571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5897 - acc: 0.7167 - val_loss: 0.7186 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5734 - acc: 0.7667 - val_loss: 0.7230 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5807 - acc: 0.7611 - val_loss: 0.7204 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5831 - acc: 0.7611 - val_loss: 0.7165 - val_acc: 0.5714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5702 - acc: 0.7722 - val_loss: 0.7191 - val_acc: 0.5714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5595 - acc: 0.7778 - val_loss: 0.7205 - val_acc: 0.5571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5721 - acc: 0.7389 - val_loss: 0.7231 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5671 - acc: 0.7556 - val_loss: 0.7153 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5663 - acc: 0.7722 - val_loss: 0.7177 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5633 - acc: 0.7667 - val_loss: 0.7152 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5609 - acc: 0.7333 - val_loss: 0.7174 - val_acc: 0.5857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5443 - acc: 0.7833 - val_loss: 0.7240 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 87us/step - loss: 0.5387 - acc: 0.7778 - val_loss: 0.7312 - val_acc: 0.5857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5570 - acc: 0.7722 - val_loss: 0.7291 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.7697 - acc: 0.5111 - val_loss: 0.7489 - val_acc: 0.5429\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7519 - acc: 0.5222 - val_loss: 0.7466 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7271 - acc: 0.5500 - val_loss: 0.7427 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7353 - acc: 0.5444 - val_loss: 0.7408 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7165 - acc: 0.5778 - val_loss: 0.7391 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7338 - acc: 0.5167 - val_loss: 0.7322 - val_acc: 0.5714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7154 - acc: 0.5722 - val_loss: 0.7289 - val_acc: 0.5857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7167 - acc: 0.5833 - val_loss: 0.7293 - val_acc: 0.5714\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7080 - acc: 0.6056 - val_loss: 0.7316 - val_acc: 0.5429\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7076 - acc: 0.5611 - val_loss: 0.7373 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7072 - acc: 0.6000 - val_loss: 0.7294 - val_acc: 0.5571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7109 - acc: 0.5722 - val_loss: 0.7226 - val_acc: 0.6000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6966 - acc: 0.6278 - val_loss: 0.7207 - val_acc: 0.6143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6985 - acc: 0.6444 - val_loss: 0.7251 - val_acc: 0.5857\n",
      "Epoch 15/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/step - loss: 0.6970 - acc: 0.6056 - val_loss: 0.7283 - val_acc: 0.5571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6877 - acc: 0.5722 - val_loss: 0.7274 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6989 - acc: 0.5944 - val_loss: 0.7272 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7116 - acc: 0.5722 - val_loss: 0.7241 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6820 - acc: 0.6167 - val_loss: 0.7207 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6929 - acc: 0.5500 - val_loss: 0.7136 - val_acc: 0.6286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6886 - acc: 0.5833 - val_loss: 0.7103 - val_acc: 0.6286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6712 - acc: 0.6833 - val_loss: 0.7120 - val_acc: 0.6143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6799 - acc: 0.6278 - val_loss: 0.7101 - val_acc: 0.6286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6828 - acc: 0.6389 - val_loss: 0.7117 - val_acc: 0.6000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6743 - acc: 0.6389 - val_loss: 0.7082 - val_acc: 0.6000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6720 - acc: 0.6333 - val_loss: 0.7056 - val_acc: 0.6143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6743 - acc: 0.6167 - val_loss: 0.7078 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6705 - acc: 0.6389 - val_loss: 0.7008 - val_acc: 0.6429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6558 - acc: 0.6944 - val_loss: 0.7054 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6696 - acc: 0.6278 - val_loss: 0.7033 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6463 - acc: 0.6833 - val_loss: 0.7027 - val_acc: 0.6000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6587 - acc: 0.6611 - val_loss: 0.7013 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6451 - acc: 0.6722 - val_loss: 0.6966 - val_acc: 0.6143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6330 - acc: 0.7222 - val_loss: 0.6963 - val_acc: 0.6143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6424 - acc: 0.6667 - val_loss: 0.6910 - val_acc: 0.6429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6386 - acc: 0.7278 - val_loss: 0.6994 - val_acc: 0.6000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6344 - acc: 0.6556 - val_loss: 0.6900 - val_acc: 0.6286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6247 - acc: 0.6778 - val_loss: 0.6852 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6124 - acc: 0.7389 - val_loss: 0.6846 - val_acc: 0.6429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6101 - acc: 0.7611 - val_loss: 0.6890 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6259 - acc: 0.7333 - val_loss: 0.6850 - val_acc: 0.6429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6140 - acc: 0.7222 - val_loss: 0.6832 - val_acc: 0.6429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6158 - acc: 0.7389 - val_loss: 0.6786 - val_acc: 0.6429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6174 - acc: 0.7444 - val_loss: 0.6818 - val_acc: 0.6429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6119 - acc: 0.7000 - val_loss: 0.6818 - val_acc: 0.6286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6074 - acc: 0.7333 - val_loss: 0.6814 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6043 - acc: 0.7500 - val_loss: 0.6839 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6005 - acc: 0.7500 - val_loss: 0.6792 - val_acc: 0.6429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5945 - acc: 0.7833 - val_loss: 0.6782 - val_acc: 0.6571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5819 - acc: 0.7556 - val_loss: 0.6822 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5987 - acc: 0.7333 - val_loss: 0.6831 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5953 - acc: 0.7722 - val_loss: 0.6810 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5829 - acc: 0.7389 - val_loss: 0.6740 - val_acc: 0.6857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5732 - acc: 0.7889 - val_loss: 0.6818 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5837 - acc: 0.7611 - val_loss: 0.6786 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5896 - acc: 0.7111 - val_loss: 0.6728 - val_acc: 0.6571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5893 - acc: 0.7667 - val_loss: 0.6733 - val_acc: 0.6714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5755 - acc: 0.7778 - val_loss: 0.6735 - val_acc: 0.6714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5690 - acc: 0.7722 - val_loss: 0.6738 - val_acc: 0.6857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5583 - acc: 0.8000 - val_loss: 0.6807 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5608 - acc: 0.8000 - val_loss: 0.6699 - val_acc: 0.6571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5656 - acc: 0.7611 - val_loss: 0.6698 - val_acc: 0.6571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5684 - acc: 0.7722 - val_loss: 0.6807 - val_acc: 0.6714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5738 - acc: 0.7556 - val_loss: 0.6835 - val_acc: 0.6571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5657 - acc: 0.7556 - val_loss: 0.6716 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5453 - acc: 0.8222 - val_loss: 0.6757 - val_acc: 0.6429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5465 - acc: 0.7667 - val_loss: 0.6762 - val_acc: 0.6571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5560 - acc: 0.7667 - val_loss: 0.6829 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5396 - acc: 0.7889 - val_loss: 0.6727 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5344 - acc: 0.7944 - val_loss: 0.6792 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5349 - acc: 0.7833 - val_loss: 0.6861 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5347 - acc: 0.7722 - val_loss: 0.6789 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5276 - acc: 0.7611 - val_loss: 0.6761 - val_acc: 0.6714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5267 - acc: 0.8056 - val_loss: 0.6733 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5132 - acc: 0.8167 - val_loss: 0.6741 - val_acc: 0.6714\n",
      "Epoch 76/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 103us/step - loss: 0.5094 - acc: 0.8167 - val_loss: 0.6803 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5229 - acc: 0.7889 - val_loss: 0.6745 - val_acc: 0.6857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5197 - acc: 0.7889 - val_loss: 0.6803 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5266 - acc: 0.7944 - val_loss: 0.6805 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5017 - acc: 0.8111 - val_loss: 0.6849 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.7686 - acc: 0.5389 - val_loss: 0.8164 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7460 - acc: 0.5556 - val_loss: 0.7893 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7222 - acc: 0.5833 - val_loss: 0.7840 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7260 - acc: 0.5500 - val_loss: 0.7870 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7184 - acc: 0.5778 - val_loss: 0.7894 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7145 - acc: 0.5833 - val_loss: 0.7800 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7149 - acc: 0.5611 - val_loss: 0.7818 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7141 - acc: 0.5444 - val_loss: 0.7801 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7120 - acc: 0.5778 - val_loss: 0.7757 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6980 - acc: 0.6111 - val_loss: 0.7712 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6960 - acc: 0.5944 - val_loss: 0.7666 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6869 - acc: 0.6222 - val_loss: 0.7642 - val_acc: 0.4857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6971 - acc: 0.5778 - val_loss: 0.7697 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6994 - acc: 0.5889 - val_loss: 0.7740 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6832 - acc: 0.5944 - val_loss: 0.7724 - val_acc: 0.4857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6801 - acc: 0.6000 - val_loss: 0.7796 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6772 - acc: 0.6056 - val_loss: 0.7705 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6677 - acc: 0.6444 - val_loss: 0.7627 - val_acc: 0.5714\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6756 - acc: 0.6444 - val_loss: 0.7613 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6723 - acc: 0.6556 - val_loss: 0.7646 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6661 - acc: 0.6278 - val_loss: 0.7629 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6595 - acc: 0.6278 - val_loss: 0.7598 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6687 - acc: 0.6556 - val_loss: 0.7594 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6498 - acc: 0.7056 - val_loss: 0.7555 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6641 - acc: 0.6778 - val_loss: 0.7590 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6472 - acc: 0.6667 - val_loss: 0.7560 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6561 - acc: 0.6722 - val_loss: 0.7537 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6581 - acc: 0.6500 - val_loss: 0.7555 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6597 - acc: 0.6833 - val_loss: 0.7551 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6411 - acc: 0.6667 - val_loss: 0.7662 - val_acc: 0.5429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6538 - acc: 0.6667 - val_loss: 0.7662 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6266 - acc: 0.6944 - val_loss: 0.7654 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6233 - acc: 0.7222 - val_loss: 0.7558 - val_acc: 0.5000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6323 - acc: 0.7056 - val_loss: 0.7611 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6140 - acc: 0.7167 - val_loss: 0.7544 - val_acc: 0.5000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6445 - acc: 0.7167 - val_loss: 0.7550 - val_acc: 0.5143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6232 - acc: 0.7000 - val_loss: 0.7637 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6153 - acc: 0.7000 - val_loss: 0.7624 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6267 - acc: 0.7111 - val_loss: 0.7591 - val_acc: 0.5000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6165 - acc: 0.7389 - val_loss: 0.7593 - val_acc: 0.5000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6065 - acc: 0.7278 - val_loss: 0.7546 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6136 - acc: 0.7389 - val_loss: 0.7612 - val_acc: 0.5286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6052 - acc: 0.7111 - val_loss: 0.7525 - val_acc: 0.5429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6149 - acc: 0.7222 - val_loss: 0.7538 - val_acc: 0.5286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6076 - acc: 0.7556 - val_loss: 0.7584 - val_acc: 0.5143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5903 - acc: 0.7722 - val_loss: 0.7645 - val_acc: 0.5143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5798 - acc: 0.7556 - val_loss: 0.7686 - val_acc: 0.5143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5809 - acc: 0.7556 - val_loss: 0.7783 - val_acc: 0.5286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5733 - acc: 0.7611 - val_loss: 0.7778 - val_acc: 0.5286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.5981 - acc: 0.718 - 0s 92us/step - loss: 0.5967 - acc: 0.7389 - val_loss: 0.7694 - val_acc: 0.5000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5916 - acc: 0.7278 - val_loss: 0.7817 - val_acc: 0.5429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5857 - acc: 0.7500 - val_loss: 0.7737 - val_acc: 0.5000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5778 - acc: 0.7556 - val_loss: 0.7685 - val_acc: 0.5000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5641 - acc: 0.8000 - val_loss: 0.7686 - val_acc: 0.5143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5712 - acc: 0.7500 - val_loss: 0.7714 - val_acc: 0.5000\n",
      "Epoch 56/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.5788 - acc: 0.7778 - val_loss: 0.7804 - val_acc: 0.5143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5582 - acc: 0.8111 - val_loss: 0.7782 - val_acc: 0.5143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5723 - acc: 0.7722 - val_loss: 0.7655 - val_acc: 0.5286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5609 - acc: 0.7944 - val_loss: 0.7863 - val_acc: 0.5143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5603 - acc: 0.7611 - val_loss: 0.7639 - val_acc: 0.5571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5457 - acc: 0.7889 - val_loss: 0.7876 - val_acc: 0.5143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5463 - acc: 0.7778 - val_loss: 0.7727 - val_acc: 0.5000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5375 - acc: 0.7889 - val_loss: 0.7759 - val_acc: 0.5143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5394 - acc: 0.8333 - val_loss: 0.7827 - val_acc: 0.5143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5412 - acc: 0.7833 - val_loss: 0.7637 - val_acc: 0.5429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5196 - acc: 0.8167 - val_loss: 0.7720 - val_acc: 0.5286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5368 - acc: 0.7944 - val_loss: 0.7955 - val_acc: 0.5286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5361 - acc: 0.7889 - val_loss: 0.7895 - val_acc: 0.5143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5385 - acc: 0.7833 - val_loss: 0.7816 - val_acc: 0.5143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5058 - acc: 0.8278 - val_loss: 0.7762 - val_acc: 0.5286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5234 - acc: 0.8000 - val_loss: 0.7715 - val_acc: 0.5286\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5322 - acc: 0.7944 - val_loss: 0.7802 - val_acc: 0.5286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5131 - acc: 0.8333 - val_loss: 0.7771 - val_acc: 0.5143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5103 - acc: 0.8000 - val_loss: 0.7799 - val_acc: 0.5143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5174 - acc: 0.8000 - val_loss: 0.7835 - val_acc: 0.5286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5077 - acc: 0.8333 - val_loss: 0.7717 - val_acc: 0.5429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5082 - acc: 0.8000 - val_loss: 0.7750 - val_acc: 0.5429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5245 - acc: 0.8000 - val_loss: 0.7842 - val_acc: 0.5143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.4933 - acc: 0.8222 - val_loss: 0.7967 - val_acc: 0.5286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5043 - acc: 0.8000 - val_loss: 0.7745 - val_acc: 0.5571\n",
      "80/80 [==============================] - 0s 112us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 2s 14ms/step - loss: 0.7416 - acc: 0.5222 - val_loss: 0.7505 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7434 - acc: 0.5222 - val_loss: 0.7500 - val_acc: 0.4714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7143 - acc: 0.5833 - val_loss: 0.7465 - val_acc: 0.4714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7133 - acc: 0.6167 - val_loss: 0.7494 - val_acc: 0.4714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7274 - acc: 0.5278 - val_loss: 0.7475 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7033 - acc: 0.5778 - val_loss: 0.7506 - val_acc: 0.4714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 99us/step - loss: 0.7070 - acc: 0.5667 - val_loss: 0.7490 - val_acc: 0.4714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7121 - acc: 0.5778 - val_loss: 0.7428 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6760 - acc: 0.6889 - val_loss: 0.7385 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.6981 - acc: 0.6444 - val_loss: 0.7401 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7018 - acc: 0.6222 - val_loss: 0.7393 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6923 - acc: 0.6167 - val_loss: 0.7427 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6916 - acc: 0.6111 - val_loss: 0.7387 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6775 - acc: 0.6778 - val_loss: 0.7424 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6842 - acc: 0.6389 - val_loss: 0.7387 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 138us/step - loss: 0.6930 - acc: 0.6111 - val_loss: 0.7386 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 124us/step - loss: 0.6829 - acc: 0.6556 - val_loss: 0.7359 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6753 - acc: 0.6611 - val_loss: 0.7343 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6753 - acc: 0.6889 - val_loss: 0.7366 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6759 - acc: 0.6444 - val_loss: 0.7296 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6591 - acc: 0.6944 - val_loss: 0.7289 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6614 - acc: 0.6722 - val_loss: 0.7289 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6617 - acc: 0.7222 - val_loss: 0.7277 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6655 - acc: 0.6944 - val_loss: 0.7281 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6685 - acc: 0.6556 - val_loss: 0.7279 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6547 - acc: 0.7167 - val_loss: 0.7267 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6498 - acc: 0.6889 - val_loss: 0.7235 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6431 - acc: 0.7000 - val_loss: 0.7271 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6507 - acc: 0.7000 - val_loss: 0.7252 - val_acc: 0.5429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6302 - acc: 0.7556 - val_loss: 0.7255 - val_acc: 0.5429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6377 - acc: 0.7056 - val_loss: 0.7257 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6468 - acc: 0.7167 - val_loss: 0.7267 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6490 - acc: 0.6833 - val_loss: 0.7249 - val_acc: 0.5286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6396 - acc: 0.7333 - val_loss: 0.7231 - val_acc: 0.5429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6385 - acc: 0.7111 - val_loss: 0.7204 - val_acc: 0.5714\n",
      "Epoch 36/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6300 - acc: 0.7389 - val_loss: 0.7152 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6293 - acc: 0.7333 - val_loss: 0.7180 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6295 - acc: 0.7333 - val_loss: 0.7199 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6263 - acc: 0.7278 - val_loss: 0.7232 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6219 - acc: 0.7222 - val_loss: 0.7162 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6062 - acc: 0.7833 - val_loss: 0.7169 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6138 - acc: 0.7389 - val_loss: 0.7162 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6019 - acc: 0.7444 - val_loss: 0.7133 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5978 - acc: 0.7667 - val_loss: 0.7100 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5935 - acc: 0.7889 - val_loss: 0.7144 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5901 - acc: 0.7611 - val_loss: 0.7059 - val_acc: 0.5857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6052 - acc: 0.7444 - val_loss: 0.7110 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5887 - acc: 0.7722 - val_loss: 0.7054 - val_acc: 0.6000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5949 - acc: 0.7667 - val_loss: 0.7080 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5886 - acc: 0.7556 - val_loss: 0.7108 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5876 - acc: 0.7333 - val_loss: 0.7110 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5869 - acc: 0.7778 - val_loss: 0.7071 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5831 - acc: 0.7833 - val_loss: 0.7109 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5672 - acc: 0.7889 - val_loss: 0.7172 - val_acc: 0.5714\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5894 - acc: 0.7667 - val_loss: 0.7064 - val_acc: 0.5857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5853 - acc: 0.7722 - val_loss: 0.7123 - val_acc: 0.5857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5775 - acc: 0.7833 - val_loss: 0.7203 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5706 - acc: 0.7667 - val_loss: 0.7071 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5600 - acc: 0.7722 - val_loss: 0.7059 - val_acc: 0.6000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5613 - acc: 0.8111 - val_loss: 0.7100 - val_acc: 0.5714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5444 - acc: 0.8056 - val_loss: 0.7049 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5511 - acc: 0.8111 - val_loss: 0.7060 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5803 - acc: 0.7778 - val_loss: 0.7182 - val_acc: 0.5857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5484 - acc: 0.8000 - val_loss: 0.7136 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5522 - acc: 0.7722 - val_loss: 0.7084 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5491 - acc: 0.7944 - val_loss: 0.7148 - val_acc: 0.5857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5761 - acc: 0.7500 - val_loss: 0.7084 - val_acc: 0.5857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5377 - acc: 0.8000 - val_loss: 0.7053 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5601 - acc: 0.7611 - val_loss: 0.7060 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 110us/step - loss: 0.5524 - acc: 0.7722 - val_loss: 0.7142 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5545 - acc: 0.8056 - val_loss: 0.7090 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5368 - acc: 0.8167 - val_loss: 0.7067 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5257 - acc: 0.8111 - val_loss: 0.7146 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5260 - acc: 0.8278 - val_loss: 0.7175 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5394 - acc: 0.8167 - val_loss: 0.7124 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5129 - acc: 0.8556 - val_loss: 0.7169 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5080 - acc: 0.8389 - val_loss: 0.7139 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5209 - acc: 0.8278 - val_loss: 0.7285 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5056 - acc: 0.8111 - val_loss: 0.7106 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5155 - acc: 0.8389 - val_loss: 0.7171 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 14ms/step - loss: 0.7606 - acc: 0.5389 - val_loss: 0.7830 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7403 - acc: 0.5556 - val_loss: 0.7679 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7414 - acc: 0.5500 - val_loss: 0.7571 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7352 - acc: 0.5333 - val_loss: 0.7524 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7299 - acc: 0.5278 - val_loss: 0.7466 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7328 - acc: 0.5389 - val_loss: 0.7460 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7279 - acc: 0.5556 - val_loss: 0.7423 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7188 - acc: 0.5389 - val_loss: 0.7383 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7092 - acc: 0.5833 - val_loss: 0.7379 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7156 - acc: 0.5778 - val_loss: 0.7357 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7015 - acc: 0.5833 - val_loss: 0.7313 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7030 - acc: 0.5556 - val_loss: 0.7300 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7006 - acc: 0.5833 - val_loss: 0.7276 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7019 - acc: 0.6000 - val_loss: 0.7227 - val_acc: 0.5571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7054 - acc: 0.5944 - val_loss: 0.7218 - val_acc: 0.5714\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6855 - acc: 0.5944 - val_loss: 0.7188 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6966 - acc: 0.6222 - val_loss: 0.7176 - val_acc: 0.5714\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6858 - acc: 0.6111 - val_loss: 0.7139 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6917 - acc: 0.6000 - val_loss: 0.7154 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6754 - acc: 0.6222 - val_loss: 0.7150 - val_acc: 0.5857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6779 - acc: 0.6278 - val_loss: 0.7136 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6723 - acc: 0.6000 - val_loss: 0.7113 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6765 - acc: 0.6056 - val_loss: 0.7070 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6723 - acc: 0.6389 - val_loss: 0.7086 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6598 - acc: 0.6722 - val_loss: 0.7067 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6621 - acc: 0.6222 - val_loss: 0.7042 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6556 - acc: 0.6556 - val_loss: 0.7042 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6520 - acc: 0.6611 - val_loss: 0.7035 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6536 - acc: 0.6333 - val_loss: 0.7087 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6589 - acc: 0.6333 - val_loss: 0.7061 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6475 - acc: 0.6556 - val_loss: 0.7032 - val_acc: 0.5857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6584 - acc: 0.6389 - val_loss: 0.6993 - val_acc: 0.5857\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6343 - acc: 0.6778 - val_loss: 0.7012 - val_acc: 0.5857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6338 - acc: 0.6778 - val_loss: 0.7037 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6291 - acc: 0.6722 - val_loss: 0.6995 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6176 - acc: 0.7278 - val_loss: 0.6973 - val_acc: 0.5857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6248 - acc: 0.7056 - val_loss: 0.6924 - val_acc: 0.5571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6327 - acc: 0.7444 - val_loss: 0.6932 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6227 - acc: 0.6944 - val_loss: 0.7012 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6208 - acc: 0.6833 - val_loss: 0.6909 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6093 - acc: 0.7500 - val_loss: 0.6861 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6088 - acc: 0.7500 - val_loss: 0.6897 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 91us/step - loss: 0.6080 - acc: 0.7167 - val_loss: 0.6881 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6048 - acc: 0.7000 - val_loss: 0.6811 - val_acc: 0.6429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6112 - acc: 0.7444 - val_loss: 0.6783 - val_acc: 0.6429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6098 - acc: 0.7389 - val_loss: 0.6793 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5997 - acc: 0.7667 - val_loss: 0.6797 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5785 - acc: 0.7889 - val_loss: 0.6879 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5873 - acc: 0.7611 - val_loss: 0.6731 - val_acc: 0.6857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5990 - acc: 0.7778 - val_loss: 0.6741 - val_acc: 0.6714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6067 - acc: 0.7333 - val_loss: 0.6765 - val_acc: 0.6286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5671 - acc: 0.7944 - val_loss: 0.6769 - val_acc: 0.6286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5796 - acc: 0.7500 - val_loss: 0.6776 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.5825 - acc: 0.7333 - val_loss: 0.6689 - val_acc: 0.6857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5726 - acc: 0.8056 - val_loss: 0.6761 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5804 - acc: 0.7667 - val_loss: 0.6779 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5571 - acc: 0.7722 - val_loss: 0.6736 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5653 - acc: 0.7722 - val_loss: 0.6702 - val_acc: 0.6714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5569 - acc: 0.7944 - val_loss: 0.6767 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5561 - acc: 0.7889 - val_loss: 0.6691 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5476 - acc: 0.7889 - val_loss: 0.6631 - val_acc: 0.6857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5413 - acc: 0.8056 - val_loss: 0.6621 - val_acc: 0.6571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5438 - acc: 0.8333 - val_loss: 0.6746 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5568 - acc: 0.7944 - val_loss: 0.6737 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5437 - acc: 0.8000 - val_loss: 0.6615 - val_acc: 0.6857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5528 - acc: 0.8167 - val_loss: 0.6620 - val_acc: 0.6857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5360 - acc: 0.7889 - val_loss: 0.6578 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5427 - acc: 0.7889 - val_loss: 0.6653 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5231 - acc: 0.8056 - val_loss: 0.6676 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 99us/step - loss: 0.5307 - acc: 0.7889 - val_loss: 0.6661 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5332 - acc: 0.7944 - val_loss: 0.6558 - val_acc: 0.6714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5286 - acc: 0.8111 - val_loss: 0.6750 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5051 - acc: 0.8222 - val_loss: 0.6601 - val_acc: 0.6857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5268 - acc: 0.8167 - val_loss: 0.6793 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5068 - acc: 0.8000 - val_loss: 0.6616 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5128 - acc: 0.8000 - val_loss: 0.6589 - val_acc: 0.6714\n",
      "Epoch 77/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 89us/step - loss: 0.5248 - acc: 0.7944 - val_loss: 0.6537 - val_acc: 0.6857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.4929 - acc: 0.8333 - val_loss: 0.6671 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.4954 - acc: 0.8167 - val_loss: 0.6584 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5079 - acc: 0.7944 - val_loss: 0.6725 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 112us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 14ms/step - loss: 0.7919 - acc: 0.5111 - val_loss: 0.7080 - val_acc: 0.6000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7601 - acc: 0.5278 - val_loss: 0.7007 - val_acc: 0.6000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7413 - acc: 0.5278 - val_loss: 0.6999 - val_acc: 0.6000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7254 - acc: 0.5556 - val_loss: 0.6974 - val_acc: 0.6143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7427 - acc: 0.5333 - val_loss: 0.6971 - val_acc: 0.6714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 123us/step - loss: 0.7251 - acc: 0.5500 - val_loss: 0.6948 - val_acc: 0.6857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7200 - acc: 0.5500 - val_loss: 0.6910 - val_acc: 0.6857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7091 - acc: 0.5833 - val_loss: 0.6888 - val_acc: 0.6714\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7143 - acc: 0.5889 - val_loss: 0.6897 - val_acc: 0.7000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7054 - acc: 0.6167 - val_loss: 0.6882 - val_acc: 0.6714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6933 - acc: 0.6000 - val_loss: 0.6864 - val_acc: 0.6714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6881 - acc: 0.6167 - val_loss: 0.6833 - val_acc: 0.6714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6883 - acc: 0.5833 - val_loss: 0.6801 - val_acc: 0.6714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6879 - acc: 0.5944 - val_loss: 0.6844 - val_acc: 0.6714\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6695 - acc: 0.6500 - val_loss: 0.6826 - val_acc: 0.6714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6770 - acc: 0.6278 - val_loss: 0.6800 - val_acc: 0.6429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6716 - acc: 0.6722 - val_loss: 0.6750 - val_acc: 0.7000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6626 - acc: 0.6444 - val_loss: 0.6784 - val_acc: 0.6429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6659 - acc: 0.6556 - val_loss: 0.6744 - val_acc: 0.7000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6643 - acc: 0.6333 - val_loss: 0.6705 - val_acc: 0.7143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 104us/step - loss: 0.6504 - acc: 0.6778 - val_loss: 0.6743 - val_acc: 0.6571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6581 - acc: 0.6722 - val_loss: 0.6681 - val_acc: 0.7143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6675 - acc: 0.6389 - val_loss: 0.6757 - val_acc: 0.6429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6484 - acc: 0.6889 - val_loss: 0.6690 - val_acc: 0.6857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6455 - acc: 0.6611 - val_loss: 0.6731 - val_acc: 0.6714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6349 - acc: 0.6667 - val_loss: 0.6729 - val_acc: 0.6571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6465 - acc: 0.6611 - val_loss: 0.6684 - val_acc: 0.6857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6330 - acc: 0.7167 - val_loss: 0.6745 - val_acc: 0.6714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6384 - acc: 0.7000 - val_loss: 0.6689 - val_acc: 0.7000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6356 - acc: 0.6833 - val_loss: 0.6611 - val_acc: 0.7000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6389 - acc: 0.6556 - val_loss: 0.6615 - val_acc: 0.7000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6321 - acc: 0.7000 - val_loss: 0.6626 - val_acc: 0.7000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6150 - acc: 0.7111 - val_loss: 0.6664 - val_acc: 0.7000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6402 - acc: 0.6778 - val_loss: 0.6631 - val_acc: 0.6857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6186 - acc: 0.6667 - val_loss: 0.6744 - val_acc: 0.7000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6290 - acc: 0.6722 - val_loss: 0.6785 - val_acc: 0.7286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6202 - acc: 0.6722 - val_loss: 0.6660 - val_acc: 0.6857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6153 - acc: 0.7000 - val_loss: 0.6664 - val_acc: 0.6857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6019 - acc: 0.6944 - val_loss: 0.6623 - val_acc: 0.7000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6085 - acc: 0.7167 - val_loss: 0.6719 - val_acc: 0.7000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6037 - acc: 0.7333 - val_loss: 0.6643 - val_acc: 0.6857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5889 - acc: 0.7333 - val_loss: 0.6714 - val_acc: 0.7000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6006 - acc: 0.7389 - val_loss: 0.6617 - val_acc: 0.7000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5978 - acc: 0.7167 - val_loss: 0.6637 - val_acc: 0.6857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5911 - acc: 0.7111 - val_loss: 0.6607 - val_acc: 0.6857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5956 - acc: 0.7222 - val_loss: 0.6699 - val_acc: 0.6857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5874 - acc: 0.7667 - val_loss: 0.6592 - val_acc: 0.7143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5799 - acc: 0.7278 - val_loss: 0.6646 - val_acc: 0.6857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5800 - acc: 0.7167 - val_loss: 0.6626 - val_acc: 0.6857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5895 - acc: 0.7333 - val_loss: 0.6664 - val_acc: 0.6857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5638 - acc: 0.7278 - val_loss: 0.6639 - val_acc: 0.6857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5712 - acc: 0.7667 - val_loss: 0.6547 - val_acc: 0.7286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5728 - acc: 0.7333 - val_loss: 0.6647 - val_acc: 0.6857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5475 - acc: 0.7722 - val_loss: 0.6717 - val_acc: 0.7000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5552 - acc: 0.7833 - val_loss: 0.6628 - val_acc: 0.6857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5675 - acc: 0.7167 - val_loss: 0.6694 - val_acc: 0.7000\n",
      "Epoch 57/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.5566 - acc: 0.7444 - val_loss: 0.6618 - val_acc: 0.7143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5758 - acc: 0.7389 - val_loss: 0.6716 - val_acc: 0.7143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5524 - acc: 0.7722 - val_loss: 0.6719 - val_acc: 0.7143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5759 - acc: 0.7389 - val_loss: 0.6696 - val_acc: 0.6857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5611 - acc: 0.7722 - val_loss: 0.6590 - val_acc: 0.7143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5742 - acc: 0.7611 - val_loss: 0.6619 - val_acc: 0.7000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5148 - acc: 0.8167 - val_loss: 0.6615 - val_acc: 0.7000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5379 - acc: 0.7833 - val_loss: 0.6653 - val_acc: 0.7000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5268 - acc: 0.7944 - val_loss: 0.6661 - val_acc: 0.7000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5269 - acc: 0.7667 - val_loss: 0.6611 - val_acc: 0.7286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5435 - acc: 0.7722 - val_loss: 0.6636 - val_acc: 0.7000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5306 - acc: 0.7667 - val_loss: 0.6604 - val_acc: 0.7286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5419 - acc: 0.7389 - val_loss: 0.6741 - val_acc: 0.7000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5093 - acc: 0.7889 - val_loss: 0.6651 - val_acc: 0.7143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5272 - acc: 0.7889 - val_loss: 0.6753 - val_acc: 0.7000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5346 - acc: 0.7667 - val_loss: 0.6842 - val_acc: 0.7286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5088 - acc: 0.8278 - val_loss: 0.6717 - val_acc: 0.7143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5281 - acc: 0.7611 - val_loss: 0.6812 - val_acc: 0.7143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5285 - acc: 0.7944 - val_loss: 0.6770 - val_acc: 0.7000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5069 - acc: 0.8000 - val_loss: 0.6769 - val_acc: 0.7000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.4822 - acc: 0.8667 - val_loss: 0.6948 - val_acc: 0.7000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.4937 - acc: 0.8111 - val_loss: 0.6760 - val_acc: 0.7143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5152 - acc: 0.7833 - val_loss: 0.6861 - val_acc: 0.6857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.4973 - acc: 0.8111 - val_loss: 0.6873 - val_acc: 0.6857\n",
      "80/80 [==============================] - 0s 112us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.9623 - acc: 0.4611 - val_loss: 0.8018 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.8693 - acc: 0.4611 - val_loss: 0.7720 - val_acc: 0.5429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.8278 - acc: 0.5056 - val_loss: 0.7532 - val_acc: 0.5857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.8047 - acc: 0.4889 - val_loss: 0.7416 - val_acc: 0.5714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7810 - acc: 0.5000 - val_loss: 0.7350 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7685 - acc: 0.5167 - val_loss: 0.7305 - val_acc: 0.5429\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7492 - acc: 0.5056 - val_loss: 0.7277 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7550 - acc: 0.5000 - val_loss: 0.7262 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7504 - acc: 0.4833 - val_loss: 0.7261 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7374 - acc: 0.5222 - val_loss: 0.7248 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7337 - acc: 0.4944 - val_loss: 0.7246 - val_acc: 0.5571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7289 - acc: 0.5778 - val_loss: 0.7241 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7235 - acc: 0.6000 - val_loss: 0.7234 - val_acc: 0.5571\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7166 - acc: 0.5778 - val_loss: 0.7239 - val_acc: 0.5857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7241 - acc: 0.5333 - val_loss: 0.7231 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7174 - acc: 0.5778 - val_loss: 0.7222 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7036 - acc: 0.6167 - val_loss: 0.7225 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7129 - acc: 0.5667 - val_loss: 0.7231 - val_acc: 0.6000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6964 - acc: 0.6500 - val_loss: 0.7223 - val_acc: 0.6143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7045 - acc: 0.6333 - val_loss: 0.7225 - val_acc: 0.6143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6998 - acc: 0.6222 - val_loss: 0.7212 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7018 - acc: 0.6222 - val_loss: 0.7231 - val_acc: 0.5857\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.6968 - acc: 0.6167 - val_loss: 0.7233 - val_acc: 0.5429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6976 - acc: 0.6389 - val_loss: 0.7220 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6947 - acc: 0.6056 - val_loss: 0.7219 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7029 - acc: 0.6333 - val_loss: 0.7194 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6789 - acc: 0.6667 - val_loss: 0.7223 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6886 - acc: 0.6000 - val_loss: 0.7178 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6741 - acc: 0.6556 - val_loss: 0.7143 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6737 - acc: 0.6667 - val_loss: 0.7168 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6663 - acc: 0.6556 - val_loss: 0.7118 - val_acc: 0.5857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6775 - acc: 0.6667 - val_loss: 0.7110 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6573 - acc: 0.6556 - val_loss: 0.7078 - val_acc: 0.5857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 91us/step - loss: 0.6602 - acc: 0.6833 - val_loss: 0.7030 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6693 - acc: 0.6778 - val_loss: 0.7067 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6487 - acc: 0.7056 - val_loss: 0.7084 - val_acc: 0.5714\n",
      "Epoch 37/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6565 - acc: 0.7000 - val_loss: 0.7065 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6527 - acc: 0.6667 - val_loss: 0.7059 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6492 - acc: 0.7222 - val_loss: 0.7006 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6527 - acc: 0.7278 - val_loss: 0.6985 - val_acc: 0.6143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6491 - acc: 0.6833 - val_loss: 0.6979 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6452 - acc: 0.7000 - val_loss: 0.6988 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6509 - acc: 0.6944 - val_loss: 0.6991 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6260 - acc: 0.7222 - val_loss: 0.6910 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6299 - acc: 0.7167 - val_loss: 0.6956 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6330 - acc: 0.7278 - val_loss: 0.6942 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6209 - acc: 0.7444 - val_loss: 0.6975 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6201 - acc: 0.7222 - val_loss: 0.6979 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6060 - acc: 0.7444 - val_loss: 0.6889 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6158 - acc: 0.7444 - val_loss: 0.6839 - val_acc: 0.6429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5955 - acc: 0.7667 - val_loss: 0.6888 - val_acc: 0.6429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5988 - acc: 0.7611 - val_loss: 0.6867 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6078 - acc: 0.7500 - val_loss: 0.6790 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6017 - acc: 0.7778 - val_loss: 0.6771 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5931 - acc: 0.7278 - val_loss: 0.6819 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6038 - acc: 0.7333 - val_loss: 0.6844 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5813 - acc: 0.7444 - val_loss: 0.6875 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5917 - acc: 0.7667 - val_loss: 0.6787 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5840 - acc: 0.7444 - val_loss: 0.6797 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5728 - acc: 0.7778 - val_loss: 0.6785 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5887 - acc: 0.7611 - val_loss: 0.6863 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5683 - acc: 0.7556 - val_loss: 0.6937 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5609 - acc: 0.7944 - val_loss: 0.6869 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5791 - acc: 0.7500 - val_loss: 0.6818 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5605 - acc: 0.7722 - val_loss: 0.6790 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5628 - acc: 0.7722 - val_loss: 0.6777 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5704 - acc: 0.7222 - val_loss: 0.6783 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5576 - acc: 0.7667 - val_loss: 0.6834 - val_acc: 0.6286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5590 - acc: 0.8056 - val_loss: 0.6764 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5547 - acc: 0.7444 - val_loss: 0.6931 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5272 - acc: 0.8111 - val_loss: 0.6815 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5420 - acc: 0.8000 - val_loss: 0.6803 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5527 - acc: 0.7611 - val_loss: 0.6790 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5253 - acc: 0.7944 - val_loss: 0.6884 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5312 - acc: 0.7889 - val_loss: 0.6857 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5201 - acc: 0.7944 - val_loss: 0.6901 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5397 - acc: 0.7722 - val_loss: 0.6978 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5356 - acc: 0.8167 - val_loss: 0.6993 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5385 - acc: 0.7778 - val_loss: 0.7008 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5076 - acc: 0.8333 - val_loss: 0.6943 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 14ms/step - loss: 0.7633 - acc: 0.5000 - val_loss: 0.7685 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7434 - acc: 0.5333 - val_loss: 0.7675 - val_acc: 0.4571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7452 - acc: 0.5278 - val_loss: 0.7647 - val_acc: 0.4714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7281 - acc: 0.5556 - val_loss: 0.7624 - val_acc: 0.4571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7244 - acc: 0.6000 - val_loss: 0.7613 - val_acc: 0.4571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7253 - acc: 0.5500 - val_loss: 0.7600 - val_acc: 0.4571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7215 - acc: 0.5611 - val_loss: 0.7609 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7334 - acc: 0.5333 - val_loss: 0.7597 - val_acc: 0.4857\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7197 - acc: 0.5722 - val_loss: 0.7586 - val_acc: 0.4857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7100 - acc: 0.6167 - val_loss: 0.7587 - val_acc: 0.4857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7157 - acc: 0.5500 - val_loss: 0.7585 - val_acc: 0.4857\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7063 - acc: 0.6000 - val_loss: 0.7567 - val_acc: 0.4714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7035 - acc: 0.5611 - val_loss: 0.7561 - val_acc: 0.4714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7012 - acc: 0.5722 - val_loss: 0.7550 - val_acc: 0.4857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7081 - acc: 0.5611 - val_loss: 0.7547 - val_acc: 0.4857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6890 - acc: 0.5889 - val_loss: 0.7537 - val_acc: 0.4714\n",
      "Epoch 17/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.7070 - acc: 0.5667 - val_loss: 0.7528 - val_acc: 0.4857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6980 - acc: 0.5889 - val_loss: 0.7520 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6971 - acc: 0.6222 - val_loss: 0.7515 - val_acc: 0.4857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6883 - acc: 0.5889 - val_loss: 0.7502 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6949 - acc: 0.6111 - val_loss: 0.7506 - val_acc: 0.4857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6812 - acc: 0.6333 - val_loss: 0.7508 - val_acc: 0.4857\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6934 - acc: 0.6111 - val_loss: 0.7510 - val_acc: 0.4857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6832 - acc: 0.6278 - val_loss: 0.7511 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6881 - acc: 0.6444 - val_loss: 0.7494 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6870 - acc: 0.6056 - val_loss: 0.7475 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6704 - acc: 0.6389 - val_loss: 0.7478 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 95us/step - loss: 0.6868 - acc: 0.6111 - val_loss: 0.7478 - val_acc: 0.5429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6780 - acc: 0.6389 - val_loss: 0.7476 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6802 - acc: 0.6056 - val_loss: 0.7481 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6636 - acc: 0.6611 - val_loss: 0.7483 - val_acc: 0.5286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6575 - acc: 0.6500 - val_loss: 0.7485 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6562 - acc: 0.6667 - val_loss: 0.7500 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6659 - acc: 0.6389 - val_loss: 0.7489 - val_acc: 0.4857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6621 - acc: 0.6500 - val_loss: 0.7485 - val_acc: 0.4714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6483 - acc: 0.7111 - val_loss: 0.7484 - val_acc: 0.5000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6471 - acc: 0.6833 - val_loss: 0.7495 - val_acc: 0.5143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6424 - acc: 0.7000 - val_loss: 0.7496 - val_acc: 0.5000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6552 - acc: 0.6667 - val_loss: 0.7491 - val_acc: 0.4857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6436 - acc: 0.7056 - val_loss: 0.7490 - val_acc: 0.4857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6588 - acc: 0.6667 - val_loss: 0.7475 - val_acc: 0.5143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6434 - acc: 0.7056 - val_loss: 0.7462 - val_acc: 0.5429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6408 - acc: 0.6889 - val_loss: 0.7469 - val_acc: 0.5286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6302 - acc: 0.7333 - val_loss: 0.7470 - val_acc: 0.4857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6378 - acc: 0.7278 - val_loss: 0.7457 - val_acc: 0.5000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6256 - acc: 0.7222 - val_loss: 0.7470 - val_acc: 0.5429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6366 - acc: 0.7000 - val_loss: 0.7466 - val_acc: 0.5286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6332 - acc: 0.6944 - val_loss: 0.7465 - val_acc: 0.5143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6229 - acc: 0.7611 - val_loss: 0.7469 - val_acc: 0.4857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6283 - acc: 0.7056 - val_loss: 0.7471 - val_acc: 0.5000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6108 - acc: 0.7167 - val_loss: 0.7457 - val_acc: 0.5143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6089 - acc: 0.7611 - val_loss: 0.7472 - val_acc: 0.5286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6112 - acc: 0.7111 - val_loss: 0.7469 - val_acc: 0.5143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6228 - acc: 0.7167 - val_loss: 0.7477 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6057 - acc: 0.7556 - val_loss: 0.7487 - val_acc: 0.5429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6081 - acc: 0.7278 - val_loss: 0.7483 - val_acc: 0.5714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6153 - acc: 0.7000 - val_loss: 0.7495 - val_acc: 0.5429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6027 - acc: 0.7556 - val_loss: 0.7493 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 92us/step - loss: 0.5983 - acc: 0.7222 - val_loss: 0.7461 - val_acc: 0.5143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5957 - acc: 0.7611 - val_loss: 0.7447 - val_acc: 0.5571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5863 - acc: 0.7333 - val_loss: 0.7424 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5971 - acc: 0.7556 - val_loss: 0.7415 - val_acc: 0.5429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5951 - acc: 0.7333 - val_loss: 0.7423 - val_acc: 0.5714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.5949 - acc: 0.7611 - val_loss: 0.7419 - val_acc: 0.5429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5751 - acc: 0.7667 - val_loss: 0.7429 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5706 - acc: 0.7556 - val_loss: 0.7401 - val_acc: 0.5571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5719 - acc: 0.7778 - val_loss: 0.7388 - val_acc: 0.5571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5704 - acc: 0.7667 - val_loss: 0.7394 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5754 - acc: 0.7556 - val_loss: 0.7360 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.5611 - acc: 0.7500 - val_loss: 0.7374 - val_acc: 0.5429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5816 - acc: 0.7556 - val_loss: 0.7370 - val_acc: 0.5714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5582 - acc: 0.7833 - val_loss: 0.7367 - val_acc: 0.5571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5639 - acc: 0.7722 - val_loss: 0.7353 - val_acc: 0.5714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5579 - acc: 0.7833 - val_loss: 0.7362 - val_acc: 0.5571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.5509 - acc: 0.7667 - val_loss: 0.7377 - val_acc: 0.5714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5395 - acc: 0.7889 - val_loss: 0.7371 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5368 - acc: 0.8056 - val_loss: 0.7393 - val_acc: 0.5571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5629 - acc: 0.7778 - val_loss: 0.7363 - val_acc: 0.5571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5328 - acc: 0.7889 - val_loss: 0.7374 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5566 - acc: 0.7778 - val_loss: 0.7412 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.7845 - acc: 0.4722 - val_loss: 0.7600 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7574 - acc: 0.4889 - val_loss: 0.7586 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.7517 - acc: 0.5222 - val_loss: 0.7599 - val_acc: 0.4286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7543 - acc: 0.5222 - val_loss: 0.7573 - val_acc: 0.4429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7336 - acc: 0.5722 - val_loss: 0.7589 - val_acc: 0.4571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7301 - acc: 0.5611 - val_loss: 0.7585 - val_acc: 0.4571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7315 - acc: 0.5667 - val_loss: 0.7541 - val_acc: 0.4571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7291 - acc: 0.5778 - val_loss: 0.7546 - val_acc: 0.4714\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7134 - acc: 0.5722 - val_loss: 0.7566 - val_acc: 0.4857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7120 - acc: 0.6167 - val_loss: 0.7519 - val_acc: 0.4857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7200 - acc: 0.5833 - val_loss: 0.7523 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7100 - acc: 0.5889 - val_loss: 0.7527 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7101 - acc: 0.5944 - val_loss: 0.7536 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7040 - acc: 0.6111 - val_loss: 0.7447 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7115 - acc: 0.5833 - val_loss: 0.7431 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6880 - acc: 0.6000 - val_loss: 0.7404 - val_acc: 0.4857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6984 - acc: 0.6278 - val_loss: 0.7376 - val_acc: 0.4571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6750 - acc: 0.6722 - val_loss: 0.7429 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6814 - acc: 0.6333 - val_loss: 0.7431 - val_acc: 0.4857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6820 - acc: 0.6667 - val_loss: 0.7424 - val_acc: 0.4714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6760 - acc: 0.6722 - val_loss: 0.7417 - val_acc: 0.4714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6653 - acc: 0.6889 - val_loss: 0.7447 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6712 - acc: 0.6778 - val_loss: 0.7442 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6688 - acc: 0.6500 - val_loss: 0.7441 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6681 - acc: 0.6556 - val_loss: 0.7365 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6616 - acc: 0.6722 - val_loss: 0.7379 - val_acc: 0.5000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6625 - acc: 0.6944 - val_loss: 0.7418 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6522 - acc: 0.7000 - val_loss: 0.7401 - val_acc: 0.5000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6533 - acc: 0.6944 - val_loss: 0.7403 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6556 - acc: 0.6833 - val_loss: 0.7379 - val_acc: 0.5000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6572 - acc: 0.6944 - val_loss: 0.7381 - val_acc: 0.5000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6537 - acc: 0.6722 - val_loss: 0.7425 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6432 - acc: 0.6833 - val_loss: 0.7464 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6452 - acc: 0.7000 - val_loss: 0.7364 - val_acc: 0.5143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6401 - acc: 0.6778 - val_loss: 0.7341 - val_acc: 0.5143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6349 - acc: 0.7222 - val_loss: 0.7307 - val_acc: 0.5000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6254 - acc: 0.7278 - val_loss: 0.7330 - val_acc: 0.5000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6418 - acc: 0.6889 - val_loss: 0.7340 - val_acc: 0.5000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6284 - acc: 0.7278 - val_loss: 0.7282 - val_acc: 0.5000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6122 - acc: 0.7389 - val_loss: 0.7328 - val_acc: 0.5000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5965 - acc: 0.7722 - val_loss: 0.7360 - val_acc: 0.5000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6175 - acc: 0.7000 - val_loss: 0.7371 - val_acc: 0.4857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6116 - acc: 0.7278 - val_loss: 0.7354 - val_acc: 0.4857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6059 - acc: 0.7167 - val_loss: 0.7361 - val_acc: 0.5000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6054 - acc: 0.7500 - val_loss: 0.7394 - val_acc: 0.5143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6013 - acc: 0.7444 - val_loss: 0.7386 - val_acc: 0.4857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5964 - acc: 0.7389 - val_loss: 0.7345 - val_acc: 0.5000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6056 - acc: 0.7333 - val_loss: 0.7328 - val_acc: 0.5000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5842 - acc: 0.7611 - val_loss: 0.7344 - val_acc: 0.5000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5930 - acc: 0.7722 - val_loss: 0.7314 - val_acc: 0.5000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6030 - acc: 0.7444 - val_loss: 0.7311 - val_acc: 0.5286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5910 - acc: 0.7278 - val_loss: 0.7331 - val_acc: 0.5143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5779 - acc: 0.7833 - val_loss: 0.7320 - val_acc: 0.5571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5842 - acc: 0.7389 - val_loss: 0.7288 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5905 - acc: 0.7056 - val_loss: 0.7359 - val_acc: 0.5286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5744 - acc: 0.7722 - val_loss: 0.7414 - val_acc: 0.5143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5645 - acc: 0.7667 - val_loss: 0.7317 - val_acc: 0.5857\n",
      "Epoch 58/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.5828 - acc: 0.7333 - val_loss: 0.7337 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5690 - acc: 0.7611 - val_loss: 0.7369 - val_acc: 0.5714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5838 - acc: 0.7333 - val_loss: 0.7364 - val_acc: 0.5714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 88us/step - loss: 0.5511 - acc: 0.7667 - val_loss: 0.7280 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5763 - acc: 0.7389 - val_loss: 0.7284 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5757 - acc: 0.7389 - val_loss: 0.7264 - val_acc: 0.5429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5459 - acc: 0.7556 - val_loss: 0.7260 - val_acc: 0.5286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5554 - acc: 0.7667 - val_loss: 0.7348 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5511 - acc: 0.7556 - val_loss: 0.7350 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5536 - acc: 0.7722 - val_loss: 0.7308 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5443 - acc: 0.7889 - val_loss: 0.7402 - val_acc: 0.5857\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5486 - acc: 0.7833 - val_loss: 0.7347 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5436 - acc: 0.7833 - val_loss: 0.7362 - val_acc: 0.5857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5430 - acc: 0.7722 - val_loss: 0.7357 - val_acc: 0.5857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5217 - acc: 0.8056 - val_loss: 0.7313 - val_acc: 0.5571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5342 - acc: 0.7833 - val_loss: 0.7349 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5268 - acc: 0.7722 - val_loss: 0.7405 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.5175 - acc: 0.7889 - val_loss: 0.7379 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5407 - acc: 0.7833 - val_loss: 0.7392 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.5227 - acc: 0.7889 - val_loss: 0.7354 - val_acc: 0.5429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.4968 - acc: 0.8333 - val_loss: 0.7429 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5074 - acc: 0.8111 - val_loss: 0.7460 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5271 - acc: 0.7833 - val_loss: 0.7432 - val_acc: 0.5429\n",
      "80/80 [==============================] - 0s 112us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.7851 - acc: 0.5500 - val_loss: 0.7536 - val_acc: 0.5429\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7488 - acc: 0.5389 - val_loss: 0.7468 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7342 - acc: 0.5556 - val_loss: 0.7413 - val_acc: 0.5714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7380 - acc: 0.5611 - val_loss: 0.7444 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7400 - acc: 0.5611 - val_loss: 0.7407 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7331 - acc: 0.5722 - val_loss: 0.7439 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7203 - acc: 0.5444 - val_loss: 0.7405 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7174 - acc: 0.6111 - val_loss: 0.7428 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7161 - acc: 0.5833 - val_loss: 0.7388 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7162 - acc: 0.5778 - val_loss: 0.7374 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7044 - acc: 0.5944 - val_loss: 0.7346 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6962 - acc: 0.6278 - val_loss: 0.7373 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6953 - acc: 0.5500 - val_loss: 0.7360 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6992 - acc: 0.5944 - val_loss: 0.7301 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6953 - acc: 0.6444 - val_loss: 0.7295 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6961 - acc: 0.6056 - val_loss: 0.7257 - val_acc: 0.5571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6969 - acc: 0.6556 - val_loss: 0.7255 - val_acc: 0.5714\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6935 - acc: 0.6333 - val_loss: 0.7267 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6774 - acc: 0.6333 - val_loss: 0.7238 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6845 - acc: 0.6056 - val_loss: 0.7205 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6646 - acc: 0.6444 - val_loss: 0.7206 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6732 - acc: 0.6556 - val_loss: 0.7170 - val_acc: 0.6000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6635 - acc: 0.7056 - val_loss: 0.7158 - val_acc: 0.6143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 96us/step - loss: 0.6696 - acc: 0.6611 - val_loss: 0.7148 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6681 - acc: 0.6444 - val_loss: 0.7180 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6611 - acc: 0.6389 - val_loss: 0.7167 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6598 - acc: 0.6333 - val_loss: 0.7137 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6633 - acc: 0.6500 - val_loss: 0.7124 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6598 - acc: 0.6833 - val_loss: 0.7107 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6519 - acc: 0.6556 - val_loss: 0.7084 - val_acc: 0.6429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6471 - acc: 0.6833 - val_loss: 0.7085 - val_acc: 0.6286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6456 - acc: 0.6889 - val_loss: 0.7114 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6477 - acc: 0.6833 - val_loss: 0.7064 - val_acc: 0.6286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6396 - acc: 0.7111 - val_loss: 0.7073 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6291 - acc: 0.7167 - val_loss: 0.7068 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6345 - acc: 0.6833 - val_loss: 0.7002 - val_acc: 0.6714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6403 - acc: 0.7222 - val_loss: 0.6999 - val_acc: 0.6571\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6318 - acc: 0.6833 - val_loss: 0.6968 - val_acc: 0.6857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6236 - acc: 0.7056 - val_loss: 0.6973 - val_acc: 0.6714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6311 - acc: 0.6889 - val_loss: 0.7009 - val_acc: 0.6143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6328 - acc: 0.6556 - val_loss: 0.7050 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6225 - acc: 0.7056 - val_loss: 0.6999 - val_acc: 0.6571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6153 - acc: 0.6833 - val_loss: 0.6985 - val_acc: 0.6571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6081 - acc: 0.7167 - val_loss: 0.6944 - val_acc: 0.6714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6245 - acc: 0.6944 - val_loss: 0.6917 - val_acc: 0.6714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6176 - acc: 0.6944 - val_loss: 0.6872 - val_acc: 0.6857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6024 - acc: 0.7889 - val_loss: 0.6909 - val_acc: 0.6857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6149 - acc: 0.7000 - val_loss: 0.6844 - val_acc: 0.6857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5956 - acc: 0.7444 - val_loss: 0.6822 - val_acc: 0.7000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 95us/step - loss: 0.6023 - acc: 0.7611 - val_loss: 0.6844 - val_acc: 0.7000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5899 - acc: 0.7444 - val_loss: 0.6813 - val_acc: 0.7143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6027 - acc: 0.7722 - val_loss: 0.6777 - val_acc: 0.7000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5913 - acc: 0.7556 - val_loss: 0.6768 - val_acc: 0.7000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5848 - acc: 0.7611 - val_loss: 0.6814 - val_acc: 0.6857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5962 - acc: 0.7111 - val_loss: 0.6741 - val_acc: 0.7143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 91us/step - loss: 0.5949 - acc: 0.7222 - val_loss: 0.6720 - val_acc: 0.6714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5924 - acc: 0.7556 - val_loss: 0.6718 - val_acc: 0.6857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5694 - acc: 0.8000 - val_loss: 0.6706 - val_acc: 0.6857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5807 - acc: 0.7611 - val_loss: 0.6815 - val_acc: 0.7000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5660 - acc: 0.8056 - val_loss: 0.6742 - val_acc: 0.7286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5712 - acc: 0.7722 - val_loss: 0.6759 - val_acc: 0.7286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5901 - acc: 0.7333 - val_loss: 0.6763 - val_acc: 0.7143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5731 - acc: 0.7667 - val_loss: 0.6705 - val_acc: 0.7286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5678 - acc: 0.7500 - val_loss: 0.6667 - val_acc: 0.6857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5560 - acc: 0.8056 - val_loss: 0.6654 - val_acc: 0.6429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5562 - acc: 0.8000 - val_loss: 0.6683 - val_acc: 0.7000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5508 - acc: 0.8278 - val_loss: 0.6695 - val_acc: 0.7000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5484 - acc: 0.8444 - val_loss: 0.6757 - val_acc: 0.7143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5552 - acc: 0.7833 - val_loss: 0.6695 - val_acc: 0.6857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5514 - acc: 0.7889 - val_loss: 0.6657 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5437 - acc: 0.7944 - val_loss: 0.6741 - val_acc: 0.7000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5416 - acc: 0.8167 - val_loss: 0.6728 - val_acc: 0.7000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5403 - acc: 0.7778 - val_loss: 0.6711 - val_acc: 0.7143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5286 - acc: 0.8389 - val_loss: 0.6669 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5350 - acc: 0.8111 - val_loss: 0.6654 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5306 - acc: 0.8222 - val_loss: 0.6719 - val_acc: 0.6857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5262 - acc: 0.8222 - val_loss: 0.6713 - val_acc: 0.6857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5438 - acc: 0.8222 - val_loss: 0.6743 - val_acc: 0.7000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5301 - acc: 0.8389 - val_loss: 0.6665 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5280 - acc: 0.8444 - val_loss: 0.6669 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.7474 - acc: 0.5333 - val_loss: 0.7761 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7286 - acc: 0.5556 - val_loss: 0.7751 - val_acc: 0.4857\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7220 - acc: 0.5778 - val_loss: 0.7700 - val_acc: 0.4714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7292 - acc: 0.5611 - val_loss: 0.7668 - val_acc: 0.4714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7086 - acc: 0.6056 - val_loss: 0.7639 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7186 - acc: 0.5889 - val_loss: 0.7637 - val_acc: 0.4714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7123 - acc: 0.5889 - val_loss: 0.7617 - val_acc: 0.4714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7135 - acc: 0.6278 - val_loss: 0.7586 - val_acc: 0.4857\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7008 - acc: 0.6167 - val_loss: 0.7604 - val_acc: 0.4857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7068 - acc: 0.6167 - val_loss: 0.7555 - val_acc: 0.4857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6999 - acc: 0.6444 - val_loss: 0.7535 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6984 - acc: 0.6278 - val_loss: 0.7523 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7005 - acc: 0.6444 - val_loss: 0.7486 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6787 - acc: 0.6667 - val_loss: 0.7516 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7039 - acc: 0.6167 - val_loss: 0.7544 - val_acc: 0.4857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7001 - acc: 0.6389 - val_loss: 0.7535 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6844 - acc: 0.6278 - val_loss: 0.7487 - val_acc: 0.5143\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6846 - acc: 0.6722 - val_loss: 0.7455 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6793 - acc: 0.6611 - val_loss: 0.7469 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6755 - acc: 0.6111 - val_loss: 0.7416 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6678 - acc: 0.6778 - val_loss: 0.7376 - val_acc: 0.6143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6759 - acc: 0.6222 - val_loss: 0.7390 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6533 - acc: 0.7111 - val_loss: 0.7377 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6741 - acc: 0.6222 - val_loss: 0.7360 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6594 - acc: 0.6833 - val_loss: 0.7340 - val_acc: 0.6143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6520 - acc: 0.7000 - val_loss: 0.7353 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6484 - acc: 0.7111 - val_loss: 0.7320 - val_acc: 0.6000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6451 - acc: 0.7167 - val_loss: 0.7315 - val_acc: 0.6143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6586 - acc: 0.7000 - val_loss: 0.7295 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6542 - acc: 0.7111 - val_loss: 0.7281 - val_acc: 0.6571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6512 - acc: 0.7056 - val_loss: 0.7275 - val_acc: 0.6571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6640 - acc: 0.6611 - val_loss: 0.7316 - val_acc: 0.5857\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6584 - acc: 0.6778 - val_loss: 0.7313 - val_acc: 0.5857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6528 - acc: 0.6889 - val_loss: 0.7283 - val_acc: 0.6286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6482 - acc: 0.6944 - val_loss: 0.7270 - val_acc: 0.6286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6414 - acc: 0.6944 - val_loss: 0.7267 - val_acc: 0.6429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6498 - acc: 0.6944 - val_loss: 0.7253 - val_acc: 0.6286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6299 - acc: 0.7278 - val_loss: 0.7253 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6633 - acc: 0.6667 - val_loss: 0.7252 - val_acc: 0.6286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6364 - acc: 0.6889 - val_loss: 0.7238 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6212 - acc: 0.7222 - val_loss: 0.7199 - val_acc: 0.6429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6291 - acc: 0.7167 - val_loss: 0.7241 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 92us/step - loss: 0.6192 - acc: 0.7389 - val_loss: 0.7188 - val_acc: 0.6571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6314 - acc: 0.7333 - val_loss: 0.7209 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6040 - acc: 0.7222 - val_loss: 0.7263 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6204 - acc: 0.7278 - val_loss: 0.7211 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6349 - acc: 0.6667 - val_loss: 0.7242 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6300 - acc: 0.7222 - val_loss: 0.7222 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6223 - acc: 0.7389 - val_loss: 0.7208 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6312 - acc: 0.7111 - val_loss: 0.7232 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6127 - acc: 0.7500 - val_loss: 0.7276 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6183 - acc: 0.7222 - val_loss: 0.7242 - val_acc: 0.6286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5911 - acc: 0.7500 - val_loss: 0.7246 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5763 - acc: 0.7667 - val_loss: 0.7218 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6014 - acc: 0.7222 - val_loss: 0.7246 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5788 - acc: 0.7611 - val_loss: 0.7188 - val_acc: 0.6571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6127 - acc: 0.7222 - val_loss: 0.7216 - val_acc: 0.6571\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5870 - acc: 0.7500 - val_loss: 0.7167 - val_acc: 0.6857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5818 - acc: 0.7444 - val_loss: 0.7196 - val_acc: 0.6571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5640 - acc: 0.7667 - val_loss: 0.7213 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5831 - acc: 0.7667 - val_loss: 0.7184 - val_acc: 0.6714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6012 - acc: 0.7500 - val_loss: 0.7220 - val_acc: 0.6571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5883 - acc: 0.7333 - val_loss: 0.7226 - val_acc: 0.6571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5677 - acc: 0.7500 - val_loss: 0.7178 - val_acc: 0.6571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5673 - acc: 0.7889 - val_loss: 0.7205 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5644 - acc: 0.7500 - val_loss: 0.7180 - val_acc: 0.6714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5853 - acc: 0.7556 - val_loss: 0.7182 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5499 - acc: 0.7833 - val_loss: 0.7175 - val_acc: 0.6714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5610 - acc: 0.7778 - val_loss: 0.7177 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5513 - acc: 0.7667 - val_loss: 0.7183 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5554 - acc: 0.7778 - val_loss: 0.7188 - val_acc: 0.6714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5427 - acc: 0.7889 - val_loss: 0.7193 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5513 - acc: 0.7611 - val_loss: 0.7221 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5441 - acc: 0.7611 - val_loss: 0.7279 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5413 - acc: 0.7778 - val_loss: 0.7250 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5545 - acc: 0.7944 - val_loss: 0.7233 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5318 - acc: 0.7667 - val_loss: 0.7341 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5473 - acc: 0.7778 - val_loss: 0.7309 - val_acc: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5535 - acc: 0.7778 - val_loss: 0.7275 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5084 - acc: 0.7833 - val_loss: 0.7259 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 1.0502 - acc: 0.4611 - val_loss: 0.9212 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.9506 - acc: 0.4611 - val_loss: 0.8858 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.9198 - acc: 0.4611 - val_loss: 0.8623 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.8917 - acc: 0.4611 - val_loss: 0.8416 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.8656 - acc: 0.4611 - val_loss: 0.8242 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.8424 - acc: 0.4611 - val_loss: 0.8112 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.8280 - acc: 0.4611 - val_loss: 0.7990 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.8087 - acc: 0.4611 - val_loss: 0.7889 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7981 - acc: 0.4556 - val_loss: 0.7818 - val_acc: 0.4857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7879 - acc: 0.4500 - val_loss: 0.7754 - val_acc: 0.4571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7684 - acc: 0.4944 - val_loss: 0.7680 - val_acc: 0.4143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7618 - acc: 0.4833 - val_loss: 0.7659 - val_acc: 0.4143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7444 - acc: 0.5222 - val_loss: 0.7630 - val_acc: 0.4286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7550 - acc: 0.4611 - val_loss: 0.7604 - val_acc: 0.4286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7379 - acc: 0.5111 - val_loss: 0.7578 - val_acc: 0.4000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.7356 - acc: 0.5333 - val_loss: 0.7560 - val_acc: 0.4143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7374 - acc: 0.5444 - val_loss: 0.7529 - val_acc: 0.4429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7315 - acc: 0.5333 - val_loss: 0.7510 - val_acc: 0.4714\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7211 - acc: 0.5778 - val_loss: 0.7493 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7204 - acc: 0.5778 - val_loss: 0.7491 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 96us/step - loss: 0.7086 - acc: 0.6167 - val_loss: 0.7487 - val_acc: 0.4857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7082 - acc: 0.6222 - val_loss: 0.7474 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7038 - acc: 0.6333 - val_loss: 0.7477 - val_acc: 0.4857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7132 - acc: 0.6111 - val_loss: 0.7474 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7045 - acc: 0.5833 - val_loss: 0.7469 - val_acc: 0.4714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6965 - acc: 0.6167 - val_loss: 0.7459 - val_acc: 0.4857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7077 - acc: 0.6056 - val_loss: 0.7450 - val_acc: 0.4714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6926 - acc: 0.6500 - val_loss: 0.7459 - val_acc: 0.4857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6946 - acc: 0.6167 - val_loss: 0.7427 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6846 - acc: 0.6444 - val_loss: 0.7421 - val_acc: 0.5286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6843 - acc: 0.6611 - val_loss: 0.7417 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6821 - acc: 0.6556 - val_loss: 0.7419 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6815 - acc: 0.6278 - val_loss: 0.7381 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6752 - acc: 0.7056 - val_loss: 0.7393 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6706 - acc: 0.6944 - val_loss: 0.7364 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6752 - acc: 0.6667 - val_loss: 0.7377 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6639 - acc: 0.6778 - val_loss: 0.7373 - val_acc: 0.5571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6763 - acc: 0.6333 - val_loss: 0.7347 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6636 - acc: 0.7167 - val_loss: 0.7296 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6554 - acc: 0.7222 - val_loss: 0.7289 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6625 - acc: 0.6833 - val_loss: 0.7288 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6608 - acc: 0.7111 - val_loss: 0.7264 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6488 - acc: 0.7222 - val_loss: 0.7280 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6442 - acc: 0.7111 - val_loss: 0.7293 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6431 - acc: 0.7111 - val_loss: 0.7230 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6416 - acc: 0.6833 - val_loss: 0.7198 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6350 - acc: 0.7500 - val_loss: 0.7194 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6205 - acc: 0.7500 - val_loss: 0.7239 - val_acc: 0.5571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6423 - acc: 0.6944 - val_loss: 0.7191 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6251 - acc: 0.7556 - val_loss: 0.7179 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 83us/step - loss: 0.6247 - acc: 0.7667 - val_loss: 0.7157 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6316 - acc: 0.7222 - val_loss: 0.7212 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6259 - acc: 0.7389 - val_loss: 0.7200 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6075 - acc: 0.7667 - val_loss: 0.7217 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6220 - acc: 0.7056 - val_loss: 0.7211 - val_acc: 0.5857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6062 - acc: 0.7667 - val_loss: 0.7161 - val_acc: 0.5857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6122 - acc: 0.7389 - val_loss: 0.7135 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6038 - acc: 0.7556 - val_loss: 0.7185 - val_acc: 0.6000\n",
      "Epoch 59/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.5983 - acc: 0.7722 - val_loss: 0.7160 - val_acc: 0.6000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5909 - acc: 0.7667 - val_loss: 0.7116 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6036 - acc: 0.7167 - val_loss: 0.7096 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5821 - acc: 0.7833 - val_loss: 0.7170 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5896 - acc: 0.7611 - val_loss: 0.7112 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5770 - acc: 0.7889 - val_loss: 0.7160 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5905 - acc: 0.7444 - val_loss: 0.7185 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5849 - acc: 0.7667 - val_loss: 0.7145 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5732 - acc: 0.8000 - val_loss: 0.7127 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5647 - acc: 0.7833 - val_loss: 0.7110 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5590 - acc: 0.7778 - val_loss: 0.7088 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5734 - acc: 0.7556 - val_loss: 0.7092 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5700 - acc: 0.7833 - val_loss: 0.7099 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5654 - acc: 0.7667 - val_loss: 0.7114 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5512 - acc: 0.7722 - val_loss: 0.7112 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5564 - acc: 0.7778 - val_loss: 0.7134 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5484 - acc: 0.7944 - val_loss: 0.7252 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5478 - acc: 0.7944 - val_loss: 0.7187 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5563 - acc: 0.7556 - val_loss: 0.7223 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5392 - acc: 0.7500 - val_loss: 0.7204 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5493 - acc: 0.7944 - val_loss: 0.7167 - val_acc: 0.6429\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5445 - acc: 0.8056 - val_loss: 0.7178 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.9323 - acc: 0.4611 - val_loss: 0.7676 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.8209 - acc: 0.4667 - val_loss: 0.7380 - val_acc: 0.6000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7866 - acc: 0.5000 - val_loss: 0.7287 - val_acc: 0.5857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7662 - acc: 0.5333 - val_loss: 0.7256 - val_acc: 0.6143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7472 - acc: 0.5722 - val_loss: 0.7260 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7223 - acc: 0.6389 - val_loss: 0.7253 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7223 - acc: 0.6111 - val_loss: 0.7258 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7367 - acc: 0.5778 - val_loss: 0.7296 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7205 - acc: 0.5944 - val_loss: 0.7274 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7329 - acc: 0.5444 - val_loss: 0.7289 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7054 - acc: 0.6167 - val_loss: 0.7260 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7187 - acc: 0.6000 - val_loss: 0.7267 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7110 - acc: 0.5944 - val_loss: 0.7261 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7069 - acc: 0.6111 - val_loss: 0.7276 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7122 - acc: 0.6167 - val_loss: 0.7241 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7039 - acc: 0.6056 - val_loss: 0.7274 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6805 - acc: 0.6500 - val_loss: 0.7252 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6955 - acc: 0.6167 - val_loss: 0.7286 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6929 - acc: 0.6556 - val_loss: 0.7227 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6815 - acc: 0.6722 - val_loss: 0.7206 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6693 - acc: 0.7167 - val_loss: 0.7215 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6969 - acc: 0.6444 - val_loss: 0.7246 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6819 - acc: 0.6222 - val_loss: 0.7256 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6663 - acc: 0.6722 - val_loss: 0.7242 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6644 - acc: 0.6889 - val_loss: 0.7144 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6662 - acc: 0.6944 - val_loss: 0.7166 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6604 - acc: 0.6722 - val_loss: 0.7131 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6642 - acc: 0.6556 - val_loss: 0.7111 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6304 - acc: 0.7556 - val_loss: 0.7092 - val_acc: 0.6143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6415 - acc: 0.7000 - val_loss: 0.7121 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6573 - acc: 0.7111 - val_loss: 0.7177 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6659 - acc: 0.6500 - val_loss: 0.7102 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6435 - acc: 0.7111 - val_loss: 0.7153 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6432 - acc: 0.7056 - val_loss: 0.7173 - val_acc: 0.5429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6573 - acc: 0.6500 - val_loss: 0.7147 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6390 - acc: 0.7500 - val_loss: 0.7168 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6318 - acc: 0.7222 - val_loss: 0.7262 - val_acc: 0.5286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6298 - acc: 0.7056 - val_loss: 0.7102 - val_acc: 0.5857\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/step - loss: 0.6292 - acc: 0.7167 - val_loss: 0.7120 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6210 - acc: 0.6944 - val_loss: 0.7117 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6115 - acc: 0.7167 - val_loss: 0.7103 - val_acc: 0.5857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6173 - acc: 0.7278 - val_loss: 0.7083 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6212 - acc: 0.7278 - val_loss: 0.7037 - val_acc: 0.6571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6212 - acc: 0.7000 - val_loss: 0.7132 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6150 - acc: 0.7444 - val_loss: 0.7154 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6144 - acc: 0.7111 - val_loss: 0.7184 - val_acc: 0.5571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.5896 - acc: 0.7389 - val_loss: 0.7186 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6021 - acc: 0.7389 - val_loss: 0.7249 - val_acc: 0.5571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6021 - acc: 0.7167 - val_loss: 0.7223 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6130 - acc: 0.7222 - val_loss: 0.7157 - val_acc: 0.5571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6072 - acc: 0.7056 - val_loss: 0.7108 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6180 - acc: 0.7167 - val_loss: 0.7066 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5707 - acc: 0.7778 - val_loss: 0.7065 - val_acc: 0.6429\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5805 - acc: 0.7444 - val_loss: 0.7032 - val_acc: 0.6571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6147 - acc: 0.7000 - val_loss: 0.7017 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5556 - acc: 0.7833 - val_loss: 0.7042 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.5553 - acc: 0.7722 - val_loss: 0.7034 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5681 - acc: 0.7556 - val_loss: 0.7195 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5738 - acc: 0.7278 - val_loss: 0.7046 - val_acc: 0.6714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5556 - acc: 0.7833 - val_loss: 0.7031 - val_acc: 0.6571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5684 - acc: 0.7722 - val_loss: 0.7046 - val_acc: 0.6571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5651 - acc: 0.7667 - val_loss: 0.7079 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5523 - acc: 0.7722 - val_loss: 0.7025 - val_acc: 0.6857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5619 - acc: 0.7444 - val_loss: 0.7050 - val_acc: 0.6571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5762 - acc: 0.7500 - val_loss: 0.7180 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5582 - acc: 0.7389 - val_loss: 0.7097 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5407 - acc: 0.8167 - val_loss: 0.7080 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5414 - acc: 0.8000 - val_loss: 0.7010 - val_acc: 0.6857\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5362 - acc: 0.7778 - val_loss: 0.7191 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5447 - acc: 0.7944 - val_loss: 0.7065 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5461 - acc: 0.7667 - val_loss: 0.7045 - val_acc: 0.6857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5527 - acc: 0.7556 - val_loss: 0.7088 - val_acc: 0.6714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5158 - acc: 0.8222 - val_loss: 0.7132 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5542 - acc: 0.7778 - val_loss: 0.7083 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5294 - acc: 0.7778 - val_loss: 0.7186 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5152 - acc: 0.8000 - val_loss: 0.7149 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5333 - acc: 0.7833 - val_loss: 0.7185 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5312 - acc: 0.7778 - val_loss: 0.7114 - val_acc: 0.6857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5184 - acc: 0.7722 - val_loss: 0.7177 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5257 - acc: 0.7722 - val_loss: 0.7314 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.8208 - acc: 0.4944 - val_loss: 0.7448 - val_acc: 0.5714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7738 - acc: 0.5278 - val_loss: 0.7365 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7494 - acc: 0.5222 - val_loss: 0.7343 - val_acc: 0.5571\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7373 - acc: 0.6056 - val_loss: 0.7355 - val_acc: 0.5714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7320 - acc: 0.5667 - val_loss: 0.7382 - val_acc: 0.5714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7179 - acc: 0.5667 - val_loss: 0.7375 - val_acc: 0.5714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7346 - acc: 0.5500 - val_loss: 0.7356 - val_acc: 0.6000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7313 - acc: 0.5500 - val_loss: 0.7365 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7220 - acc: 0.5778 - val_loss: 0.7353 - val_acc: 0.5714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7014 - acc: 0.6167 - val_loss: 0.7386 - val_acc: 0.5571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7067 - acc: 0.6167 - val_loss: 0.7350 - val_acc: 0.5857\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6960 - acc: 0.6389 - val_loss: 0.7334 - val_acc: 0.5857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7051 - acc: 0.6222 - val_loss: 0.7332 - val_acc: 0.5857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7056 - acc: 0.5778 - val_loss: 0.7267 - val_acc: 0.6000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7036 - acc: 0.5889 - val_loss: 0.7274 - val_acc: 0.5857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7023 - acc: 0.6000 - val_loss: 0.7247 - val_acc: 0.6000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6912 - acc: 0.6111 - val_loss: 0.7214 - val_acc: 0.6143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 109us/step - loss: 0.6858 - acc: 0.6222 - val_loss: 0.7207 - val_acc: 0.6286\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6802 - acc: 0.6556 - val_loss: 0.7182 - val_acc: 0.6143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6828 - acc: 0.6389 - val_loss: 0.7145 - val_acc: 0.6429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6814 - acc: 0.6667 - val_loss: 0.7164 - val_acc: 0.6143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6771 - acc: 0.6278 - val_loss: 0.7128 - val_acc: 0.6429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6577 - acc: 0.7056 - val_loss: 0.7142 - val_acc: 0.6000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6622 - acc: 0.6833 - val_loss: 0.7184 - val_acc: 0.6143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6805 - acc: 0.5889 - val_loss: 0.7090 - val_acc: 0.6286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6553 - acc: 0.6889 - val_loss: 0.7070 - val_acc: 0.6143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6716 - acc: 0.6333 - val_loss: 0.7116 - val_acc: 0.6143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6555 - acc: 0.6778 - val_loss: 0.7026 - val_acc: 0.6143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6634 - acc: 0.6444 - val_loss: 0.6991 - val_acc: 0.6857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6650 - acc: 0.7000 - val_loss: 0.6996 - val_acc: 0.6571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6590 - acc: 0.7000 - val_loss: 0.6979 - val_acc: 0.6857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6648 - acc: 0.6778 - val_loss: 0.6951 - val_acc: 0.6857\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6289 - acc: 0.7500 - val_loss: 0.6946 - val_acc: 0.6857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6425 - acc: 0.6778 - val_loss: 0.6972 - val_acc: 0.6714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6332 - acc: 0.7111 - val_loss: 0.6948 - val_acc: 0.6714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6421 - acc: 0.6889 - val_loss: 0.6934 - val_acc: 0.6714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6473 - acc: 0.6889 - val_loss: 0.6984 - val_acc: 0.6429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6457 - acc: 0.6556 - val_loss: 0.6886 - val_acc: 0.7000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6321 - acc: 0.7389 - val_loss: 0.6872 - val_acc: 0.6857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6256 - acc: 0.7056 - val_loss: 0.6855 - val_acc: 0.7000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 244us/step - loss: 0.6159 - acc: 0.7500 - val_loss: 0.6872 - val_acc: 0.6857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 205us/step - loss: 0.6145 - acc: 0.7278 - val_loss: 0.6851 - val_acc: 0.6857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 266us/step - loss: 0.6151 - acc: 0.7556 - val_loss: 0.6860 - val_acc: 0.6857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6060 - acc: 0.7278 - val_loss: 0.6869 - val_acc: 0.6714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6077 - acc: 0.7333 - val_loss: 0.6879 - val_acc: 0.6714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6120 - acc: 0.7333 - val_loss: 0.6883 - val_acc: 0.6714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6138 - acc: 0.7000 - val_loss: 0.6931 - val_acc: 0.6429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6049 - acc: 0.7167 - val_loss: 0.6789 - val_acc: 0.7143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5967 - acc: 0.7778 - val_loss: 0.6779 - val_acc: 0.7143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5899 - acc: 0.7500 - val_loss: 0.6857 - val_acc: 0.6571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6111 - acc: 0.7111 - val_loss: 0.6920 - val_acc: 0.6429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6084 - acc: 0.7056 - val_loss: 0.6885 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5915 - acc: 0.7722 - val_loss: 0.6782 - val_acc: 0.7143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5866 - acc: 0.7500 - val_loss: 0.6784 - val_acc: 0.6857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5758 - acc: 0.7889 - val_loss: 0.6783 - val_acc: 0.6857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5841 - acc: 0.7556 - val_loss: 0.6797 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6043 - acc: 0.7444 - val_loss: 0.6738 - val_acc: 0.6857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5899 - acc: 0.7556 - val_loss: 0.6761 - val_acc: 0.7143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5912 - acc: 0.7278 - val_loss: 0.6765 - val_acc: 0.7143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5827 - acc: 0.7389 - val_loss: 0.6772 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5753 - acc: 0.7722 - val_loss: 0.6757 - val_acc: 0.6571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5674 - acc: 0.7611 - val_loss: 0.6734 - val_acc: 0.6857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5742 - acc: 0.7389 - val_loss: 0.6732 - val_acc: 0.6714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5583 - acc: 0.7833 - val_loss: 0.6782 - val_acc: 0.6571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5579 - acc: 0.7500 - val_loss: 0.6764 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5548 - acc: 0.7556 - val_loss: 0.6795 - val_acc: 0.6429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5571 - acc: 0.7722 - val_loss: 0.6749 - val_acc: 0.6571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5667 - acc: 0.7722 - val_loss: 0.6762 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5539 - acc: 0.7722 - val_loss: 0.6836 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5527 - acc: 0.7889 - val_loss: 0.6783 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5474 - acc: 0.8056 - val_loss: 0.6752 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5678 - acc: 0.7444 - val_loss: 0.6709 - val_acc: 0.6714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5756 - acc: 0.7444 - val_loss: 0.6713 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5369 - acc: 0.8000 - val_loss: 0.6733 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5483 - acc: 0.7611 - val_loss: 0.6706 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5461 - acc: 0.7778 - val_loss: 0.6724 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5336 - acc: 0.7833 - val_loss: 0.6810 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5179 - acc: 0.8111 - val_loss: 0.6746 - val_acc: 0.6429\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.5511 - acc: 0.7722 - val_loss: 0.6782 - val_acc: 0.6571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5486 - acc: 0.7889 - val_loss: 0.6735 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 17ms/step - loss: 0.8577 - acc: 0.4667 - val_loss: 0.7755 - val_acc: 0.5571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.8061 - acc: 0.4889 - val_loss: 0.7611 - val_acc: 0.5714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7963 - acc: 0.4667 - val_loss: 0.7541 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7671 - acc: 0.5222 - val_loss: 0.7474 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7696 - acc: 0.5000 - val_loss: 0.7450 - val_acc: 0.4857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7733 - acc: 0.5056 - val_loss: 0.7430 - val_acc: 0.4714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7461 - acc: 0.5111 - val_loss: 0.7416 - val_acc: 0.4714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7432 - acc: 0.5000 - val_loss: 0.7402 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7460 - acc: 0.5222 - val_loss: 0.7388 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7299 - acc: 0.5833 - val_loss: 0.7380 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7386 - acc: 0.5333 - val_loss: 0.7361 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7414 - acc: 0.5167 - val_loss: 0.7351 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7315 - acc: 0.5944 - val_loss: 0.7350 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7289 - acc: 0.5722 - val_loss: 0.7341 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7292 - acc: 0.5889 - val_loss: 0.7338 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7258 - acc: 0.5333 - val_loss: 0.7349 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7170 - acc: 0.6000 - val_loss: 0.7341 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7162 - acc: 0.5667 - val_loss: 0.7322 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7155 - acc: 0.5667 - val_loss: 0.7321 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7275 - acc: 0.5389 - val_loss: 0.7321 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7124 - acc: 0.5778 - val_loss: 0.7313 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7186 - acc: 0.5778 - val_loss: 0.7295 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7138 - acc: 0.5778 - val_loss: 0.7311 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7113 - acc: 0.5778 - val_loss: 0.7284 - val_acc: 0.5143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7074 - acc: 0.5833 - val_loss: 0.7275 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6998 - acc: 0.6056 - val_loss: 0.7280 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7010 - acc: 0.6167 - val_loss: 0.7277 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6988 - acc: 0.5944 - val_loss: 0.7277 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7010 - acc: 0.6278 - val_loss: 0.7300 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7006 - acc: 0.6000 - val_loss: 0.7280 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7082 - acc: 0.5944 - val_loss: 0.7289 - val_acc: 0.5143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6905 - acc: 0.6111 - val_loss: 0.7263 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6934 - acc: 0.6167 - val_loss: 0.7222 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6896 - acc: 0.6333 - val_loss: 0.7192 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6973 - acc: 0.6222 - val_loss: 0.7213 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7021 - acc: 0.6167 - val_loss: 0.7245 - val_acc: 0.5143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6801 - acc: 0.6611 - val_loss: 0.7210 - val_acc: 0.5286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6871 - acc: 0.6389 - val_loss: 0.7224 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6832 - acc: 0.6444 - val_loss: 0.7192 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6744 - acc: 0.7111 - val_loss: 0.7209 - val_acc: 0.5286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6692 - acc: 0.6722 - val_loss: 0.7194 - val_acc: 0.5571\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6741 - acc: 0.6833 - val_loss: 0.7249 - val_acc: 0.5143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6744 - acc: 0.6722 - val_loss: 0.7221 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6754 - acc: 0.6889 - val_loss: 0.7200 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6767 - acc: 0.6944 - val_loss: 0.7222 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 101us/step - loss: 0.6741 - acc: 0.6778 - val_loss: 0.7195 - val_acc: 0.5429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6599 - acc: 0.7167 - val_loss: 0.7193 - val_acc: 0.5429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6664 - acc: 0.6889 - val_loss: 0.7205 - val_acc: 0.5286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6500 - acc: 0.7444 - val_loss: 0.7184 - val_acc: 0.5429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6614 - acc: 0.7111 - val_loss: 0.7194 - val_acc: 0.5429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.6454 - acc: 0.7444 - val_loss: 0.7168 - val_acc: 0.5571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6525 - acc: 0.6722 - val_loss: 0.7164 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6665 - acc: 0.6667 - val_loss: 0.7182 - val_acc: 0.5571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6464 - acc: 0.7111 - val_loss: 0.7188 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6498 - acc: 0.6833 - val_loss: 0.7191 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6578 - acc: 0.7000 - val_loss: 0.7187 - val_acc: 0.5571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6429 - acc: 0.6944 - val_loss: 0.7199 - val_acc: 0.5571\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6462 - acc: 0.6889 - val_loss: 0.7137 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6340 - acc: 0.7222 - val_loss: 0.7154 - val_acc: 0.5429\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6381 - acc: 0.6778 - val_loss: 0.7226 - val_acc: 0.5571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6346 - acc: 0.7111 - val_loss: 0.7232 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6291 - acc: 0.6944 - val_loss: 0.7162 - val_acc: 0.5429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6275 - acc: 0.7167 - val_loss: 0.7205 - val_acc: 0.5571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6098 - acc: 0.7556 - val_loss: 0.7180 - val_acc: 0.5571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6245 - acc: 0.7556 - val_loss: 0.7172 - val_acc: 0.5429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6156 - acc: 0.6944 - val_loss: 0.7156 - val_acc: 0.5429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6090 - acc: 0.7444 - val_loss: 0.7153 - val_acc: 0.5429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6117 - acc: 0.7500 - val_loss: 0.7186 - val_acc: 0.5429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6142 - acc: 0.7444 - val_loss: 0.7245 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6010 - acc: 0.7556 - val_loss: 0.7158 - val_acc: 0.5429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5983 - acc: 0.7500 - val_loss: 0.7177 - val_acc: 0.5429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6000 - acc: 0.7778 - val_loss: 0.7197 - val_acc: 0.5714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6062 - acc: 0.7556 - val_loss: 0.7198 - val_acc: 0.5429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5815 - acc: 0.7833 - val_loss: 0.7192 - val_acc: 0.5429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5946 - acc: 0.7667 - val_loss: 0.7162 - val_acc: 0.5429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6113 - acc: 0.7167 - val_loss: 0.7153 - val_acc: 0.5429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5849 - acc: 0.7778 - val_loss: 0.7159 - val_acc: 0.5571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5909 - acc: 0.7444 - val_loss: 0.7207 - val_acc: 0.5429\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5714 - acc: 0.7667 - val_loss: 0.7212 - val_acc: 0.5571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5841 - acc: 0.7333 - val_loss: 0.7214 - val_acc: 0.5571\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 17ms/step - loss: 0.7767 - acc: 0.5444 - val_loss: 0.7660 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7583 - acc: 0.5278 - val_loss: 0.7518 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7503 - acc: 0.5444 - val_loss: 0.7454 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7367 - acc: 0.5500 - val_loss: 0.7436 - val_acc: 0.4857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7401 - acc: 0.5389 - val_loss: 0.7383 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7355 - acc: 0.5556 - val_loss: 0.7355 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7267 - acc: 0.5778 - val_loss: 0.7323 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7346 - acc: 0.5611 - val_loss: 0.7290 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7296 - acc: 0.5500 - val_loss: 0.7265 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7153 - acc: 0.5778 - val_loss: 0.7234 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7222 - acc: 0.5556 - val_loss: 0.7221 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7178 - acc: 0.5556 - val_loss: 0.7196 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7085 - acc: 0.5611 - val_loss: 0.7198 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7224 - acc: 0.5500 - val_loss: 0.7178 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7052 - acc: 0.5778 - val_loss: 0.7183 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7061 - acc: 0.5500 - val_loss: 0.7156 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6984 - acc: 0.5722 - val_loss: 0.7130 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7100 - acc: 0.5611 - val_loss: 0.7134 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6920 - acc: 0.5722 - val_loss: 0.7127 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6898 - acc: 0.5778 - val_loss: 0.7123 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7046 - acc: 0.5944 - val_loss: 0.7072 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6945 - acc: 0.5944 - val_loss: 0.7072 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6993 - acc: 0.5944 - val_loss: 0.7055 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6973 - acc: 0.6111 - val_loss: 0.7043 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6848 - acc: 0.6000 - val_loss: 0.7058 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6875 - acc: 0.5722 - val_loss: 0.7044 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6859 - acc: 0.5944 - val_loss: 0.6993 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6806 - acc: 0.6222 - val_loss: 0.7004 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6828 - acc: 0.6167 - val_loss: 0.6984 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6695 - acc: 0.6222 - val_loss: 0.6964 - val_acc: 0.6143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6706 - acc: 0.6444 - val_loss: 0.6996 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6711 - acc: 0.6278 - val_loss: 0.7010 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6678 - acc: 0.6056 - val_loss: 0.6978 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6682 - acc: 0.6167 - val_loss: 0.6939 - val_acc: 0.6143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6717 - acc: 0.6278 - val_loss: 0.6965 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6634 - acc: 0.6611 - val_loss: 0.6926 - val_acc: 0.6286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6578 - acc: 0.6444 - val_loss: 0.6909 - val_acc: 0.6286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6615 - acc: 0.6500 - val_loss: 0.6874 - val_acc: 0.6429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6565 - acc: 0.6611 - val_loss: 0.6831 - val_acc: 0.6571\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6565 - acc: 0.6833 - val_loss: 0.6842 - val_acc: 0.6429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6558 - acc: 0.6778 - val_loss: 0.6827 - val_acc: 0.6429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6576 - acc: 0.6944 - val_loss: 0.6886 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6468 - acc: 0.6556 - val_loss: 0.6852 - val_acc: 0.6429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6515 - acc: 0.6667 - val_loss: 0.6803 - val_acc: 0.6571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6354 - acc: 0.7000 - val_loss: 0.6763 - val_acc: 0.6571\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6365 - acc: 0.7278 - val_loss: 0.6741 - val_acc: 0.6857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6329 - acc: 0.7278 - val_loss: 0.6723 - val_acc: 0.7000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6254 - acc: 0.7500 - val_loss: 0.6743 - val_acc: 0.6571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6245 - acc: 0.7111 - val_loss: 0.6758 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6238 - acc: 0.6944 - val_loss: 0.6726 - val_acc: 0.6857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6307 - acc: 0.6944 - val_loss: 0.6727 - val_acc: 0.6714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6324 - acc: 0.7056 - val_loss: 0.6706 - val_acc: 0.6571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6094 - acc: 0.7500 - val_loss: 0.6689 - val_acc: 0.6571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6241 - acc: 0.7500 - val_loss: 0.6722 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6186 - acc: 0.7000 - val_loss: 0.6724 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6132 - acc: 0.7167 - val_loss: 0.6747 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6095 - acc: 0.7111 - val_loss: 0.6691 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6075 - acc: 0.7556 - val_loss: 0.6750 - val_acc: 0.6571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5983 - acc: 0.7333 - val_loss: 0.6700 - val_acc: 0.6571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6060 - acc: 0.7556 - val_loss: 0.6693 - val_acc: 0.6571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6072 - acc: 0.7889 - val_loss: 0.6661 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6002 - acc: 0.7333 - val_loss: 0.6663 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5937 - acc: 0.7778 - val_loss: 0.6673 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5924 - acc: 0.7500 - val_loss: 0.6645 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5987 - acc: 0.7278 - val_loss: 0.6687 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5844 - acc: 0.7611 - val_loss: 0.6674 - val_acc: 0.6571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5864 - acc: 0.7444 - val_loss: 0.6630 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5773 - acc: 0.7722 - val_loss: 0.6708 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5996 - acc: 0.7611 - val_loss: 0.6634 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5804 - acc: 0.7833 - val_loss: 0.6668 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5590 - acc: 0.7833 - val_loss: 0.6627 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5661 - acc: 0.7833 - val_loss: 0.6590 - val_acc: 0.7143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5879 - acc: 0.7611 - val_loss: 0.6621 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5616 - acc: 0.7444 - val_loss: 0.6627 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5778 - acc: 0.7611 - val_loss: 0.6577 - val_acc: 0.7143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5641 - acc: 0.8056 - val_loss: 0.6609 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5492 - acc: 0.8000 - val_loss: 0.6614 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5503 - acc: 0.8111 - val_loss: 0.6592 - val_acc: 0.7143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5778 - acc: 0.7833 - val_loss: 0.6596 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5642 - acc: 0.7722 - val_loss: 0.6624 - val_acc: 0.6857\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 17ms/step - loss: 0.7818 - acc: 0.5333 - val_loss: 0.7555 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7298 - acc: 0.5556 - val_loss: 0.7420 - val_acc: 0.5429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7218 - acc: 0.5611 - val_loss: 0.7407 - val_acc: 0.5429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7183 - acc: 0.5944 - val_loss: 0.7401 - val_acc: 0.5429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7184 - acc: 0.6111 - val_loss: 0.7320 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7139 - acc: 0.5722 - val_loss: 0.7263 - val_acc: 0.5857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7195 - acc: 0.5500 - val_loss: 0.7257 - val_acc: 0.5857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6996 - acc: 0.6056 - val_loss: 0.7219 - val_acc: 0.6000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7126 - acc: 0.6111 - val_loss: 0.7258 - val_acc: 0.5857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7086 - acc: 0.6000 - val_loss: 0.7290 - val_acc: 0.5714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6874 - acc: 0.6278 - val_loss: 0.7240 - val_acc: 0.6000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7036 - acc: 0.5889 - val_loss: 0.7236 - val_acc: 0.5714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 119us/step - loss: 0.6955 - acc: 0.5722 - val_loss: 0.7265 - val_acc: 0.5714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6878 - acc: 0.6000 - val_loss: 0.7235 - val_acc: 0.5857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6780 - acc: 0.6611 - val_loss: 0.7188 - val_acc: 0.5857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6781 - acc: 0.5944 - val_loss: 0.7124 - val_acc: 0.6286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6820 - acc: 0.6778 - val_loss: 0.7146 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6663 - acc: 0.6944 - val_loss: 0.7105 - val_acc: 0.6286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6759 - acc: 0.6111 - val_loss: 0.7088 - val_acc: 0.6143\n",
      "Epoch 20/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6766 - acc: 0.6278 - val_loss: 0.7122 - val_acc: 0.6143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6604 - acc: 0.6667 - val_loss: 0.7076 - val_acc: 0.6143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6757 - acc: 0.6611 - val_loss: 0.7103 - val_acc: 0.6286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6604 - acc: 0.6556 - val_loss: 0.7050 - val_acc: 0.6143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6752 - acc: 0.6278 - val_loss: 0.7115 - val_acc: 0.6143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6629 - acc: 0.6611 - val_loss: 0.7126 - val_acc: 0.6143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6517 - acc: 0.6333 - val_loss: 0.7014 - val_acc: 0.6143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6422 - acc: 0.7056 - val_loss: 0.7018 - val_acc: 0.6286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6364 - acc: 0.6889 - val_loss: 0.6943 - val_acc: 0.6286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6462 - acc: 0.6556 - val_loss: 0.7005 - val_acc: 0.6286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6617 - acc: 0.6556 - val_loss: 0.6970 - val_acc: 0.6143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6442 - acc: 0.6778 - val_loss: 0.6956 - val_acc: 0.6000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6304 - acc: 0.6889 - val_loss: 0.7004 - val_acc: 0.6143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6262 - acc: 0.6889 - val_loss: 0.7002 - val_acc: 0.6286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6375 - acc: 0.6611 - val_loss: 0.6945 - val_acc: 0.6286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6239 - acc: 0.7000 - val_loss: 0.6990 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6260 - acc: 0.6778 - val_loss: 0.6986 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6215 - acc: 0.7000 - val_loss: 0.6951 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6195 - acc: 0.7500 - val_loss: 0.7015 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6140 - acc: 0.7222 - val_loss: 0.6923 - val_acc: 0.6143\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6109 - acc: 0.7444 - val_loss: 0.6949 - val_acc: 0.6143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6158 - acc: 0.7389 - val_loss: 0.6896 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6058 - acc: 0.6944 - val_loss: 0.6921 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6131 - acc: 0.7000 - val_loss: 0.6893 - val_acc: 0.6429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6056 - acc: 0.7222 - val_loss: 0.6829 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6056 - acc: 0.7333 - val_loss: 0.6943 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5943 - acc: 0.7444 - val_loss: 0.6874 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6034 - acc: 0.7556 - val_loss: 0.6983 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6161 - acc: 0.6667 - val_loss: 0.6902 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5999 - acc: 0.7222 - val_loss: 0.6888 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6010 - acc: 0.7167 - val_loss: 0.6970 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6050 - acc: 0.7111 - val_loss: 0.6915 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5855 - acc: 0.7556 - val_loss: 0.6918 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5844 - acc: 0.7444 - val_loss: 0.6877 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5781 - acc: 0.7667 - val_loss: 0.6891 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5956 - acc: 0.7111 - val_loss: 0.6837 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5987 - acc: 0.7333 - val_loss: 0.6822 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5840 - acc: 0.7722 - val_loss: 0.6790 - val_acc: 0.6714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5837 - acc: 0.8056 - val_loss: 0.6851 - val_acc: 0.6429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5839 - acc: 0.7667 - val_loss: 0.6829 - val_acc: 0.6429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5844 - acc: 0.7222 - val_loss: 0.6892 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5746 - acc: 0.7611 - val_loss: 0.6908 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5776 - acc: 0.7333 - val_loss: 0.6770 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5851 - acc: 0.7444 - val_loss: 0.6852 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5615 - acc: 0.7889 - val_loss: 0.6837 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5658 - acc: 0.7889 - val_loss: 0.6855 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5633 - acc: 0.7389 - val_loss: 0.6807 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5729 - acc: 0.7556 - val_loss: 0.6841 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5643 - acc: 0.7389 - val_loss: 0.6852 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5417 - acc: 0.7889 - val_loss: 0.6846 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5480 - acc: 0.7389 - val_loss: 0.6856 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5416 - acc: 0.7944 - val_loss: 0.6766 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5583 - acc: 0.7389 - val_loss: 0.6883 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5205 - acc: 0.7944 - val_loss: 0.6885 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5371 - acc: 0.7944 - val_loss: 0.6925 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5370 - acc: 0.7778 - val_loss: 0.6887 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5557 - acc: 0.7889 - val_loss: 0.6883 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5217 - acc: 0.8111 - val_loss: 0.6873 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5087 - acc: 0.8167 - val_loss: 0.6844 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.5215 - acc: 0.8056 - val_loss: 0.6788 - val_acc: 0.6429\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5254 - acc: 0.7667 - val_loss: 0.6778 - val_acc: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 17ms/step - loss: 0.7933 - acc: 0.4500 - val_loss: 0.7660 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7631 - acc: 0.4889 - val_loss: 0.7568 - val_acc: 0.4857\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7513 - acc: 0.5222 - val_loss: 0.7530 - val_acc: 0.5429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7398 - acc: 0.5278 - val_loss: 0.7495 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7485 - acc: 0.5278 - val_loss: 0.7469 - val_acc: 0.4857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7340 - acc: 0.5556 - val_loss: 0.7456 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7259 - acc: 0.6389 - val_loss: 0.7447 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7201 - acc: 0.6167 - val_loss: 0.7446 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7223 - acc: 0.5944 - val_loss: 0.7434 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7168 - acc: 0.5889 - val_loss: 0.7432 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7206 - acc: 0.5889 - val_loss: 0.7414 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7109 - acc: 0.6278 - val_loss: 0.7414 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7003 - acc: 0.6444 - val_loss: 0.7405 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 238us/step - loss: 0.6948 - acc: 0.6778 - val_loss: 0.7398 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 249us/step - loss: 0.6967 - acc: 0.6611 - val_loss: 0.7406 - val_acc: 0.5571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6973 - acc: 0.6500 - val_loss: 0.7400 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6993 - acc: 0.6778 - val_loss: 0.7392 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6902 - acc: 0.6778 - val_loss: 0.7378 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6855 - acc: 0.7167 - val_loss: 0.7385 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6872 - acc: 0.6667 - val_loss: 0.7377 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6778 - acc: 0.7056 - val_loss: 0.7362 - val_acc: 0.6000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6834 - acc: 0.6944 - val_loss: 0.7364 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6670 - acc: 0.7111 - val_loss: 0.7364 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6665 - acc: 0.7111 - val_loss: 0.7382 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6665 - acc: 0.7056 - val_loss: 0.7357 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6532 - acc: 0.7167 - val_loss: 0.7350 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6612 - acc: 0.7444 - val_loss: 0.7352 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 141us/step - loss: 0.6521 - acc: 0.7444 - val_loss: 0.7338 - val_acc: 0.5000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6517 - acc: 0.7167 - val_loss: 0.7350 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6408 - acc: 0.7556 - val_loss: 0.7324 - val_acc: 0.5286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6377 - acc: 0.7667 - val_loss: 0.7340 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6557 - acc: 0.7278 - val_loss: 0.7313 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6274 - acc: 0.7667 - val_loss: 0.7321 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6276 - acc: 0.7444 - val_loss: 0.7342 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6432 - acc: 0.7222 - val_loss: 0.7328 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6228 - acc: 0.7667 - val_loss: 0.7305 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6233 - acc: 0.7556 - val_loss: 0.7294 - val_acc: 0.5286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6248 - acc: 0.7556 - val_loss: 0.7276 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6194 - acc: 0.7167 - val_loss: 0.7232 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6089 - acc: 0.7667 - val_loss: 0.7236 - val_acc: 0.5143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6114 - acc: 0.7556 - val_loss: 0.7221 - val_acc: 0.5429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6073 - acc: 0.7500 - val_loss: 0.7193 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6044 - acc: 0.7611 - val_loss: 0.7152 - val_acc: 0.5857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6059 - acc: 0.7611 - val_loss: 0.7208 - val_acc: 0.5143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5991 - acc: 0.7500 - val_loss: 0.7193 - val_acc: 0.5286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6009 - acc: 0.7333 - val_loss: 0.7135 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5928 - acc: 0.7556 - val_loss: 0.7149 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5942 - acc: 0.7556 - val_loss: 0.7158 - val_acc: 0.5714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5781 - acc: 0.7667 - val_loss: 0.7087 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5671 - acc: 0.8056 - val_loss: 0.7087 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5634 - acc: 0.7889 - val_loss: 0.7060 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5871 - acc: 0.7778 - val_loss: 0.7128 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5677 - acc: 0.7889 - val_loss: 0.7064 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5678 - acc: 0.7833 - val_loss: 0.7095 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5583 - acc: 0.7944 - val_loss: 0.7074 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5501 - acc: 0.7944 - val_loss: 0.7094 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5573 - acc: 0.8056 - val_loss: 0.7090 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5632 - acc: 0.7778 - val_loss: 0.7059 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5583 - acc: 0.7889 - val_loss: 0.7033 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5601 - acc: 0.7389 - val_loss: 0.7041 - val_acc: 0.6143\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.5404 - acc: 0.8167 - val_loss: 0.7048 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5376 - acc: 0.7944 - val_loss: 0.7119 - val_acc: 0.5857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5387 - acc: 0.7833 - val_loss: 0.7063 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5398 - acc: 0.7667 - val_loss: 0.7082 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5272 - acc: 0.8056 - val_loss: 0.7023 - val_acc: 0.6429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5498 - acc: 0.8000 - val_loss: 0.7022 - val_acc: 0.6429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5325 - acc: 0.7944 - val_loss: 0.7010 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5262 - acc: 0.7778 - val_loss: 0.7062 - val_acc: 0.6286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5138 - acc: 0.8167 - val_loss: 0.7048 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5171 - acc: 0.7889 - val_loss: 0.7035 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5136 - acc: 0.7944 - val_loss: 0.7011 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5225 - acc: 0.7722 - val_loss: 0.7066 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5046 - acc: 0.8222 - val_loss: 0.7036 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5083 - acc: 0.7944 - val_loss: 0.7064 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.4992 - acc: 0.8056 - val_loss: 0.7030 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5016 - acc: 0.8444 - val_loss: 0.7081 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5143 - acc: 0.7611 - val_loss: 0.7231 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5063 - acc: 0.8111 - val_loss: 0.7124 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5200 - acc: 0.7889 - val_loss: 0.7147 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.4921 - acc: 0.8056 - val_loss: 0.7193 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 125us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 17ms/step - loss: 0.8742 - acc: 0.4556 - val_loss: 0.7727 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7863 - acc: 0.4944 - val_loss: 0.7569 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7825 - acc: 0.4889 - val_loss: 0.7448 - val_acc: 0.4429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7545 - acc: 0.4944 - val_loss: 0.7399 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7489 - acc: 0.5222 - val_loss: 0.7385 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7352 - acc: 0.5667 - val_loss: 0.7368 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7457 - acc: 0.5222 - val_loss: 0.7353 - val_acc: 0.5857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7281 - acc: 0.5833 - val_loss: 0.7342 - val_acc: 0.6000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7125 - acc: 0.6278 - val_loss: 0.7340 - val_acc: 0.5857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7284 - acc: 0.5389 - val_loss: 0.7346 - val_acc: 0.5857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7184 - acc: 0.5889 - val_loss: 0.7355 - val_acc: 0.5857\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7045 - acc: 0.6389 - val_loss: 0.7348 - val_acc: 0.5714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7004 - acc: 0.6278 - val_loss: 0.7315 - val_acc: 0.5714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6938 - acc: 0.6333 - val_loss: 0.7306 - val_acc: 0.5571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7086 - acc: 0.5944 - val_loss: 0.7307 - val_acc: 0.5571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.7037 - acc: 0.6111 - val_loss: 0.7325 - val_acc: 0.5571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6966 - acc: 0.6222 - val_loss: 0.7297 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6867 - acc: 0.6833 - val_loss: 0.7280 - val_acc: 0.5714\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6874 - acc: 0.6278 - val_loss: 0.7304 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6927 - acc: 0.6222 - val_loss: 0.7264 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6789 - acc: 0.6111 - val_loss: 0.7273 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6821 - acc: 0.5889 - val_loss: 0.7258 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6805 - acc: 0.6667 - val_loss: 0.7230 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6860 - acc: 0.6278 - val_loss: 0.7163 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6840 - acc: 0.6000 - val_loss: 0.7116 - val_acc: 0.5857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6766 - acc: 0.6333 - val_loss: 0.7112 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6664 - acc: 0.6778 - val_loss: 0.7094 - val_acc: 0.6000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6832 - acc: 0.6333 - val_loss: 0.7155 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6713 - acc: 0.6556 - val_loss: 0.7159 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6602 - acc: 0.6833 - val_loss: 0.7187 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6611 - acc: 0.6389 - val_loss: 0.7121 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6630 - acc: 0.6611 - val_loss: 0.7070 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6658 - acc: 0.6222 - val_loss: 0.7038 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6427 - acc: 0.7222 - val_loss: 0.6996 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6361 - acc: 0.7056 - val_loss: 0.6959 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6531 - acc: 0.6889 - val_loss: 0.6970 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6446 - acc: 0.6889 - val_loss: 0.6909 - val_acc: 0.6000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6544 - acc: 0.6722 - val_loss: 0.6870 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6289 - acc: 0.7222 - val_loss: 0.6904 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6464 - acc: 0.7056 - val_loss: 0.6860 - val_acc: 0.6286\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6380 - acc: 0.6778 - val_loss: 0.6875 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6474 - acc: 0.7222 - val_loss: 0.6876 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6359 - acc: 0.7389 - val_loss: 0.6893 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6261 - acc: 0.7333 - val_loss: 0.6948 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6330 - acc: 0.6778 - val_loss: 0.6863 - val_acc: 0.6429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6356 - acc: 0.7111 - val_loss: 0.6897 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6297 - acc: 0.7000 - val_loss: 0.6942 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6217 - acc: 0.6889 - val_loss: 0.6859 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6118 - acc: 0.7333 - val_loss: 0.6860 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6136 - acc: 0.7000 - val_loss: 0.6863 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6140 - acc: 0.7389 - val_loss: 0.6860 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6033 - acc: 0.7556 - val_loss: 0.6838 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6070 - acc: 0.7556 - val_loss: 0.6829 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5931 - acc: 0.7778 - val_loss: 0.6766 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5855 - acc: 0.7333 - val_loss: 0.6757 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6017 - acc: 0.7000 - val_loss: 0.6748 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6039 - acc: 0.7056 - val_loss: 0.6799 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5861 - acc: 0.7500 - val_loss: 0.6815 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5881 - acc: 0.7556 - val_loss: 0.6775 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5950 - acc: 0.7500 - val_loss: 0.6806 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5963 - acc: 0.7278 - val_loss: 0.6886 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5687 - acc: 0.7778 - val_loss: 0.6819 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5678 - acc: 0.7444 - val_loss: 0.6795 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5691 - acc: 0.7500 - val_loss: 0.6932 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5946 - acc: 0.7056 - val_loss: 0.6851 - val_acc: 0.5857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5696 - acc: 0.7611 - val_loss: 0.6820 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5565 - acc: 0.7889 - val_loss: 0.6945 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5651 - acc: 0.7778 - val_loss: 0.6885 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.5667 - acc: 0.7389 - val_loss: 0.6833 - val_acc: 0.6429\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5643 - acc: 0.7667 - val_loss: 0.6938 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5559 - acc: 0.7500 - val_loss: 0.6998 - val_acc: 0.5857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5715 - acc: 0.7556 - val_loss: 0.6950 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5631 - acc: 0.7333 - val_loss: 0.6927 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.5468 - acc: 0.7611 - val_loss: 0.6878 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5434 - acc: 0.7778 - val_loss: 0.6863 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5321 - acc: 0.8056 - val_loss: 0.6992 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5412 - acc: 0.7500 - val_loss: 0.6886 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5400 - acc: 0.7778 - val_loss: 0.6991 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5165 - acc: 0.8000 - val_loss: 0.6885 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5455 - acc: 0.7556 - val_loss: 0.6900 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 174us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.8415 - acc: 0.4778 - val_loss: 0.7917 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7830 - acc: 0.4722 - val_loss: 0.7737 - val_acc: 0.4857\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7759 - acc: 0.4611 - val_loss: 0.7627 - val_acc: 0.4857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7585 - acc: 0.4667 - val_loss: 0.7580 - val_acc: 0.4429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7538 - acc: 0.5111 - val_loss: 0.7552 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7404 - acc: 0.4944 - val_loss: 0.7530 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7357 - acc: 0.5000 - val_loss: 0.7504 - val_acc: 0.5571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7286 - acc: 0.5333 - val_loss: 0.7484 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7379 - acc: 0.4944 - val_loss: 0.7471 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7331 - acc: 0.5167 - val_loss: 0.7456 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7221 - acc: 0.5778 - val_loss: 0.7430 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7243 - acc: 0.5500 - val_loss: 0.7408 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7143 - acc: 0.5778 - val_loss: 0.7389 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7177 - acc: 0.5667 - val_loss: 0.7382 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6979 - acc: 0.6389 - val_loss: 0.7382 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7108 - acc: 0.5667 - val_loss: 0.7354 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7002 - acc: 0.6333 - val_loss: 0.7356 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7007 - acc: 0.6056 - val_loss: 0.7338 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6992 - acc: 0.6000 - val_loss: 0.7309 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6919 - acc: 0.6444 - val_loss: 0.7294 - val_acc: 0.5571\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/step - loss: 0.6892 - acc: 0.6389 - val_loss: 0.7298 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6917 - acc: 0.6056 - val_loss: 0.7272 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6811 - acc: 0.6667 - val_loss: 0.7270 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6780 - acc: 0.6944 - val_loss: 0.7263 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6723 - acc: 0.6833 - val_loss: 0.7256 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6671 - acc: 0.6778 - val_loss: 0.7246 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6708 - acc: 0.6722 - val_loss: 0.7263 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6719 - acc: 0.6667 - val_loss: 0.7248 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6651 - acc: 0.6722 - val_loss: 0.7272 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6665 - acc: 0.6556 - val_loss: 0.7239 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6554 - acc: 0.7111 - val_loss: 0.7249 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6699 - acc: 0.6667 - val_loss: 0.7260 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6519 - acc: 0.6889 - val_loss: 0.7239 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6641 - acc: 0.7056 - val_loss: 0.7230 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6487 - acc: 0.7111 - val_loss: 0.7233 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6515 - acc: 0.7333 - val_loss: 0.7217 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6441 - acc: 0.7056 - val_loss: 0.7232 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6317 - acc: 0.7389 - val_loss: 0.7217 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6344 - acc: 0.7222 - val_loss: 0.7231 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6352 - acc: 0.7111 - val_loss: 0.7258 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6213 - acc: 0.7278 - val_loss: 0.7198 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6284 - acc: 0.7222 - val_loss: 0.7215 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6322 - acc: 0.7278 - val_loss: 0.7259 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6229 - acc: 0.7278 - val_loss: 0.7196 - val_acc: 0.5714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6179 - acc: 0.7389 - val_loss: 0.7235 - val_acc: 0.5571\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6150 - acc: 0.7500 - val_loss: 0.7270 - val_acc: 0.5571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6198 - acc: 0.7500 - val_loss: 0.7239 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6189 - acc: 0.7333 - val_loss: 0.7237 - val_acc: 0.5429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6096 - acc: 0.7722 - val_loss: 0.7232 - val_acc: 0.5571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6098 - acc: 0.7500 - val_loss: 0.7242 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5980 - acc: 0.7833 - val_loss: 0.7219 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5967 - acc: 0.7722 - val_loss: 0.7230 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5963 - acc: 0.7556 - val_loss: 0.7239 - val_acc: 0.5571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5920 - acc: 0.7944 - val_loss: 0.7278 - val_acc: 0.5571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5841 - acc: 0.7556 - val_loss: 0.7227 - val_acc: 0.5714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5914 - acc: 0.7500 - val_loss: 0.7237 - val_acc: 0.5714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5781 - acc: 0.8000 - val_loss: 0.7221 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5756 - acc: 0.7944 - val_loss: 0.7253 - val_acc: 0.5714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5715 - acc: 0.8000 - val_loss: 0.7342 - val_acc: 0.5429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5716 - acc: 0.8056 - val_loss: 0.7358 - val_acc: 0.5429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5805 - acc: 0.7778 - val_loss: 0.7333 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5784 - acc: 0.7611 - val_loss: 0.7304 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5726 - acc: 0.7889 - val_loss: 0.7316 - val_acc: 0.5571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5644 - acc: 0.8111 - val_loss: 0.7337 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5528 - acc: 0.8000 - val_loss: 0.7319 - val_acc: 0.5571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5801 - acc: 0.8000 - val_loss: 0.7365 - val_acc: 0.5714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5554 - acc: 0.8222 - val_loss: 0.7305 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5478 - acc: 0.8111 - val_loss: 0.7346 - val_acc: 0.5571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5545 - acc: 0.7944 - val_loss: 0.7338 - val_acc: 0.5714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5442 - acc: 0.8333 - val_loss: 0.7426 - val_acc: 0.5857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5450 - acc: 0.7722 - val_loss: 0.7417 - val_acc: 0.5571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5538 - acc: 0.7889 - val_loss: 0.7440 - val_acc: 0.5571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5252 - acc: 0.8167 - val_loss: 0.7376 - val_acc: 0.5714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5248 - acc: 0.8333 - val_loss: 0.7355 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5205 - acc: 0.8556 - val_loss: 0.7384 - val_acc: 0.5857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5290 - acc: 0.8167 - val_loss: 0.7369 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5242 - acc: 0.8333 - val_loss: 0.7372 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5199 - acc: 0.8056 - val_loss: 0.7471 - val_acc: 0.5571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.4988 - acc: 0.8333 - val_loss: 0.7468 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5190 - acc: 0.8389 - val_loss: 0.7464 - val_acc: 0.5714\n",
      "80/80 [==============================] - 0s 175us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 19ms/step - loss: 0.8168 - acc: 0.4722 - val_loss: 0.7780 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7824 - acc: 0.4833 - val_loss: 0.7681 - val_acc: 0.4286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7690 - acc: 0.4611 - val_loss: 0.7620 - val_acc: 0.4429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7537 - acc: 0.5000 - val_loss: 0.7565 - val_acc: 0.4571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7464 - acc: 0.4778 - val_loss: 0.7540 - val_acc: 0.4857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7391 - acc: 0.5000 - val_loss: 0.7518 - val_acc: 0.4857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7226 - acc: 0.5444 - val_loss: 0.7507 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7244 - acc: 0.6000 - val_loss: 0.7482 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7214 - acc: 0.5778 - val_loss: 0.7464 - val_acc: 0.5429\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7212 - acc: 0.5500 - val_loss: 0.7435 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7134 - acc: 0.5833 - val_loss: 0.7408 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7135 - acc: 0.5444 - val_loss: 0.7383 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7054 - acc: 0.5833 - val_loss: 0.7376 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7023 - acc: 0.5778 - val_loss: 0.7344 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7096 - acc: 0.5778 - val_loss: 0.7319 - val_acc: 0.4857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7064 - acc: 0.5833 - val_loss: 0.7303 - val_acc: 0.4857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7038 - acc: 0.5833 - val_loss: 0.7280 - val_acc: 0.4857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6871 - acc: 0.6389 - val_loss: 0.7264 - val_acc: 0.4857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7030 - acc: 0.5556 - val_loss: 0.7274 - val_acc: 0.4857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6945 - acc: 0.5778 - val_loss: 0.7271 - val_acc: 0.4857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6894 - acc: 0.5667 - val_loss: 0.7241 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6929 - acc: 0.5778 - val_loss: 0.7230 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6845 - acc: 0.6056 - val_loss: 0.7187 - val_acc: 0.4857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6786 - acc: 0.6167 - val_loss: 0.7177 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.6841 - acc: 0.6000 - val_loss: 0.7154 - val_acc: 0.5000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6821 - acc: 0.6111 - val_loss: 0.7118 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6765 - acc: 0.6333 - val_loss: 0.7108 - val_acc: 0.5000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6656 - acc: 0.6222 - val_loss: 0.7104 - val_acc: 0.5000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6707 - acc: 0.6389 - val_loss: 0.7073 - val_acc: 0.5429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6711 - acc: 0.6389 - val_loss: 0.7067 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6636 - acc: 0.6944 - val_loss: 0.7056 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6637 - acc: 0.6722 - val_loss: 0.7036 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6657 - acc: 0.6556 - val_loss: 0.7039 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 137us/step - loss: 0.6676 - acc: 0.6667 - val_loss: 0.7013 - val_acc: 0.5429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6574 - acc: 0.6611 - val_loss: 0.7046 - val_acc: 0.5429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6604 - acc: 0.6500 - val_loss: 0.7021 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6504 - acc: 0.6611 - val_loss: 0.7018 - val_acc: 0.5571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6523 - acc: 0.6833 - val_loss: 0.7033 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6443 - acc: 0.7000 - val_loss: 0.7020 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6356 - acc: 0.7056 - val_loss: 0.6974 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.6245 - acc: 0.710 - 0s 150us/step - loss: 0.6379 - acc: 0.6944 - val_loss: 0.6974 - val_acc: 0.5857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6455 - acc: 0.6889 - val_loss: 0.6960 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6301 - acc: 0.6833 - val_loss: 0.6958 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6412 - acc: 0.6556 - val_loss: 0.6927 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 126us/step - loss: 0.6341 - acc: 0.7000 - val_loss: 0.6883 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6331 - acc: 0.7333 - val_loss: 0.6869 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6246 - acc: 0.7611 - val_loss: 0.6874 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6245 - acc: 0.7389 - val_loss: 0.6886 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 146us/step - loss: 0.6147 - acc: 0.7444 - val_loss: 0.6900 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6133 - acc: 0.7444 - val_loss: 0.6898 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6132 - acc: 0.7500 - val_loss: 0.6877 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6189 - acc: 0.7167 - val_loss: 0.6934 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 140us/step - loss: 0.6069 - acc: 0.7000 - val_loss: 0.6884 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6071 - acc: 0.7056 - val_loss: 0.6943 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6013 - acc: 0.7722 - val_loss: 0.6883 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6049 - acc: 0.7500 - val_loss: 0.6857 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5946 - acc: 0.7833 - val_loss: 0.6841 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5911 - acc: 0.7778 - val_loss: 0.6830 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5977 - acc: 0.7722 - val_loss: 0.6882 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5887 - acc: 0.7722 - val_loss: 0.6865 - val_acc: 0.6143\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.5906 - acc: 0.7611 - val_loss: 0.6874 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5826 - acc: 0.7611 - val_loss: 0.6777 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5719 - acc: 0.8000 - val_loss: 0.6889 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5833 - acc: 0.7556 - val_loss: 0.6857 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5704 - acc: 0.7556 - val_loss: 0.6816 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5724 - acc: 0.7778 - val_loss: 0.6820 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5651 - acc: 0.8000 - val_loss: 0.6854 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5701 - acc: 0.7667 - val_loss: 0.6776 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5656 - acc: 0.7889 - val_loss: 0.6798 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5734 - acc: 0.7500 - val_loss: 0.6806 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5655 - acc: 0.7833 - val_loss: 0.6808 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5584 - acc: 0.7667 - val_loss: 0.6810 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5596 - acc: 0.7833 - val_loss: 0.6775 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5568 - acc: 0.8000 - val_loss: 0.6832 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5514 - acc: 0.7833 - val_loss: 0.6771 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5433 - acc: 0.8167 - val_loss: 0.6785 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5538 - acc: 0.7944 - val_loss: 0.6810 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5285 - acc: 0.8167 - val_loss: 0.6846 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5436 - acc: 0.8056 - val_loss: 0.6844 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5469 - acc: 0.7611 - val_loss: 0.6789 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.7394 - acc: 0.5500 - val_loss: 0.7314 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7352 - acc: 0.5167 - val_loss: 0.7300 - val_acc: 0.5429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7371 - acc: 0.5111 - val_loss: 0.7291 - val_acc: 0.5571\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7203 - acc: 0.5889 - val_loss: 0.7265 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7178 - acc: 0.5889 - val_loss: 0.7240 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7143 - acc: 0.5667 - val_loss: 0.7204 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7098 - acc: 0.6056 - val_loss: 0.7178 - val_acc: 0.5571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7135 - acc: 0.5611 - val_loss: 0.7163 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7128 - acc: 0.6000 - val_loss: 0.7165 - val_acc: 0.5429\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7030 - acc: 0.6111 - val_loss: 0.7128 - val_acc: 0.5714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 102us/step - loss: 0.6985 - acc: 0.6278 - val_loss: 0.7106 - val_acc: 0.5571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7003 - acc: 0.6222 - val_loss: 0.7087 - val_acc: 0.5714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6949 - acc: 0.6056 - val_loss: 0.7089 - val_acc: 0.5857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6923 - acc: 0.6333 - val_loss: 0.7065 - val_acc: 0.6000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6965 - acc: 0.6389 - val_loss: 0.7033 - val_acc: 0.6000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6724 - acc: 0.6667 - val_loss: 0.7047 - val_acc: 0.6000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6845 - acc: 0.6444 - val_loss: 0.6996 - val_acc: 0.6000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6827 - acc: 0.6389 - val_loss: 0.6962 - val_acc: 0.6286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6813 - acc: 0.6722 - val_loss: 0.6949 - val_acc: 0.6143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6671 - acc: 0.6722 - val_loss: 0.6925 - val_acc: 0.6429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6691 - acc: 0.6889 - val_loss: 0.6948 - val_acc: 0.6143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6683 - acc: 0.6333 - val_loss: 0.6916 - val_acc: 0.6429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6660 - acc: 0.6611 - val_loss: 0.6899 - val_acc: 0.6571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6488 - acc: 0.6722 - val_loss: 0.6863 - val_acc: 0.6571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6631 - acc: 0.6833 - val_loss: 0.6872 - val_acc: 0.6571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6501 - acc: 0.6611 - val_loss: 0.6839 - val_acc: 0.6571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6605 - acc: 0.6389 - val_loss: 0.6810 - val_acc: 0.6857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6376 - acc: 0.6611 - val_loss: 0.6823 - val_acc: 0.6571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6513 - acc: 0.6778 - val_loss: 0.6784 - val_acc: 0.7143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6274 - acc: 0.7167 - val_loss: 0.6779 - val_acc: 0.7143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6356 - acc: 0.6833 - val_loss: 0.6786 - val_acc: 0.6857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6202 - acc: 0.7056 - val_loss: 0.6730 - val_acc: 0.7429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.6293 - acc: 0.7167 - val_loss: 0.6729 - val_acc: 0.7143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6365 - acc: 0.6778 - val_loss: 0.6709 - val_acc: 0.7143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6213 - acc: 0.7611 - val_loss: 0.6729 - val_acc: 0.6429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6228 - acc: 0.7278 - val_loss: 0.6707 - val_acc: 0.6571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6287 - acc: 0.6889 - val_loss: 0.6685 - val_acc: 0.6714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6269 - acc: 0.6889 - val_loss: 0.6655 - val_acc: 0.7429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6373 - acc: 0.7000 - val_loss: 0.6703 - val_acc: 0.6571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6075 - acc: 0.6944 - val_loss: 0.6638 - val_acc: 0.7143\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/step - loss: 0.6108 - acc: 0.7333 - val_loss: 0.6672 - val_acc: 0.6714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6269 - acc: 0.6833 - val_loss: 0.6602 - val_acc: 0.7286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6148 - acc: 0.7056 - val_loss: 0.6607 - val_acc: 0.7000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6198 - acc: 0.7167 - val_loss: 0.6609 - val_acc: 0.6714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5965 - acc: 0.7333 - val_loss: 0.6586 - val_acc: 0.7000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6032 - acc: 0.7444 - val_loss: 0.6566 - val_acc: 0.7571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5854 - acc: 0.7833 - val_loss: 0.6584 - val_acc: 0.7000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5958 - acc: 0.7611 - val_loss: 0.6593 - val_acc: 0.6714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5919 - acc: 0.7667 - val_loss: 0.6611 - val_acc: 0.6714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5875 - acc: 0.7389 - val_loss: 0.6634 - val_acc: 0.6571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5892 - acc: 0.7444 - val_loss: 0.6569 - val_acc: 0.6857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5976 - acc: 0.7222 - val_loss: 0.6571 - val_acc: 0.6857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5724 - acc: 0.7389 - val_loss: 0.6552 - val_acc: 0.6857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5873 - acc: 0.7611 - val_loss: 0.6584 - val_acc: 0.6857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5735 - acc: 0.7778 - val_loss: 0.6510 - val_acc: 0.7429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5756 - acc: 0.7333 - val_loss: 0.6537 - val_acc: 0.6857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5615 - acc: 0.7722 - val_loss: 0.6606 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5530 - acc: 0.7556 - val_loss: 0.6527 - val_acc: 0.6857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5771 - acc: 0.7444 - val_loss: 0.6546 - val_acc: 0.6857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5596 - acc: 0.7889 - val_loss: 0.6548 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5538 - acc: 0.7556 - val_loss: 0.6591 - val_acc: 0.6714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5752 - acc: 0.7389 - val_loss: 0.6567 - val_acc: 0.6714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5408 - acc: 0.7944 - val_loss: 0.6481 - val_acc: 0.7286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5552 - acc: 0.7722 - val_loss: 0.6532 - val_acc: 0.6857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5793 - acc: 0.7278 - val_loss: 0.6516 - val_acc: 0.7000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5509 - acc: 0.7944 - val_loss: 0.6540 - val_acc: 0.6857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5627 - acc: 0.7333 - val_loss: 0.6548 - val_acc: 0.6857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5577 - acc: 0.7611 - val_loss: 0.6610 - val_acc: 0.6714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5575 - acc: 0.7611 - val_loss: 0.6503 - val_acc: 0.7143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5410 - acc: 0.7722 - val_loss: 0.6517 - val_acc: 0.7143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5297 - acc: 0.7833 - val_loss: 0.6506 - val_acc: 0.7143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5317 - acc: 0.7944 - val_loss: 0.6506 - val_acc: 0.7143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5287 - acc: 0.7722 - val_loss: 0.6505 - val_acc: 0.7143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5337 - acc: 0.8000 - val_loss: 0.6601 - val_acc: 0.6857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5193 - acc: 0.8111 - val_loss: 0.6573 - val_acc: 0.6857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5440 - acc: 0.7500 - val_loss: 0.6600 - val_acc: 0.6857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5104 - acc: 0.8056 - val_loss: 0.6614 - val_acc: 0.6857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5174 - acc: 0.8000 - val_loss: 0.6525 - val_acc: 0.6857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5244 - acc: 0.8167 - val_loss: 0.6572 - val_acc: 0.6857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5257 - acc: 0.7833 - val_loss: 0.6577 - val_acc: 0.6857\n",
      "80/80 [==============================] - 0s 199us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 25ms/step - loss: 0.7473 - acc: 0.4944 - val_loss: 0.7585 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7442 - acc: 0.5000 - val_loss: 0.7612 - val_acc: 0.4714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.7298 - acc: 0.5333 - val_loss: 0.7606 - val_acc: 0.4714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7296 - acc: 0.5500 - val_loss: 0.7533 - val_acc: 0.4571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7259 - acc: 0.5500 - val_loss: 0.7570 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7099 - acc: 0.5667 - val_loss: 0.7572 - val_acc: 0.4857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7265 - acc: 0.5167 - val_loss: 0.7496 - val_acc: 0.4571\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.7177 - acc: 0.5167 - val_loss: 0.7496 - val_acc: 0.4571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.7136 - acc: 0.5722 - val_loss: 0.7510 - val_acc: 0.4857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7223 - acc: 0.5444 - val_loss: 0.7554 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7109 - acc: 0.5722 - val_loss: 0.7566 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.7086 - acc: 0.5556 - val_loss: 0.7521 - val_acc: 0.4857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7078 - acc: 0.5944 - val_loss: 0.7535 - val_acc: 0.4857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7046 - acc: 0.5722 - val_loss: 0.7548 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6981 - acc: 0.5611 - val_loss: 0.7533 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6979 - acc: 0.6056 - val_loss: 0.7521 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7017 - acc: 0.5944 - val_loss: 0.7468 - val_acc: 0.4857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6862 - acc: 0.6222 - val_loss: 0.7450 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6898 - acc: 0.6278 - val_loss: 0.7412 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6810 - acc: 0.6556 - val_loss: 0.7386 - val_acc: 0.5143\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 133us/step - loss: 0.6931 - acc: 0.6167 - val_loss: 0.7420 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6845 - acc: 0.5944 - val_loss: 0.7369 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6737 - acc: 0.6111 - val_loss: 0.7366 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6708 - acc: 0.6389 - val_loss: 0.7339 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6893 - acc: 0.6333 - val_loss: 0.7347 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 115us/step - loss: 0.6746 - acc: 0.6444 - val_loss: 0.7327 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6718 - acc: 0.6667 - val_loss: 0.7341 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 128us/step - loss: 0.6762 - acc: 0.6222 - val_loss: 0.7378 - val_acc: 0.5429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6724 - acc: 0.6444 - val_loss: 0.7388 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6635 - acc: 0.6389 - val_loss: 0.7355 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 124us/step - loss: 0.6690 - acc: 0.6556 - val_loss: 0.7338 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6649 - acc: 0.6611 - val_loss: 0.7305 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6525 - acc: 0.6722 - val_loss: 0.7285 - val_acc: 0.5286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6534 - acc: 0.6889 - val_loss: 0.7267 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6492 - acc: 0.6833 - val_loss: 0.7277 - val_acc: 0.5429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6529 - acc: 0.6889 - val_loss: 0.7250 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6527 - acc: 0.6778 - val_loss: 0.7310 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6208 - acc: 0.7278 - val_loss: 0.7302 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6396 - acc: 0.6833 - val_loss: 0.7301 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6488 - acc: 0.6667 - val_loss: 0.7262 - val_acc: 0.5286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6481 - acc: 0.6722 - val_loss: 0.7238 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6418 - acc: 0.7056 - val_loss: 0.7239 - val_acc: 0.5286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6390 - acc: 0.7167 - val_loss: 0.7260 - val_acc: 0.5286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6330 - acc: 0.6722 - val_loss: 0.7332 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6392 - acc: 0.6611 - val_loss: 0.7393 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6262 - acc: 0.7000 - val_loss: 0.7262 - val_acc: 0.5286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6306 - acc: 0.7167 - val_loss: 0.7289 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 149us/step - loss: 0.6213 - acc: 0.7167 - val_loss: 0.7309 - val_acc: 0.5429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6246 - acc: 0.7000 - val_loss: 0.7267 - val_acc: 0.5429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6260 - acc: 0.7167 - val_loss: 0.7286 - val_acc: 0.5286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6182 - acc: 0.7278 - val_loss: 0.7244 - val_acc: 0.5571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 136us/step - loss: 0.6247 - acc: 0.7278 - val_loss: 0.7262 - val_acc: 0.5571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6138 - acc: 0.7333 - val_loss: 0.7329 - val_acc: 0.5429\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6168 - acc: 0.6833 - val_loss: 0.7272 - val_acc: 0.5714\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6179 - acc: 0.7111 - val_loss: 0.7337 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6130 - acc: 0.7167 - val_loss: 0.7248 - val_acc: 0.5714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.6034 - acc: 0.7500 - val_loss: 0.7222 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6086 - acc: 0.7500 - val_loss: 0.7250 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5957 - acc: 0.7556 - val_loss: 0.7240 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6088 - acc: 0.7444 - val_loss: 0.7251 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6054 - acc: 0.7333 - val_loss: 0.7226 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6051 - acc: 0.7222 - val_loss: 0.7281 - val_acc: 0.5714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6044 - acc: 0.7111 - val_loss: 0.7208 - val_acc: 0.5714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5795 - acc: 0.7667 - val_loss: 0.7235 - val_acc: 0.5857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5739 - acc: 0.7389 - val_loss: 0.7215 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5830 - acc: 0.7500 - val_loss: 0.7213 - val_acc: 0.5714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5770 - acc: 0.7278 - val_loss: 0.7220 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5880 - acc: 0.7167 - val_loss: 0.7233 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5657 - acc: 0.7778 - val_loss: 0.7303 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5933 - acc: 0.7556 - val_loss: 0.7292 - val_acc: 0.5857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.5788 - acc: 0.7500 - val_loss: 0.7274 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 188us/step - loss: 0.5733 - acc: 0.7444 - val_loss: 0.7302 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.5692 - acc: 0.7500 - val_loss: 0.7236 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 183us/step - loss: 0.5682 - acc: 0.7500 - val_loss: 0.7272 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 188us/step - loss: 0.5870 - acc: 0.7111 - val_loss: 0.7280 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.5655 - acc: 0.7722 - val_loss: 0.7206 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5678 - acc: 0.7278 - val_loss: 0.7205 - val_acc: 0.5714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5646 - acc: 0.7611 - val_loss: 0.7269 - val_acc: 0.5714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5699 - acc: 0.7333 - val_loss: 0.7332 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5620 - acc: 0.7389 - val_loss: 0.7287 - val_acc: 0.5714\n",
      "80/80 [==============================] - 0s 312us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 5s 30ms/step - loss: 0.7634 - acc: 0.5333 - val_loss: 0.7831 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 194us/step - loss: 0.7425 - acc: 0.5278 - val_loss: 0.7655 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7316 - acc: 0.5444 - val_loss: 0.7591 - val_acc: 0.5429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7258 - acc: 0.5611 - val_loss: 0.7567 - val_acc: 0.5429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.7125 - acc: 0.5889 - val_loss: 0.7571 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.7224 - acc: 0.5556 - val_loss: 0.7539 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 244us/step - loss: 0.7200 - acc: 0.5722 - val_loss: 0.7519 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.7182 - acc: 0.5667 - val_loss: 0.7517 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.7149 - acc: 0.5333 - val_loss: 0.7531 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.7123 - acc: 0.5722 - val_loss: 0.7496 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 183us/step - loss: 0.7103 - acc: 0.5833 - val_loss: 0.7495 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 188us/step - loss: 0.6977 - acc: 0.5778 - val_loss: 0.7487 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.6920 - acc: 0.6056 - val_loss: 0.7479 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 216us/step - loss: 0.7016 - acc: 0.5889 - val_loss: 0.7462 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 188us/step - loss: 0.6965 - acc: 0.5722 - val_loss: 0.7450 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.6934 - acc: 0.5778 - val_loss: 0.7445 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 152us/step - loss: 0.6834 - acc: 0.6056 - val_loss: 0.7437 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6834 - acc: 0.5944 - val_loss: 0.7410 - val_acc: 0.5714\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6949 - acc: 0.6111 - val_loss: 0.7372 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6873 - acc: 0.6000 - val_loss: 0.7360 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6717 - acc: 0.6278 - val_loss: 0.7332 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 172us/step - loss: 0.6760 - acc: 0.6556 - val_loss: 0.7334 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6782 - acc: 0.6444 - val_loss: 0.7332 - val_acc: 0.5429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6826 - acc: 0.6167 - val_loss: 0.7296 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6727 - acc: 0.6444 - val_loss: 0.7285 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6716 - acc: 0.6611 - val_loss: 0.7277 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6690 - acc: 0.6500 - val_loss: 0.7282 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6622 - acc: 0.6611 - val_loss: 0.7304 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6529 - acc: 0.6444 - val_loss: 0.7303 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6627 - acc: 0.6833 - val_loss: 0.7282 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6624 - acc: 0.6167 - val_loss: 0.7248 - val_acc: 0.5857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6441 - acc: 0.7222 - val_loss: 0.7245 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 126us/step - loss: 0.6467 - acc: 0.6944 - val_loss: 0.7228 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6597 - acc: 0.6778 - val_loss: 0.7216 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6496 - acc: 0.6889 - val_loss: 0.7245 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6545 - acc: 0.6389 - val_loss: 0.7237 - val_acc: 0.5857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.6493 - acc: 0.6444 - val_loss: 0.7221 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6404 - acc: 0.6833 - val_loss: 0.7225 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6355 - acc: 0.6833 - val_loss: 0.7209 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 308us/step - loss: 0.6285 - acc: 0.7111 - val_loss: 0.7199 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 222us/step - loss: 0.6247 - acc: 0.7389 - val_loss: 0.7206 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 324us/step - loss: 0.6224 - acc: 0.6889 - val_loss: 0.7214 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.6138 - acc: 0.7056 - val_loss: 0.7261 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.6199 - acc: 0.6944 - val_loss: 0.7186 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.6249 - acc: 0.7222 - val_loss: 0.7181 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6177 - acc: 0.7278 - val_loss: 0.7133 - val_acc: 0.5857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 162us/step - loss: 0.6294 - acc: 0.7278 - val_loss: 0.7133 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6248 - acc: 0.7167 - val_loss: 0.7140 - val_acc: 0.5857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6142 - acc: 0.7056 - val_loss: 0.7109 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 164us/step - loss: 0.6232 - acc: 0.7111 - val_loss: 0.7097 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6188 - acc: 0.7111 - val_loss: 0.7082 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6178 - acc: 0.7333 - val_loss: 0.7137 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6024 - acc: 0.7278 - val_loss: 0.7104 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6013 - acc: 0.7111 - val_loss: 0.7121 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6049 - acc: 0.7278 - val_loss: 0.7094 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5924 - acc: 0.7611 - val_loss: 0.7127 - val_acc: 0.6000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5867 - acc: 0.7611 - val_loss: 0.7179 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6019 - acc: 0.7333 - val_loss: 0.7092 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5868 - acc: 0.7278 - val_loss: 0.7061 - val_acc: 0.6000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 253us/step - loss: 0.5890 - acc: 0.7333 - val_loss: 0.7101 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5887 - acc: 0.7389 - val_loss: 0.7117 - val_acc: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.5722 - acc: 0.7944 - val_loss: 0.7079 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5945 - acc: 0.7778 - val_loss: 0.7089 - val_acc: 0.6286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 172us/step - loss: 0.5854 - acc: 0.7444 - val_loss: 0.7060 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5824 - acc: 0.7333 - val_loss: 0.7052 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5818 - acc: 0.7333 - val_loss: 0.7112 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5578 - acc: 0.7611 - val_loss: 0.7062 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5789 - acc: 0.7611 - val_loss: 0.7051 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 344us/step - loss: 0.5655 - acc: 0.7778 - val_loss: 0.7052 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 222us/step - loss: 0.5605 - acc: 0.8000 - val_loss: 0.7070 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 183us/step - loss: 0.5532 - acc: 0.7722 - val_loss: 0.7097 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 222us/step - loss: 0.5635 - acc: 0.7611 - val_loss: 0.7153 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 216us/step - loss: 0.5510 - acc: 0.7722 - val_loss: 0.7130 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5611 - acc: 0.7611 - val_loss: 0.7134 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5614 - acc: 0.7389 - val_loss: 0.7089 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.5453 - acc: 0.7889 - val_loss: 0.7121 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5480 - acc: 0.7611 - val_loss: 0.7193 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 183us/step - loss: 0.5367 - acc: 0.7722 - val_loss: 0.7068 - val_acc: 0.6429\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5352 - acc: 0.7944 - val_loss: 0.7089 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5489 - acc: 0.7444 - val_loss: 0.7174 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 175us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.8073 - acc: 0.5000 - val_loss: 0.7762 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7630 - acc: 0.5000 - val_loss: 0.7668 - val_acc: 0.4714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7622 - acc: 0.5000 - val_loss: 0.7606 - val_acc: 0.4286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 149us/step - loss: 0.7499 - acc: 0.4833 - val_loss: 0.7563 - val_acc: 0.4429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7392 - acc: 0.5167 - val_loss: 0.7538 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7334 - acc: 0.5222 - val_loss: 0.7535 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7296 - acc: 0.5556 - val_loss: 0.7499 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.7263 - acc: 0.5611 - val_loss: 0.7483 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7273 - acc: 0.6111 - val_loss: 0.7467 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.7205 - acc: 0.5667 - val_loss: 0.7452 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 164us/step - loss: 0.7203 - acc: 0.5778 - val_loss: 0.7430 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7087 - acc: 0.5833 - val_loss: 0.7410 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7004 - acc: 0.6167 - val_loss: 0.7392 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7104 - acc: 0.5778 - val_loss: 0.7358 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 130us/step - loss: 0.7066 - acc: 0.6056 - val_loss: 0.7356 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 183us/step - loss: 0.6917 - acc: 0.6278 - val_loss: 0.7341 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.7003 - acc: 0.6111 - val_loss: 0.7315 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.6839 - acc: 0.6389 - val_loss: 0.7288 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6884 - acc: 0.6667 - val_loss: 0.7289 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7006 - acc: 0.6000 - val_loss: 0.7287 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6932 - acc: 0.5944 - val_loss: 0.7285 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6811 - acc: 0.6389 - val_loss: 0.7237 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 205us/step - loss: 0.6863 - acc: 0.6500 - val_loss: 0.7243 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.6815 - acc: 0.6444 - val_loss: 0.7234 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6709 - acc: 0.6500 - val_loss: 0.7208 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6791 - acc: 0.6611 - val_loss: 0.7205 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6630 - acc: 0.6722 - val_loss: 0.7206 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6699 - acc: 0.6389 - val_loss: 0.7184 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6719 - acc: 0.6500 - val_loss: 0.7159 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 305us/step - loss: 0.6653 - acc: 0.6611 - val_loss: 0.7136 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 146us/step - loss: 0.6566 - acc: 0.6889 - val_loss: 0.7123 - val_acc: 0.6143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6623 - acc: 0.6833 - val_loss: 0.7118 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6620 - acc: 0.6778 - val_loss: 0.7132 - val_acc: 0.5286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6577 - acc: 0.6778 - val_loss: 0.7130 - val_acc: 0.5143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.6497 - acc: 0.6500 - val_loss: 0.7104 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6534 - acc: 0.7000 - val_loss: 0.7068 - val_acc: 0.5429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6513 - acc: 0.7000 - val_loss: 0.7070 - val_acc: 0.5286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6441 - acc: 0.7056 - val_loss: 0.7062 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6450 - acc: 0.6944 - val_loss: 0.7049 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6324 - acc: 0.7333 - val_loss: 0.7068 - val_acc: 0.5429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6451 - acc: 0.6889 - val_loss: 0.7055 - val_acc: 0.5571\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.6402 - acc: 0.6778 - val_loss: 0.7031 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6272 - acc: 0.7111 - val_loss: 0.7036 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6384 - acc: 0.6889 - val_loss: 0.7026 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6390 - acc: 0.6722 - val_loss: 0.7010 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6173 - acc: 0.7222 - val_loss: 0.7016 - val_acc: 0.5571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6254 - acc: 0.7167 - val_loss: 0.7012 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6404 - acc: 0.6889 - val_loss: 0.7022 - val_acc: 0.5571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6185 - acc: 0.7111 - val_loss: 0.7001 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6119 - acc: 0.7278 - val_loss: 0.7000 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6039 - acc: 0.7056 - val_loss: 0.6997 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5944 - acc: 0.7278 - val_loss: 0.6962 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6113 - acc: 0.7500 - val_loss: 0.6937 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6116 - acc: 0.7333 - val_loss: 0.6947 - val_acc: 0.5714\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5984 - acc: 0.7389 - val_loss: 0.6926 - val_acc: 0.5857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6010 - acc: 0.7389 - val_loss: 0.6961 - val_acc: 0.5571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5987 - acc: 0.7333 - val_loss: 0.6930 - val_acc: 0.5857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6107 - acc: 0.7056 - val_loss: 0.6918 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5815 - acc: 0.7389 - val_loss: 0.6913 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5881 - acc: 0.7556 - val_loss: 0.6916 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5823 - acc: 0.7278 - val_loss: 0.6890 - val_acc: 0.5857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5922 - acc: 0.7167 - val_loss: 0.6917 - val_acc: 0.5857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5786 - acc: 0.7333 - val_loss: 0.6874 - val_acc: 0.5857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5732 - acc: 0.7611 - val_loss: 0.6863 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5593 - acc: 0.7833 - val_loss: 0.6873 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5830 - acc: 0.7278 - val_loss: 0.6876 - val_acc: 0.5857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5582 - acc: 0.7667 - val_loss: 0.6895 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5619 - acc: 0.7667 - val_loss: 0.6863 - val_acc: 0.5857\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5584 - acc: 0.7833 - val_loss: 0.6872 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5690 - acc: 0.7444 - val_loss: 0.6867 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5496 - acc: 0.7778 - val_loss: 0.6878 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5752 - acc: 0.7500 - val_loss: 0.6868 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5659 - acc: 0.7278 - val_loss: 0.6859 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5747 - acc: 0.7278 - val_loss: 0.6851 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5390 - acc: 0.7889 - val_loss: 0.6847 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5482 - acc: 0.7556 - val_loss: 0.6852 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5555 - acc: 0.7611 - val_loss: 0.6832 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5471 - acc: 0.7667 - val_loss: 0.6839 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5444 - acc: 0.7722 - val_loss: 0.6838 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 130us/step - loss: 0.5597 - acc: 0.7778 - val_loss: 0.6833 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.7448 - acc: 0.5333 - val_loss: 0.7586 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7283 - acc: 0.5500 - val_loss: 0.7580 - val_acc: 0.4857\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7269 - acc: 0.5444 - val_loss: 0.7573 - val_acc: 0.4714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7307 - acc: 0.5667 - val_loss: 0.7551 - val_acc: 0.4714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7324 - acc: 0.5611 - val_loss: 0.7568 - val_acc: 0.4857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7177 - acc: 0.5722 - val_loss: 0.7568 - val_acc: 0.4857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.7249 - acc: 0.5556 - val_loss: 0.7539 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7152 - acc: 0.5722 - val_loss: 0.7523 - val_acc: 0.4857\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7002 - acc: 0.6000 - val_loss: 0.7500 - val_acc: 0.4714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7013 - acc: 0.6111 - val_loss: 0.7500 - val_acc: 0.4714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.7215 - acc: 0.5611 - val_loss: 0.7501 - val_acc: 0.4571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7105 - acc: 0.5722 - val_loss: 0.7494 - val_acc: 0.4714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7042 - acc: 0.5833 - val_loss: 0.7493 - val_acc: 0.4571\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7133 - acc: 0.5944 - val_loss: 0.7476 - val_acc: 0.4714\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6990 - acc: 0.6167 - val_loss: 0.7462 - val_acc: 0.4714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6942 - acc: 0.6333 - val_loss: 0.7461 - val_acc: 0.4714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6926 - acc: 0.6278 - val_loss: 0.7444 - val_acc: 0.4714\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7112 - acc: 0.5667 - val_loss: 0.7435 - val_acc: 0.4714\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6870 - acc: 0.6167 - val_loss: 0.7420 - val_acc: 0.4714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6926 - acc: 0.6000 - val_loss: 0.7419 - val_acc: 0.4857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6919 - acc: 0.6056 - val_loss: 0.7417 - val_acc: 0.4714\n",
      "Epoch 22/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.6886 - acc: 0.6111 - val_loss: 0.7433 - val_acc: 0.4714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6843 - acc: 0.5778 - val_loss: 0.7436 - val_acc: 0.4714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6769 - acc: 0.6056 - val_loss: 0.7448 - val_acc: 0.4714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6804 - acc: 0.6278 - val_loss: 0.7427 - val_acc: 0.4714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6718 - acc: 0.5944 - val_loss: 0.7381 - val_acc: 0.4714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6728 - acc: 0.6222 - val_loss: 0.7363 - val_acc: 0.5000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6764 - acc: 0.6667 - val_loss: 0.7347 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6721 - acc: 0.6444 - val_loss: 0.7336 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6728 - acc: 0.6222 - val_loss: 0.7344 - val_acc: 0.5000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6758 - acc: 0.6722 - val_loss: 0.7341 - val_acc: 0.5000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6618 - acc: 0.6722 - val_loss: 0.7336 - val_acc: 0.5000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6676 - acc: 0.6278 - val_loss: 0.7317 - val_acc: 0.5286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6663 - acc: 0.6500 - val_loss: 0.7302 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6673 - acc: 0.6333 - val_loss: 0.7307 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6599 - acc: 0.6778 - val_loss: 0.7300 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6550 - acc: 0.6667 - val_loss: 0.7303 - val_acc: 0.5286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6574 - acc: 0.6889 - val_loss: 0.7299 - val_acc: 0.5000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6537 - acc: 0.6889 - val_loss: 0.7296 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6549 - acc: 0.6611 - val_loss: 0.7297 - val_acc: 0.5286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6400 - acc: 0.6722 - val_loss: 0.7297 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6549 - acc: 0.7000 - val_loss: 0.7299 - val_acc: 0.5143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6415 - acc: 0.7000 - val_loss: 0.7285 - val_acc: 0.5143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6476 - acc: 0.6556 - val_loss: 0.7285 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6556 - acc: 0.6667 - val_loss: 0.7269 - val_acc: 0.5571\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6394 - acc: 0.6889 - val_loss: 0.7264 - val_acc: 0.5571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6478 - acc: 0.6944 - val_loss: 0.7268 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6208 - acc: 0.7389 - val_loss: 0.7254 - val_acc: 0.5857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6331 - acc: 0.7111 - val_loss: 0.7261 - val_acc: 0.5571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6209 - acc: 0.7056 - val_loss: 0.7278 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6407 - acc: 0.6778 - val_loss: 0.7283 - val_acc: 0.5571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6111 - acc: 0.7167 - val_loss: 0.7289 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6271 - acc: 0.6944 - val_loss: 0.7260 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6281 - acc: 0.7222 - val_loss: 0.7271 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6064 - acc: 0.7111 - val_loss: 0.7266 - val_acc: 0.5714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6250 - acc: 0.6944 - val_loss: 0.7248 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.6220 - acc: 0.7111 - val_loss: 0.7258 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.5855 - acc: 0.734 - 0s 161us/step - loss: 0.5921 - acc: 0.7111 - val_loss: 0.7238 - val_acc: 0.6429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6042 - acc: 0.7167 - val_loss: 0.7272 - val_acc: 0.5714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6193 - acc: 0.6778 - val_loss: 0.7261 - val_acc: 0.5714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.6138 - acc: 0.7222 - val_loss: 0.7258 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6116 - acc: 0.7000 - val_loss: 0.7236 - val_acc: 0.5857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6145 - acc: 0.7167 - val_loss: 0.7244 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5872 - acc: 0.7778 - val_loss: 0.7291 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5812 - acc: 0.7333 - val_loss: 0.7298 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5706 - acc: 0.7500 - val_loss: 0.7247 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5908 - acc: 0.7333 - val_loss: 0.7244 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5953 - acc: 0.7556 - val_loss: 0.7246 - val_acc: 0.5857\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5729 - acc: 0.7444 - val_loss: 0.7264 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5689 - acc: 0.7889 - val_loss: 0.7286 - val_acc: 0.5714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5740 - acc: 0.7278 - val_loss: 0.7271 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5690 - acc: 0.7722 - val_loss: 0.7333 - val_acc: 0.5714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5728 - acc: 0.7500 - val_loss: 0.7270 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5851 - acc: 0.7556 - val_loss: 0.7259 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5654 - acc: 0.7500 - val_loss: 0.7249 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5443 - acc: 0.7778 - val_loss: 0.7322 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5620 - acc: 0.7611 - val_loss: 0.7311 - val_acc: 0.5714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5720 - acc: 0.7111 - val_loss: 0.7288 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5552 - acc: 0.7722 - val_loss: 0.7325 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5606 - acc: 0.7500 - val_loss: 0.7298 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 162us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.9382 - acc: 0.4556 - val_loss: 0.7984 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 112us/step - loss: 0.8397 - acc: 0.4611 - val_loss: 0.7714 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.8125 - acc: 0.4667 - val_loss: 0.7572 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7733 - acc: 0.4944 - val_loss: 0.7502 - val_acc: 0.5714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 172us/step - loss: 0.7596 - acc: 0.5167 - val_loss: 0.7438 - val_acc: 0.5857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 152us/step - loss: 0.7571 - acc: 0.5222 - val_loss: 0.7379 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7360 - acc: 0.5778 - val_loss: 0.7345 - val_acc: 0.6143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7397 - acc: 0.5611 - val_loss: 0.7318 - val_acc: 0.6000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7189 - acc: 0.5722 - val_loss: 0.7307 - val_acc: 0.6571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7277 - acc: 0.5500 - val_loss: 0.7275 - val_acc: 0.6143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7128 - acc: 0.6167 - val_loss: 0.7253 - val_acc: 0.5714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7131 - acc: 0.5889 - val_loss: 0.7268 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7218 - acc: 0.5500 - val_loss: 0.7259 - val_acc: 0.4857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7203 - acc: 0.5778 - val_loss: 0.7267 - val_acc: 0.4857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7164 - acc: 0.5333 - val_loss: 0.7238 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7014 - acc: 0.6111 - val_loss: 0.7222 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7101 - acc: 0.5944 - val_loss: 0.7185 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6934 - acc: 0.6389 - val_loss: 0.7197 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6878 - acc: 0.6556 - val_loss: 0.7184 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6943 - acc: 0.6111 - val_loss: 0.7164 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6879 - acc: 0.6389 - val_loss: 0.7193 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6770 - acc: 0.6611 - val_loss: 0.7167 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6974 - acc: 0.6056 - val_loss: 0.7127 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6883 - acc: 0.6389 - val_loss: 0.7131 - val_acc: 0.5714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6787 - acc: 0.6611 - val_loss: 0.7134 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6737 - acc: 0.6500 - val_loss: 0.7121 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6796 - acc: 0.6444 - val_loss: 0.7111 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6912 - acc: 0.6389 - val_loss: 0.7123 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6824 - acc: 0.6333 - val_loss: 0.7096 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6794 - acc: 0.6389 - val_loss: 0.7095 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6858 - acc: 0.6500 - val_loss: 0.7132 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6771 - acc: 0.6778 - val_loss: 0.7109 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6755 - acc: 0.6278 - val_loss: 0.7049 - val_acc: 0.6429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 89us/step - loss: 0.6578 - acc: 0.6833 - val_loss: 0.7058 - val_acc: 0.6286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6585 - acc: 0.6667 - val_loss: 0.7056 - val_acc: 0.6429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6622 - acc: 0.6889 - val_loss: 0.7053 - val_acc: 0.6286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6579 - acc: 0.6667 - val_loss: 0.7063 - val_acc: 0.6286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6485 - acc: 0.6833 - val_loss: 0.7035 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6501 - acc: 0.6778 - val_loss: 0.7098 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6489 - acc: 0.6611 - val_loss: 0.7064 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6378 - acc: 0.6778 - val_loss: 0.6988 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6458 - acc: 0.6833 - val_loss: 0.7007 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6522 - acc: 0.6444 - val_loss: 0.6971 - val_acc: 0.6286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6538 - acc: 0.6611 - val_loss: 0.6946 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6348 - acc: 0.7222 - val_loss: 0.6885 - val_acc: 0.6286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6300 - acc: 0.7222 - val_loss: 0.6957 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6304 - acc: 0.6833 - val_loss: 0.6981 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6299 - acc: 0.7056 - val_loss: 0.6947 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6256 - acc: 0.7111 - val_loss: 0.6922 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6357 - acc: 0.7222 - val_loss: 0.6894 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6328 - acc: 0.6667 - val_loss: 0.6930 - val_acc: 0.6429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6260 - acc: 0.6889 - val_loss: 0.6900 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6171 - acc: 0.7167 - val_loss: 0.6922 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6147 - acc: 0.7444 - val_loss: 0.6868 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6072 - acc: 0.7222 - val_loss: 0.6872 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6128 - acc: 0.7278 - val_loss: 0.6833 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5917 - acc: 0.7611 - val_loss: 0.6883 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6070 - acc: 0.7278 - val_loss: 0.6935 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6059 - acc: 0.7389 - val_loss: 0.6846 - val_acc: 0.6429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6031 - acc: 0.7056 - val_loss: 0.6860 - val_acc: 0.6571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5835 - acc: 0.7611 - val_loss: 0.6861 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6027 - acc: 0.7444 - val_loss: 0.6945 - val_acc: 0.5857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5922 - acc: 0.7611 - val_loss: 0.6893 - val_acc: 0.6286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5846 - acc: 0.7278 - val_loss: 0.6840 - val_acc: 0.6714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5908 - acc: 0.7444 - val_loss: 0.6901 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5915 - acc: 0.7278 - val_loss: 0.6927 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5700 - acc: 0.7778 - val_loss: 0.6860 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5783 - acc: 0.7833 - val_loss: 0.6852 - val_acc: 0.6714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5972 - acc: 0.7333 - val_loss: 0.6923 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5692 - acc: 0.7444 - val_loss: 0.6859 - val_acc: 0.6714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5926 - acc: 0.7278 - val_loss: 0.6818 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5867 - acc: 0.7222 - val_loss: 0.6837 - val_acc: 0.6571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 109us/step - loss: 0.5712 - acc: 0.7611 - val_loss: 0.6958 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5772 - acc: 0.7389 - val_loss: 0.6896 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5592 - acc: 0.7667 - val_loss: 0.6876 - val_acc: 0.6857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5510 - acc: 0.7944 - val_loss: 0.6916 - val_acc: 0.6714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5622 - acc: 0.7611 - val_loss: 0.6925 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5524 - acc: 0.7778 - val_loss: 0.6946 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5579 - acc: 0.7500 - val_loss: 0.6925 - val_acc: 0.6857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5581 - acc: 0.7611 - val_loss: 0.6912 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.7630 - acc: 0.4611 - val_loss: 0.7602 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7463 - acc: 0.5167 - val_loss: 0.7561 - val_acc: 0.4571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7404 - acc: 0.5389 - val_loss: 0.7542 - val_acc: 0.4429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7399 - acc: 0.5333 - val_loss: 0.7523 - val_acc: 0.4429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7362 - acc: 0.5278 - val_loss: 0.7511 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7280 - acc: 0.5333 - val_loss: 0.7503 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7171 - acc: 0.5833 - val_loss: 0.7495 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7197 - acc: 0.5556 - val_loss: 0.7492 - val_acc: 0.4571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7192 - acc: 0.5444 - val_loss: 0.7485 - val_acc: 0.4571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7162 - acc: 0.5500 - val_loss: 0.7476 - val_acc: 0.4571\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7111 - acc: 0.5778 - val_loss: 0.7469 - val_acc: 0.4429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7061 - acc: 0.5944 - val_loss: 0.7466 - val_acc: 0.4429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7149 - acc: 0.5611 - val_loss: 0.7460 - val_acc: 0.4429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7079 - acc: 0.5833 - val_loss: 0.7459 - val_acc: 0.4429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7064 - acc: 0.5778 - val_loss: 0.7456 - val_acc: 0.4429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6938 - acc: 0.6444 - val_loss: 0.7456 - val_acc: 0.4571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6972 - acc: 0.6111 - val_loss: 0.7450 - val_acc: 0.4571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6957 - acc: 0.5833 - val_loss: 0.7446 - val_acc: 0.4857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6863 - acc: 0.6222 - val_loss: 0.7449 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6827 - acc: 0.6222 - val_loss: 0.7456 - val_acc: 0.4714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6801 - acc: 0.6167 - val_loss: 0.7446 - val_acc: 0.4571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6873 - acc: 0.6444 - val_loss: 0.7433 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6882 - acc: 0.6444 - val_loss: 0.7429 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6878 - acc: 0.6000 - val_loss: 0.7419 - val_acc: 0.4714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6798 - acc: 0.6389 - val_loss: 0.7414 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6662 - acc: 0.6667 - val_loss: 0.7413 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6688 - acc: 0.6556 - val_loss: 0.7420 - val_acc: 0.4857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.6680 - acc: 0.6611 - val_loss: 0.7418 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6601 - acc: 0.6722 - val_loss: 0.7411 - val_acc: 0.5000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6678 - acc: 0.6611 - val_loss: 0.7423 - val_acc: 0.5000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6617 - acc: 0.6389 - val_loss: 0.7413 - val_acc: 0.5000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6544 - acc: 0.6833 - val_loss: 0.7412 - val_acc: 0.4857\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6604 - acc: 0.6722 - val_loss: 0.7419 - val_acc: 0.5000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6496 - acc: 0.7111 - val_loss: 0.7421 - val_acc: 0.5000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6472 - acc: 0.6833 - val_loss: 0.7403 - val_acc: 0.4571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6542 - acc: 0.7000 - val_loss: 0.7408 - val_acc: 0.4714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6376 - acc: 0.7222 - val_loss: 0.7410 - val_acc: 0.4857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6422 - acc: 0.7056 - val_loss: 0.7438 - val_acc: 0.4571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6270 - acc: 0.7222 - val_loss: 0.7415 - val_acc: 0.4714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6311 - acc: 0.7333 - val_loss: 0.7423 - val_acc: 0.4714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6270 - acc: 0.7278 - val_loss: 0.7431 - val_acc: 0.4714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 112us/step - loss: 0.6210 - acc: 0.7167 - val_loss: 0.7437 - val_acc: 0.4714\n",
      "Epoch 43/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6343 - acc: 0.7111 - val_loss: 0.7442 - val_acc: 0.4857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6294 - acc: 0.7222 - val_loss: 0.7450 - val_acc: 0.4429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6226 - acc: 0.7056 - val_loss: 0.7466 - val_acc: 0.4857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6209 - acc: 0.7389 - val_loss: 0.7430 - val_acc: 0.5143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6023 - acc: 0.7278 - val_loss: 0.7440 - val_acc: 0.5286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 102us/step - loss: 0.6246 - acc: 0.7000 - val_loss: 0.7441 - val_acc: 0.5143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6125 - acc: 0.7500 - val_loss: 0.7437 - val_acc: 0.5143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6073 - acc: 0.7444 - val_loss: 0.7420 - val_acc: 0.5143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6161 - acc: 0.7222 - val_loss: 0.7440 - val_acc: 0.5143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.6090 - acc: 0.7222 - val_loss: 0.7412 - val_acc: 0.5143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6067 - acc: 0.7500 - val_loss: 0.7408 - val_acc: 0.5143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6031 - acc: 0.7667 - val_loss: 0.7424 - val_acc: 0.5000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5975 - acc: 0.7500 - val_loss: 0.7480 - val_acc: 0.5286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6043 - acc: 0.7278 - val_loss: 0.7402 - val_acc: 0.5143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6023 - acc: 0.7667 - val_loss: 0.7412 - val_acc: 0.5286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5836 - acc: 0.7778 - val_loss: 0.7406 - val_acc: 0.5143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5957 - acc: 0.7278 - val_loss: 0.7449 - val_acc: 0.5000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5838 - acc: 0.7889 - val_loss: 0.7421 - val_acc: 0.5143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5817 - acc: 0.7500 - val_loss: 0.7436 - val_acc: 0.5000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5950 - acc: 0.7444 - val_loss: 0.7462 - val_acc: 0.5286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5891 - acc: 0.7722 - val_loss: 0.7463 - val_acc: 0.5286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5838 - acc: 0.7556 - val_loss: 0.7432 - val_acc: 0.5143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5690 - acc: 0.7556 - val_loss: 0.7487 - val_acc: 0.5286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5649 - acc: 0.7722 - val_loss: 0.7438 - val_acc: 0.5000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5753 - acc: 0.7556 - val_loss: 0.7462 - val_acc: 0.5000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5664 - acc: 0.7722 - val_loss: 0.7482 - val_acc: 0.5429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5692 - acc: 0.7611 - val_loss: 0.7468 - val_acc: 0.5143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5754 - acc: 0.7944 - val_loss: 0.7474 - val_acc: 0.5286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5617 - acc: 0.7722 - val_loss: 0.7520 - val_acc: 0.5286\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5580 - acc: 0.7667 - val_loss: 0.7512 - val_acc: 0.5143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5460 - acc: 0.8056 - val_loss: 0.7542 - val_acc: 0.5286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5650 - acc: 0.7611 - val_loss: 0.7497 - val_acc: 0.5143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5502 - acc: 0.7944 - val_loss: 0.7492 - val_acc: 0.5143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5586 - acc: 0.7444 - val_loss: 0.7467 - val_acc: 0.5143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5443 - acc: 0.7778 - val_loss: 0.7507 - val_acc: 0.5286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5491 - acc: 0.7778 - val_loss: 0.7559 - val_acc: 0.5286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5343 - acc: 0.8056 - val_loss: 0.7513 - val_acc: 0.5143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5369 - acc: 0.7889 - val_loss: 0.7503 - val_acc: 0.5429\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.7573 - acc: 0.5167 - val_loss: 0.7638 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7671 - acc: 0.4500 - val_loss: 0.7575 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7496 - acc: 0.4889 - val_loss: 0.7553 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7504 - acc: 0.5000 - val_loss: 0.7546 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7396 - acc: 0.4944 - val_loss: 0.7529 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7256 - acc: 0.5833 - val_loss: 0.7500 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7361 - acc: 0.5444 - val_loss: 0.7482 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7288 - acc: 0.5611 - val_loss: 0.7483 - val_acc: 0.4857\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7322 - acc: 0.5500 - val_loss: 0.7469 - val_acc: 0.4714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7151 - acc: 0.5833 - val_loss: 0.7469 - val_acc: 0.4857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7142 - acc: 0.6000 - val_loss: 0.7449 - val_acc: 0.4714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7190 - acc: 0.5833 - val_loss: 0.7425 - val_acc: 0.4857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7198 - acc: 0.5667 - val_loss: 0.7422 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7069 - acc: 0.5944 - val_loss: 0.7404 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7009 - acc: 0.6056 - val_loss: 0.7394 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 118us/step - loss: 0.7032 - acc: 0.6000 - val_loss: 0.7363 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7019 - acc: 0.6167 - val_loss: 0.7366 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6970 - acc: 0.6389 - val_loss: 0.7386 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6889 - acc: 0.6111 - val_loss: 0.7378 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6885 - acc: 0.5944 - val_loss: 0.7348 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6903 - acc: 0.6389 - val_loss: 0.7338 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6857 - acc: 0.6333 - val_loss: 0.7326 - val_acc: 0.5286\n",
      "Epoch 23/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6799 - acc: 0.6333 - val_loss: 0.7326 - val_acc: 0.5429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6792 - acc: 0.6556 - val_loss: 0.7303 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6734 - acc: 0.6611 - val_loss: 0.7316 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 97us/step - loss: 0.6866 - acc: 0.6667 - val_loss: 0.7295 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6876 - acc: 0.6278 - val_loss: 0.7264 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6731 - acc: 0.6722 - val_loss: 0.7252 - val_acc: 0.5429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6681 - acc: 0.6778 - val_loss: 0.7234 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6628 - acc: 0.6722 - val_loss: 0.7238 - val_acc: 0.5286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.6580 - acc: 0.6778 - val_loss: 0.7205 - val_acc: 0.5286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6468 - acc: 0.7222 - val_loss: 0.7222 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6515 - acc: 0.7111 - val_loss: 0.7193 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6481 - acc: 0.7222 - val_loss: 0.7190 - val_acc: 0.5429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6342 - acc: 0.6889 - val_loss: 0.7212 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6550 - acc: 0.6944 - val_loss: 0.7223 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6407 - acc: 0.6889 - val_loss: 0.7204 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6472 - acc: 0.7167 - val_loss: 0.7169 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6401 - acc: 0.7111 - val_loss: 0.7103 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6345 - acc: 0.7111 - val_loss: 0.7106 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6214 - acc: 0.7222 - val_loss: 0.7142 - val_acc: 0.5571\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6311 - acc: 0.6944 - val_loss: 0.7084 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6275 - acc: 0.7333 - val_loss: 0.7092 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6159 - acc: 0.7278 - val_loss: 0.7113 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6260 - acc: 0.6833 - val_loss: 0.7065 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6241 - acc: 0.7444 - val_loss: 0.7080 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6080 - acc: 0.7444 - val_loss: 0.7038 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6213 - acc: 0.7278 - val_loss: 0.7026 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6132 - acc: 0.7333 - val_loss: 0.7002 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5982 - acc: 0.7667 - val_loss: 0.7046 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5952 - acc: 0.7611 - val_loss: 0.7045 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6026 - acc: 0.7444 - val_loss: 0.7060 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6111 - acc: 0.7444 - val_loss: 0.7003 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5862 - acc: 0.7722 - val_loss: 0.6973 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5841 - acc: 0.7667 - val_loss: 0.6952 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5942 - acc: 0.7500 - val_loss: 0.6958 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5720 - acc: 0.7833 - val_loss: 0.6958 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5833 - acc: 0.7722 - val_loss: 0.6957 - val_acc: 0.6429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5745 - acc: 0.8167 - val_loss: 0.6914 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5710 - acc: 0.7667 - val_loss: 0.6931 - val_acc: 0.6571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5626 - acc: 0.7944 - val_loss: 0.6897 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5652 - acc: 0.7778 - val_loss: 0.6892 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5429 - acc: 0.8222 - val_loss: 0.6947 - val_acc: 0.6571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5577 - acc: 0.7833 - val_loss: 0.6880 - val_acc: 0.6571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5494 - acc: 0.7833 - val_loss: 0.6888 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5644 - acc: 0.7778 - val_loss: 0.6876 - val_acc: 0.6571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5490 - acc: 0.8111 - val_loss: 0.6913 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5526 - acc: 0.7722 - val_loss: 0.6886 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5606 - acc: 0.7778 - val_loss: 0.6903 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5310 - acc: 0.8000 - val_loss: 0.6863 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5532 - acc: 0.7944 - val_loss: 0.6856 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.5370 - acc: 0.8111 - val_loss: 0.6889 - val_acc: 0.6857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5421 - acc: 0.8000 - val_loss: 0.6875 - val_acc: 0.6714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5414 - acc: 0.8000 - val_loss: 0.6862 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5375 - acc: 0.7833 - val_loss: 0.6889 - val_acc: 0.6857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5343 - acc: 0.7833 - val_loss: 0.6898 - val_acc: 0.6857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.5485 - acc: 0.7611 - val_loss: 0.6845 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5327 - acc: 0.8000 - val_loss: 0.6961 - val_acc: 0.6714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5209 - acc: 0.7889 - val_loss: 0.6959 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5216 - acc: 0.8000 - val_loss: 0.6900 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.8355 - acc: 0.4611 - val_loss: 0.7567 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7717 - acc: 0.4889 - val_loss: 0.7480 - val_acc: 0.5286\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.7626 - acc: 0.5167 - val_loss: 0.7430 - val_acc: 0.4857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7428 - acc: 0.5222 - val_loss: 0.7418 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7438 - acc: 0.5278 - val_loss: 0.7407 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7372 - acc: 0.5333 - val_loss: 0.7404 - val_acc: 0.4857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7291 - acc: 0.6000 - val_loss: 0.7393 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7249 - acc: 0.5444 - val_loss: 0.7390 - val_acc: 0.5429\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7271 - acc: 0.5556 - val_loss: 0.7384 - val_acc: 0.5571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7079 - acc: 0.6222 - val_loss: 0.7382 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7188 - acc: 0.5667 - val_loss: 0.7370 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7104 - acc: 0.6111 - val_loss: 0.7382 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7123 - acc: 0.5889 - val_loss: 0.7389 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7172 - acc: 0.5722 - val_loss: 0.7387 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7060 - acc: 0.6056 - val_loss: 0.7398 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7051 - acc: 0.6056 - val_loss: 0.7392 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6961 - acc: 0.6444 - val_loss: 0.7390 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7000 - acc: 0.6389 - val_loss: 0.7375 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7038 - acc: 0.6167 - val_loss: 0.7368 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6885 - acc: 0.6667 - val_loss: 0.7362 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6920 - acc: 0.6222 - val_loss: 0.7341 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6870 - acc: 0.6444 - val_loss: 0.7322 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6857 - acc: 0.6778 - val_loss: 0.7327 - val_acc: 0.4857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6812 - acc: 0.6833 - val_loss: 0.7314 - val_acc: 0.5000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6748 - acc: 0.6611 - val_loss: 0.7327 - val_acc: 0.5000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6787 - acc: 0.6500 - val_loss: 0.7304 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6701 - acc: 0.6944 - val_loss: 0.7307 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6857 - acc: 0.6056 - val_loss: 0.7280 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6749 - acc: 0.6722 - val_loss: 0.7282 - val_acc: 0.4857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6746 - acc: 0.6556 - val_loss: 0.7258 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6750 - acc: 0.6444 - val_loss: 0.7271 - val_acc: 0.5000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6721 - acc: 0.6667 - val_loss: 0.7288 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6708 - acc: 0.6722 - val_loss: 0.7302 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6635 - acc: 0.6833 - val_loss: 0.7252 - val_acc: 0.5143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6535 - acc: 0.6833 - val_loss: 0.7277 - val_acc: 0.5143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6529 - acc: 0.6889 - val_loss: 0.7284 - val_acc: 0.5143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6554 - acc: 0.6889 - val_loss: 0.7269 - val_acc: 0.5286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6532 - acc: 0.6667 - val_loss: 0.7291 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6452 - acc: 0.7056 - val_loss: 0.7269 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6436 - acc: 0.6833 - val_loss: 0.7272 - val_acc: 0.5286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6391 - acc: 0.6944 - val_loss: 0.7269 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6192 - acc: 0.7111 - val_loss: 0.7304 - val_acc: 0.5286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6473 - acc: 0.6611 - val_loss: 0.7296 - val_acc: 0.5286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6461 - acc: 0.6667 - val_loss: 0.7236 - val_acc: 0.5143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6319 - acc: 0.6833 - val_loss: 0.7232 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6347 - acc: 0.7278 - val_loss: 0.7246 - val_acc: 0.5429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6269 - acc: 0.7000 - val_loss: 0.7257 - val_acc: 0.5429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6463 - acc: 0.7056 - val_loss: 0.7292 - val_acc: 0.5286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6231 - acc: 0.7000 - val_loss: 0.7231 - val_acc: 0.5571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6295 - acc: 0.7056 - val_loss: 0.7229 - val_acc: 0.5571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5978 - acc: 0.7556 - val_loss: 0.7285 - val_acc: 0.5429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6213 - acc: 0.6611 - val_loss: 0.7244 - val_acc: 0.5429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6134 - acc: 0.7167 - val_loss: 0.7282 - val_acc: 0.5286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6094 - acc: 0.7222 - val_loss: 0.7291 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6012 - acc: 0.7500 - val_loss: 0.7267 - val_acc: 0.5429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5885 - acc: 0.7500 - val_loss: 0.7229 - val_acc: 0.5429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6107 - acc: 0.7222 - val_loss: 0.7298 - val_acc: 0.5429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6075 - acc: 0.6833 - val_loss: 0.7246 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5981 - acc: 0.7556 - val_loss: 0.7288 - val_acc: 0.5571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5919 - acc: 0.7333 - val_loss: 0.7235 - val_acc: 0.5714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5919 - acc: 0.7333 - val_loss: 0.7254 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6027 - acc: 0.7333 - val_loss: 0.7194 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5928 - acc: 0.7278 - val_loss: 0.7180 - val_acc: 0.5857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5855 - acc: 0.7444 - val_loss: 0.7198 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5868 - acc: 0.7333 - val_loss: 0.7181 - val_acc: 0.5429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5627 - acc: 0.7889 - val_loss: 0.7210 - val_acc: 0.5714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5794 - acc: 0.7389 - val_loss: 0.7206 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5745 - acc: 0.7389 - val_loss: 0.7196 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5735 - acc: 0.7500 - val_loss: 0.7157 - val_acc: 0.5714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5760 - acc: 0.7222 - val_loss: 0.7129 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5722 - acc: 0.7444 - val_loss: 0.7131 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5787 - acc: 0.7056 - val_loss: 0.7138 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5769 - acc: 0.7500 - val_loss: 0.7199 - val_acc: 0.5714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5473 - acc: 0.8000 - val_loss: 0.7202 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5708 - acc: 0.7611 - val_loss: 0.7244 - val_acc: 0.5714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5581 - acc: 0.7889 - val_loss: 0.7241 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5447 - acc: 0.7667 - val_loss: 0.7272 - val_acc: 0.5857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5422 - acc: 0.7778 - val_loss: 0.7242 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5497 - acc: 0.7611 - val_loss: 0.7231 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5463 - acc: 0.7667 - val_loss: 0.7262 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.7520 - acc: 0.5222 - val_loss: 0.7435 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7390 - acc: 0.5278 - val_loss: 0.7401 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7373 - acc: 0.5333 - val_loss: 0.7379 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7321 - acc: 0.5278 - val_loss: 0.7366 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7333 - acc: 0.5222 - val_loss: 0.7345 - val_acc: 0.5286\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7259 - acc: 0.5556 - val_loss: 0.7362 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7196 - acc: 0.5611 - val_loss: 0.7377 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7186 - acc: 0.5556 - val_loss: 0.7359 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7256 - acc: 0.5389 - val_loss: 0.7343 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7136 - acc: 0.5722 - val_loss: 0.7326 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7215 - acc: 0.5389 - val_loss: 0.7307 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7179 - acc: 0.5389 - val_loss: 0.7312 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7162 - acc: 0.5611 - val_loss: 0.7290 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7108 - acc: 0.5611 - val_loss: 0.7291 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7106 - acc: 0.5667 - val_loss: 0.7291 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7150 - acc: 0.5611 - val_loss: 0.7252 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7052 - acc: 0.5556 - val_loss: 0.7247 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7017 - acc: 0.5889 - val_loss: 0.7233 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7027 - acc: 0.5778 - val_loss: 0.7257 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6944 - acc: 0.5556 - val_loss: 0.7230 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6944 - acc: 0.5944 - val_loss: 0.7245 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7119 - acc: 0.5611 - val_loss: 0.7190 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6917 - acc: 0.5833 - val_loss: 0.7185 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6963 - acc: 0.5778 - val_loss: 0.7173 - val_acc: 0.5143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6975 - acc: 0.5722 - val_loss: 0.7157 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6802 - acc: 0.6111 - val_loss: 0.7158 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6938 - acc: 0.6111 - val_loss: 0.7158 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6900 - acc: 0.5667 - val_loss: 0.7150 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6790 - acc: 0.6278 - val_loss: 0.7118 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6912 - acc: 0.5833 - val_loss: 0.7091 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6801 - acc: 0.6556 - val_loss: 0.7087 - val_acc: 0.5286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6776 - acc: 0.6667 - val_loss: 0.7089 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6805 - acc: 0.6389 - val_loss: 0.7071 - val_acc: 0.5286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6769 - acc: 0.6556 - val_loss: 0.7076 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6770 - acc: 0.6056 - val_loss: 0.7083 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6778 - acc: 0.6389 - val_loss: 0.7076 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6648 - acc: 0.6389 - val_loss: 0.7037 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6727 - acc: 0.6333 - val_loss: 0.7059 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6676 - acc: 0.6389 - val_loss: 0.7055 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6662 - acc: 0.6111 - val_loss: 0.7022 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6652 - acc: 0.6611 - val_loss: 0.7044 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6567 - acc: 0.6500 - val_loss: 0.7016 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6517 - acc: 0.6944 - val_loss: 0.7045 - val_acc: 0.5286\n",
      "Epoch 44/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6587 - acc: 0.6500 - val_loss: 0.7001 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6567 - acc: 0.6500 - val_loss: 0.6962 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6521 - acc: 0.7111 - val_loss: 0.6969 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6454 - acc: 0.6722 - val_loss: 0.6934 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6371 - acc: 0.6944 - val_loss: 0.6904 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6500 - acc: 0.6833 - val_loss: 0.6916 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6521 - acc: 0.6833 - val_loss: 0.6911 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6383 - acc: 0.7111 - val_loss: 0.6971 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6450 - acc: 0.6889 - val_loss: 0.6914 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6400 - acc: 0.6667 - val_loss: 0.6905 - val_acc: 0.5857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6306 - acc: 0.7056 - val_loss: 0.6855 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6256 - acc: 0.7167 - val_loss: 0.6863 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6329 - acc: 0.7111 - val_loss: 0.6827 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6373 - acc: 0.6889 - val_loss: 0.6869 - val_acc: 0.5857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6060 - acc: 0.7556 - val_loss: 0.6809 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6244 - acc: 0.7278 - val_loss: 0.6838 - val_acc: 0.5714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6216 - acc: 0.7000 - val_loss: 0.6805 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6135 - acc: 0.7500 - val_loss: 0.6764 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6115 - acc: 0.7667 - val_loss: 0.6796 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6065 - acc: 0.7389 - val_loss: 0.6741 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6064 - acc: 0.7333 - val_loss: 0.6819 - val_acc: 0.5857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6184 - acc: 0.7111 - val_loss: 0.6773 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5968 - acc: 0.7278 - val_loss: 0.6771 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6073 - acc: 0.7611 - val_loss: 0.6736 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6122 - acc: 0.7444 - val_loss: 0.6786 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5950 - acc: 0.7389 - val_loss: 0.6737 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5876 - acc: 0.7611 - val_loss: 0.6729 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5883 - acc: 0.7611 - val_loss: 0.6693 - val_acc: 0.6857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5860 - acc: 0.7778 - val_loss: 0.6741 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5854 - acc: 0.7444 - val_loss: 0.6761 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5794 - acc: 0.7556 - val_loss: 0.6771 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5943 - acc: 0.7222 - val_loss: 0.6727 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5644 - acc: 0.7722 - val_loss: 0.6685 - val_acc: 0.7143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5876 - acc: 0.7611 - val_loss: 0.6707 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5750 - acc: 0.7611 - val_loss: 0.6665 - val_acc: 0.7000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5624 - acc: 0.7778 - val_loss: 0.6685 - val_acc: 0.6857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5674 - acc: 0.7833 - val_loss: 0.6681 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.9316 - acc: 0.4444 - val_loss: 0.8470 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.8620 - acc: 0.4556 - val_loss: 0.8232 - val_acc: 0.4429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.8325 - acc: 0.4333 - val_loss: 0.8092 - val_acc: 0.4429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.8186 - acc: 0.4056 - val_loss: 0.7987 - val_acc: 0.4000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7963 - acc: 0.4167 - val_loss: 0.7929 - val_acc: 0.4000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7918 - acc: 0.4111 - val_loss: 0.7894 - val_acc: 0.4000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7811 - acc: 0.3944 - val_loss: 0.7853 - val_acc: 0.4286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7808 - acc: 0.4278 - val_loss: 0.7844 - val_acc: 0.3714\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7575 - acc: 0.5000 - val_loss: 0.7813 - val_acc: 0.3714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7562 - acc: 0.4722 - val_loss: 0.7803 - val_acc: 0.3286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7454 - acc: 0.4667 - val_loss: 0.7778 - val_acc: 0.3286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7504 - acc: 0.4944 - val_loss: 0.7757 - val_acc: 0.3429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7350 - acc: 0.5333 - val_loss: 0.7734 - val_acc: 0.3857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7337 - acc: 0.5000 - val_loss: 0.7732 - val_acc: 0.4429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7273 - acc: 0.5167 - val_loss: 0.7701 - val_acc: 0.4143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7305 - acc: 0.5111 - val_loss: 0.7696 - val_acc: 0.4857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.7279 - acc: 0.5278 - val_loss: 0.7697 - val_acc: 0.4857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7257 - acc: 0.5500 - val_loss: 0.7670 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7253 - acc: 0.5278 - val_loss: 0.7651 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7268 - acc: 0.5111 - val_loss: 0.7637 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7211 - acc: 0.5222 - val_loss: 0.7640 - val_acc: 0.4857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7143 - acc: 0.5500 - val_loss: 0.7648 - val_acc: 0.4857\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7138 - acc: 0.5611 - val_loss: 0.7643 - val_acc: 0.4714\n",
      "Epoch 24/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.7135 - acc: 0.5167 - val_loss: 0.7648 - val_acc: 0.4857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6958 - acc: 0.5944 - val_loss: 0.7635 - val_acc: 0.4714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 149us/step - loss: 0.7006 - acc: 0.6000 - val_loss: 0.7634 - val_acc: 0.4571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 128us/step - loss: 0.7015 - acc: 0.6167 - val_loss: 0.7641 - val_acc: 0.4714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6973 - acc: 0.6056 - val_loss: 0.7616 - val_acc: 0.4857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6926 - acc: 0.6389 - val_loss: 0.7619 - val_acc: 0.4714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6844 - acc: 0.6500 - val_loss: 0.7632 - val_acc: 0.4714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 120us/step - loss: 0.6823 - acc: 0.6556 - val_loss: 0.7623 - val_acc: 0.4714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6841 - acc: 0.6222 - val_loss: 0.7604 - val_acc: 0.4714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6864 - acc: 0.6500 - val_loss: 0.7632 - val_acc: 0.4714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6758 - acc: 0.6333 - val_loss: 0.7628 - val_acc: 0.4571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 131us/step - loss: 0.6724 - acc: 0.6667 - val_loss: 0.7609 - val_acc: 0.4857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6672 - acc: 0.6944 - val_loss: 0.7614 - val_acc: 0.4857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6611 - acc: 0.6778 - val_loss: 0.7606 - val_acc: 0.4857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6700 - acc: 0.6389 - val_loss: 0.7587 - val_acc: 0.4714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6634 - acc: 0.7056 - val_loss: 0.7586 - val_acc: 0.4857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6570 - acc: 0.7167 - val_loss: 0.7571 - val_acc: 0.4857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6572 - acc: 0.7167 - val_loss: 0.7572 - val_acc: 0.4714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6449 - acc: 0.7000 - val_loss: 0.7546 - val_acc: 0.5000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6533 - acc: 0.7000 - val_loss: 0.7543 - val_acc: 0.5000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6391 - acc: 0.7278 - val_loss: 0.7555 - val_acc: 0.5000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6441 - acc: 0.6889 - val_loss: 0.7526 - val_acc: 0.5000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6426 - acc: 0.7167 - val_loss: 0.7518 - val_acc: 0.5429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6392 - acc: 0.6944 - val_loss: 0.7511 - val_acc: 0.5286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6340 - acc: 0.7056 - val_loss: 0.7546 - val_acc: 0.5000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6306 - acc: 0.6944 - val_loss: 0.7527 - val_acc: 0.5286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6281 - acc: 0.6833 - val_loss: 0.7508 - val_acc: 0.5286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6262 - acc: 0.7333 - val_loss: 0.7494 - val_acc: 0.5143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6295 - acc: 0.7278 - val_loss: 0.7511 - val_acc: 0.5571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6178 - acc: 0.7278 - val_loss: 0.7498 - val_acc: 0.5286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 125us/step - loss: 0.6249 - acc: 0.7389 - val_loss: 0.7481 - val_acc: 0.5714\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6211 - acc: 0.7333 - val_loss: 0.7469 - val_acc: 0.5429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6068 - acc: 0.7444 - val_loss: 0.7495 - val_acc: 0.5571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6189 - acc: 0.7333 - val_loss: 0.7487 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5948 - acc: 0.7556 - val_loss: 0.7534 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.5851 - acc: 0.7611 - val_loss: 0.7459 - val_acc: 0.5571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5929 - acc: 0.7333 - val_loss: 0.7478 - val_acc: 0.5571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5892 - acc: 0.7556 - val_loss: 0.7485 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5881 - acc: 0.7444 - val_loss: 0.7518 - val_acc: 0.5429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5766 - acc: 0.7667 - val_loss: 0.7473 - val_acc: 0.5429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.5866 - acc: 0.7556 - val_loss: 0.7473 - val_acc: 0.5286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5974 - acc: 0.7556 - val_loss: 0.7512 - val_acc: 0.5429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5811 - acc: 0.7722 - val_loss: 0.7476 - val_acc: 0.5429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5741 - acc: 0.8056 - val_loss: 0.7503 - val_acc: 0.5571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5577 - acc: 0.8111 - val_loss: 0.7506 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5669 - acc: 0.7889 - val_loss: 0.7486 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5715 - acc: 0.7611 - val_loss: 0.7572 - val_acc: 0.5714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5485 - acc: 0.7889 - val_loss: 0.7537 - val_acc: 0.5714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5616 - acc: 0.7833 - val_loss: 0.7583 - val_acc: 0.5571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5564 - acc: 0.7778 - val_loss: 0.7510 - val_acc: 0.5714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5498 - acc: 0.8222 - val_loss: 0.7523 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5503 - acc: 0.7833 - val_loss: 0.7560 - val_acc: 0.5714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5544 - acc: 0.7778 - val_loss: 0.7523 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5485 - acc: 0.8167 - val_loss: 0.7528 - val_acc: 0.5714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5593 - acc: 0.7722 - val_loss: 0.7555 - val_acc: 0.5714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5527 - acc: 0.7778 - val_loss: 0.7530 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5377 - acc: 0.8056 - val_loss: 0.7600 - val_acc: 0.5714\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.7843 - acc: 0.4500 - val_loss: 0.7624 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7678 - acc: 0.4500 - val_loss: 0.7605 - val_acc: 0.4714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7537 - acc: 0.4556 - val_loss: 0.7568 - val_acc: 0.4000\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 127us/step - loss: 0.7566 - acc: 0.5111 - val_loss: 0.7558 - val_acc: 0.4000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7485 - acc: 0.4833 - val_loss: 0.7550 - val_acc: 0.3571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7408 - acc: 0.5000 - val_loss: 0.7525 - val_acc: 0.4143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7398 - acc: 0.5111 - val_loss: 0.7509 - val_acc: 0.4000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7407 - acc: 0.4778 - val_loss: 0.7500 - val_acc: 0.4143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7368 - acc: 0.5000 - val_loss: 0.7488 - val_acc: 0.4714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7318 - acc: 0.5222 - val_loss: 0.7489 - val_acc: 0.4286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7316 - acc: 0.5222 - val_loss: 0.7479 - val_acc: 0.4571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7294 - acc: 0.5444 - val_loss: 0.7487 - val_acc: 0.4571\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7284 - acc: 0.5222 - val_loss: 0.7500 - val_acc: 0.4571\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7212 - acc: 0.5556 - val_loss: 0.7505 - val_acc: 0.4571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7272 - acc: 0.5667 - val_loss: 0.7506 - val_acc: 0.4429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7174 - acc: 0.6111 - val_loss: 0.7507 - val_acc: 0.4571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7104 - acc: 0.5889 - val_loss: 0.7511 - val_acc: 0.4571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7102 - acc: 0.6056 - val_loss: 0.7499 - val_acc: 0.4571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7203 - acc: 0.5667 - val_loss: 0.7498 - val_acc: 0.4571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7123 - acc: 0.5778 - val_loss: 0.7510 - val_acc: 0.4571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7008 - acc: 0.5944 - val_loss: 0.7504 - val_acc: 0.4571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7028 - acc: 0.5833 - val_loss: 0.7502 - val_acc: 0.4714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7003 - acc: 0.6556 - val_loss: 0.7491 - val_acc: 0.4571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6937 - acc: 0.6333 - val_loss: 0.7489 - val_acc: 0.4714\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7053 - acc: 0.6167 - val_loss: 0.7477 - val_acc: 0.4714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6976 - acc: 0.6278 - val_loss: 0.7472 - val_acc: 0.4714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7005 - acc: 0.6056 - val_loss: 0.7490 - val_acc: 0.4571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6919 - acc: 0.6111 - val_loss: 0.7498 - val_acc: 0.4714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6923 - acc: 0.5833 - val_loss: 0.7494 - val_acc: 0.4714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6876 - acc: 0.5944 - val_loss: 0.7503 - val_acc: 0.4714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6903 - acc: 0.6000 - val_loss: 0.7482 - val_acc: 0.4429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.6846 - acc: 0.648 - 0s 139us/step - loss: 0.6920 - acc: 0.6222 - val_loss: 0.7462 - val_acc: 0.4571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6846 - acc: 0.6333 - val_loss: 0.7465 - val_acc: 0.4714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6816 - acc: 0.6389 - val_loss: 0.7455 - val_acc: 0.4857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.6836 - acc: 0.6500 - val_loss: 0.7440 - val_acc: 0.4571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6808 - acc: 0.6278 - val_loss: 0.7446 - val_acc: 0.4857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6812 - acc: 0.6222 - val_loss: 0.7437 - val_acc: 0.4857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6765 - acc: 0.6389 - val_loss: 0.7431 - val_acc: 0.4857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 119us/step - loss: 0.6719 - acc: 0.6389 - val_loss: 0.7423 - val_acc: 0.4714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6674 - acc: 0.6722 - val_loss: 0.7451 - val_acc: 0.4714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6675 - acc: 0.6444 - val_loss: 0.7434 - val_acc: 0.4857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6700 - acc: 0.6111 - val_loss: 0.7411 - val_acc: 0.4714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6614 - acc: 0.6500 - val_loss: 0.7428 - val_acc: 0.4714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6689 - acc: 0.6611 - val_loss: 0.7437 - val_acc: 0.4714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6641 - acc: 0.6556 - val_loss: 0.7398 - val_acc: 0.4714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6555 - acc: 0.6778 - val_loss: 0.7402 - val_acc: 0.5000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6537 - acc: 0.6556 - val_loss: 0.7410 - val_acc: 0.4857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.6612 - acc: 0.6556 - val_loss: 0.7399 - val_acc: 0.5000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6484 - acc: 0.6944 - val_loss: 0.7391 - val_acc: 0.5000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6574 - acc: 0.6778 - val_loss: 0.7367 - val_acc: 0.5000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6419 - acc: 0.6833 - val_loss: 0.7361 - val_acc: 0.5000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6402 - acc: 0.6944 - val_loss: 0.7361 - val_acc: 0.5000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6498 - acc: 0.6056 - val_loss: 0.7361 - val_acc: 0.5000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6459 - acc: 0.6500 - val_loss: 0.7349 - val_acc: 0.5000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6415 - acc: 0.6444 - val_loss: 0.7329 - val_acc: 0.5143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6356 - acc: 0.6889 - val_loss: 0.7296 - val_acc: 0.5143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6185 - acc: 0.7278 - val_loss: 0.7306 - val_acc: 0.5143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6320 - acc: 0.6833 - val_loss: 0.7305 - val_acc: 0.5143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6238 - acc: 0.7500 - val_loss: 0.7275 - val_acc: 0.5143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6233 - acc: 0.7444 - val_loss: 0.7279 - val_acc: 0.5000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6235 - acc: 0.7444 - val_loss: 0.7269 - val_acc: 0.5143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6117 - acc: 0.7111 - val_loss: 0.7281 - val_acc: 0.5143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6103 - acc: 0.7000 - val_loss: 0.7246 - val_acc: 0.5000\n",
      "Epoch 64/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 133us/step - loss: 0.6133 - acc: 0.6944 - val_loss: 0.7231 - val_acc: 0.4857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6087 - acc: 0.7556 - val_loss: 0.7201 - val_acc: 0.5286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.6163 - acc: 0.7278 - val_loss: 0.7196 - val_acc: 0.5429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6173 - acc: 0.7389 - val_loss: 0.7241 - val_acc: 0.5143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5925 - acc: 0.7444 - val_loss: 0.7214 - val_acc: 0.5286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5923 - acc: 0.7500 - val_loss: 0.7172 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6001 - acc: 0.7556 - val_loss: 0.7166 - val_acc: 0.5429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.5982 - acc: 0.7556 - val_loss: 0.7166 - val_acc: 0.5571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5948 - acc: 0.7500 - val_loss: 0.7213 - val_acc: 0.5143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5846 - acc: 0.7778 - val_loss: 0.7270 - val_acc: 0.5000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5934 - acc: 0.7333 - val_loss: 0.7219 - val_acc: 0.5429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5791 - acc: 0.7833 - val_loss: 0.7185 - val_acc: 0.5571\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6072 - acc: 0.7167 - val_loss: 0.7203 - val_acc: 0.5714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5742 - acc: 0.7611 - val_loss: 0.7244 - val_acc: 0.5429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5935 - acc: 0.7333 - val_loss: 0.7190 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5809 - acc: 0.7556 - val_loss: 0.7194 - val_acc: 0.5857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5779 - acc: 0.7611 - val_loss: 0.7192 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.7416 - acc: 0.4833 - val_loss: 0.7427 - val_acc: 0.5714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7282 - acc: 0.5111 - val_loss: 0.7454 - val_acc: 0.5714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7249 - acc: 0.5722 - val_loss: 0.7441 - val_acc: 0.5857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7283 - acc: 0.5389 - val_loss: 0.7426 - val_acc: 0.6143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7143 - acc: 0.5278 - val_loss: 0.7426 - val_acc: 0.6000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7196 - acc: 0.5167 - val_loss: 0.7434 - val_acc: 0.5857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7216 - acc: 0.5167 - val_loss: 0.7424 - val_acc: 0.6143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7069 - acc: 0.5778 - val_loss: 0.7438 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7030 - acc: 0.5500 - val_loss: 0.7433 - val_acc: 0.5429\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7062 - acc: 0.5944 - val_loss: 0.7420 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.7023 - acc: 0.5667 - val_loss: 0.7400 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6922 - acc: 0.6056 - val_loss: 0.7395 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6877 - acc: 0.6000 - val_loss: 0.7402 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6783 - acc: 0.6278 - val_loss: 0.7400 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6866 - acc: 0.6333 - val_loss: 0.7384 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 115us/step - loss: 0.6899 - acc: 0.6167 - val_loss: 0.7365 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6847 - acc: 0.6500 - val_loss: 0.7392 - val_acc: 0.4857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6853 - acc: 0.6111 - val_loss: 0.7384 - val_acc: 0.4857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6857 - acc: 0.6000 - val_loss: 0.7383 - val_acc: 0.4857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6799 - acc: 0.6111 - val_loss: 0.7408 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6666 - acc: 0.6556 - val_loss: 0.7383 - val_acc: 0.4857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6641 - acc: 0.6500 - val_loss: 0.7368 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6712 - acc: 0.6611 - val_loss: 0.7391 - val_acc: 0.4714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6712 - acc: 0.6222 - val_loss: 0.7388 - val_acc: 0.4857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6642 - acc: 0.6000 - val_loss: 0.7364 - val_acc: 0.5000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6694 - acc: 0.6222 - val_loss: 0.7378 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6602 - acc: 0.6444 - val_loss: 0.7367 - val_acc: 0.5000\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6547 - acc: 0.6556 - val_loss: 0.7340 - val_acc: 0.5000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.6541 - acc: 0.6944 - val_loss: 0.7328 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6530 - acc: 0.6944 - val_loss: 0.7321 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6506 - acc: 0.6611 - val_loss: 0.7311 - val_acc: 0.5143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6438 - acc: 0.6889 - val_loss: 0.7327 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6643 - acc: 0.6389 - val_loss: 0.7374 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 112us/step - loss: 0.6446 - acc: 0.6889 - val_loss: 0.7361 - val_acc: 0.5000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6473 - acc: 0.6722 - val_loss: 0.7331 - val_acc: 0.5143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6419 - acc: 0.6833 - val_loss: 0.7323 - val_acc: 0.5143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6380 - acc: 0.6611 - val_loss: 0.7331 - val_acc: 0.5143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6426 - acc: 0.7056 - val_loss: 0.7329 - val_acc: 0.5143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6184 - acc: 0.7167 - val_loss: 0.7294 - val_acc: 0.5143\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6316 - acc: 0.7111 - val_loss: 0.7301 - val_acc: 0.5143\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6261 - acc: 0.7056 - val_loss: 0.7328 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6240 - acc: 0.7167 - val_loss: 0.7313 - val_acc: 0.5286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5964 - acc: 0.8000 - val_loss: 0.7289 - val_acc: 0.5429\n",
      "Epoch 44/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.6207 - acc: 0.7444 - val_loss: 0.7277 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6113 - acc: 0.7333 - val_loss: 0.7294 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6057 - acc: 0.7778 - val_loss: 0.7337 - val_acc: 0.5143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6150 - acc: 0.7000 - val_loss: 0.7325 - val_acc: 0.5286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6119 - acc: 0.6944 - val_loss: 0.7309 - val_acc: 0.5429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6042 - acc: 0.7333 - val_loss: 0.7271 - val_acc: 0.5429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5924 - acc: 0.7889 - val_loss: 0.7276 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6201 - acc: 0.7278 - val_loss: 0.7263 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6061 - acc: 0.7222 - val_loss: 0.7263 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5893 - acc: 0.7889 - val_loss: 0.7267 - val_acc: 0.5714\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5870 - acc: 0.7444 - val_loss: 0.7278 - val_acc: 0.5714\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6041 - acc: 0.7333 - val_loss: 0.7319 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5869 - acc: 0.7722 - val_loss: 0.7350 - val_acc: 0.5429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5866 - acc: 0.7722 - val_loss: 0.7308 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5863 - acc: 0.7500 - val_loss: 0.7347 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5908 - acc: 0.7222 - val_loss: 0.7313 - val_acc: 0.6000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5762 - acc: 0.7778 - val_loss: 0.7342 - val_acc: 0.5714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5702 - acc: 0.7500 - val_loss: 0.7327 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5767 - acc: 0.7833 - val_loss: 0.7334 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5688 - acc: 0.7778 - val_loss: 0.7307 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5602 - acc: 0.7722 - val_loss: 0.7325 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5599 - acc: 0.8000 - val_loss: 0.7347 - val_acc: 0.5857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5582 - acc: 0.8000 - val_loss: 0.7334 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5582 - acc: 0.7778 - val_loss: 0.7386 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5528 - acc: 0.7889 - val_loss: 0.7306 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5455 - acc: 0.7833 - val_loss: 0.7370 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5261 - acc: 0.7944 - val_loss: 0.7396 - val_acc: 0.5857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5348 - acc: 0.8111 - val_loss: 0.7402 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5545 - acc: 0.7833 - val_loss: 0.7406 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5437 - acc: 0.8056 - val_loss: 0.7457 - val_acc: 0.5571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5377 - acc: 0.7944 - val_loss: 0.7438 - val_acc: 0.6000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5394 - acc: 0.7722 - val_loss: 0.7408 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5431 - acc: 0.7778 - val_loss: 0.7389 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5418 - acc: 0.7667 - val_loss: 0.7442 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5300 - acc: 0.8000 - val_loss: 0.7417 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5166 - acc: 0.8000 - val_loss: 0.7452 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5253 - acc: 0.8000 - val_loss: 0.7463 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.7430 - acc: 0.5389 - val_loss: 0.7334 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7346 - acc: 0.5833 - val_loss: 0.7344 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7236 - acc: 0.5889 - val_loss: 0.7341 - val_acc: 0.5286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7213 - acc: 0.5611 - val_loss: 0.7353 - val_acc: 0.5286\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7227 - acc: 0.5611 - val_loss: 0.7310 - val_acc: 0.5286\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7168 - acc: 0.5722 - val_loss: 0.7274 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7125 - acc: 0.5833 - val_loss: 0.7260 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7234 - acc: 0.5667 - val_loss: 0.7242 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7151 - acc: 0.5778 - val_loss: 0.7246 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7168 - acc: 0.5667 - val_loss: 0.7236 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7118 - acc: 0.5722 - val_loss: 0.7209 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 112us/step - loss: 0.7019 - acc: 0.5944 - val_loss: 0.7207 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7054 - acc: 0.6056 - val_loss: 0.7217 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6976 - acc: 0.5889 - val_loss: 0.7181 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6963 - acc: 0.5889 - val_loss: 0.7158 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6987 - acc: 0.6000 - val_loss: 0.7142 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6994 - acc: 0.5833 - val_loss: 0.7119 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6941 - acc: 0.6167 - val_loss: 0.7103 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6893 - acc: 0.6000 - val_loss: 0.7080 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6818 - acc: 0.6444 - val_loss: 0.7084 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6849 - acc: 0.6389 - val_loss: 0.7060 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6821 - acc: 0.6444 - val_loss: 0.7079 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6810 - acc: 0.6222 - val_loss: 0.7047 - val_acc: 0.5571\n",
      "Epoch 24/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6727 - acc: 0.6722 - val_loss: 0.7004 - val_acc: 0.6000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6830 - acc: 0.6333 - val_loss: 0.7010 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6746 - acc: 0.6389 - val_loss: 0.6991 - val_acc: 0.5714\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6718 - acc: 0.6667 - val_loss: 0.7000 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6720 - acc: 0.6333 - val_loss: 0.6986 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6727 - acc: 0.6333 - val_loss: 0.6959 - val_acc: 0.5714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6692 - acc: 0.6611 - val_loss: 0.7000 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 98us/step - loss: 0.6626 - acc: 0.6556 - val_loss: 0.6975 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6600 - acc: 0.6556 - val_loss: 0.6940 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6620 - acc: 0.6389 - val_loss: 0.6892 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6540 - acc: 0.6778 - val_loss: 0.6929 - val_acc: 0.6000\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6544 - acc: 0.6556 - val_loss: 0.6901 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 99us/step - loss: 0.6613 - acc: 0.6611 - val_loss: 0.6929 - val_acc: 0.5857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6617 - acc: 0.6722 - val_loss: 0.6886 - val_acc: 0.6000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 138us/step - loss: 0.6502 - acc: 0.7000 - val_loss: 0.6888 - val_acc: 0.6000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6506 - acc: 0.6667 - val_loss: 0.6866 - val_acc: 0.5857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6431 - acc: 0.7056 - val_loss: 0.6910 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6452 - acc: 0.6944 - val_loss: 0.6844 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6392 - acc: 0.7000 - val_loss: 0.6793 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6380 - acc: 0.7278 - val_loss: 0.6821 - val_acc: 0.6286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6463 - acc: 0.7000 - val_loss: 0.6803 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6360 - acc: 0.6833 - val_loss: 0.6804 - val_acc: 0.6286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6384 - acc: 0.6667 - val_loss: 0.6750 - val_acc: 0.6429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6289 - acc: 0.7167 - val_loss: 0.6713 - val_acc: 0.6857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6258 - acc: 0.7278 - val_loss: 0.6697 - val_acc: 0.6714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6280 - acc: 0.7167 - val_loss: 0.6694 - val_acc: 0.6857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6299 - acc: 0.7444 - val_loss: 0.6664 - val_acc: 0.6857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6159 - acc: 0.7778 - val_loss: 0.6684 - val_acc: 0.6857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6124 - acc: 0.7667 - val_loss: 0.6672 - val_acc: 0.6857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6318 - acc: 0.7222 - val_loss: 0.6633 - val_acc: 0.7000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6110 - acc: 0.7722 - val_loss: 0.6626 - val_acc: 0.7000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6035 - acc: 0.8000 - val_loss: 0.6643 - val_acc: 0.6857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6130 - acc: 0.7556 - val_loss: 0.6641 - val_acc: 0.6714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5958 - acc: 0.7667 - val_loss: 0.6613 - val_acc: 0.6857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6063 - acc: 0.7333 - val_loss: 0.6645 - val_acc: 0.6857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5985 - acc: 0.7889 - val_loss: 0.6597 - val_acc: 0.6714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5903 - acc: 0.7833 - val_loss: 0.6619 - val_acc: 0.6857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6051 - acc: 0.7500 - val_loss: 0.6562 - val_acc: 0.6714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 172us/step - loss: 0.5687 - acc: 0.8167 - val_loss: 0.6570 - val_acc: 0.6714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5995 - acc: 0.7778 - val_loss: 0.6576 - val_acc: 0.6857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 172us/step - loss: 0.5695 - acc: 0.7667 - val_loss: 0.6561 - val_acc: 0.6714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.5870 - acc: 0.7667 - val_loss: 0.6586 - val_acc: 0.6857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.5774 - acc: 0.8056 - val_loss: 0.6568 - val_acc: 0.6857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.5849 - acc: 0.7944 - val_loss: 0.6603 - val_acc: 0.6857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.5651 - acc: 0.8056 - val_loss: 0.6571 - val_acc: 0.6714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5735 - acc: 0.7611 - val_loss: 0.6640 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5678 - acc: 0.8000 - val_loss: 0.6600 - val_acc: 0.6857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5616 - acc: 0.7944 - val_loss: 0.6595 - val_acc: 0.6857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5759 - acc: 0.7444 - val_loss: 0.6523 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5555 - acc: 0.7778 - val_loss: 0.6598 - val_acc: 0.6714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5603 - acc: 0.7778 - val_loss: 0.6501 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5647 - acc: 0.8000 - val_loss: 0.6623 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.5675 - acc: 0.7722 - val_loss: 0.6644 - val_acc: 0.6714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5563 - acc: 0.7611 - val_loss: 0.6616 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5653 - acc: 0.7944 - val_loss: 0.6525 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5443 - acc: 0.8000 - val_loss: 0.6542 - val_acc: 0.6429\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5543 - acc: 0.7889 - val_loss: 0.6526 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.7801 - acc: 0.4944 - val_loss: 0.7526 - val_acc: 0.4000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7427 - acc: 0.5389 - val_loss: 0.7491 - val_acc: 0.5429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7343 - acc: 0.5611 - val_loss: 0.7469 - val_acc: 0.5429\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.7272 - acc: 0.5389 - val_loss: 0.7471 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7270 - acc: 0.5556 - val_loss: 0.7451 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7243 - acc: 0.5556 - val_loss: 0.7444 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7313 - acc: 0.5056 - val_loss: 0.7439 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7127 - acc: 0.5556 - val_loss: 0.7427 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7118 - acc: 0.5778 - val_loss: 0.7425 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7273 - acc: 0.5500 - val_loss: 0.7414 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7061 - acc: 0.5611 - val_loss: 0.7400 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7027 - acc: 0.5889 - val_loss: 0.7423 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6946 - acc: 0.5556 - val_loss: 0.7376 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6947 - acc: 0.5778 - val_loss: 0.7396 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6902 - acc: 0.6111 - val_loss: 0.7351 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6865 - acc: 0.6278 - val_loss: 0.7331 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6833 - acc: 0.6278 - val_loss: 0.7328 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6871 - acc: 0.6389 - val_loss: 0.7322 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6749 - acc: 0.6389 - val_loss: 0.7286 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6758 - acc: 0.6556 - val_loss: 0.7293 - val_acc: 0.5857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6723 - acc: 0.6500 - val_loss: 0.7291 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6583 - acc: 0.6778 - val_loss: 0.7276 - val_acc: 0.5857\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6666 - acc: 0.6389 - val_loss: 0.7270 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6800 - acc: 0.6000 - val_loss: 0.7205 - val_acc: 0.6286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6723 - acc: 0.6500 - val_loss: 0.7209 - val_acc: 0.6286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6516 - acc: 0.7111 - val_loss: 0.7259 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6544 - acc: 0.7167 - val_loss: 0.7298 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6549 - acc: 0.6889 - val_loss: 0.7308 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 194us/step - loss: 0.6497 - acc: 0.6778 - val_loss: 0.7237 - val_acc: 0.6429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6347 - acc: 0.7444 - val_loss: 0.7247 - val_acc: 0.6429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6486 - acc: 0.6722 - val_loss: 0.7267 - val_acc: 0.6286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6260 - acc: 0.7111 - val_loss: 0.7232 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6292 - acc: 0.7333 - val_loss: 0.7200 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6258 - acc: 0.7167 - val_loss: 0.7273 - val_acc: 0.6143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6258 - acc: 0.7167 - val_loss: 0.7310 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6320 - acc: 0.6778 - val_loss: 0.7181 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6228 - acc: 0.7444 - val_loss: 0.7228 - val_acc: 0.6000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6128 - acc: 0.7333 - val_loss: 0.7226 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6124 - acc: 0.7167 - val_loss: 0.7208 - val_acc: 0.6143\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6031 - acc: 0.7611 - val_loss: 0.7177 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6101 - acc: 0.7556 - val_loss: 0.7181 - val_acc: 0.6143\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6126 - acc: 0.7278 - val_loss: 0.7185 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 125us/step - loss: 0.5860 - acc: 0.7611 - val_loss: 0.7207 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5978 - acc: 0.7889 - val_loss: 0.7191 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5909 - acc: 0.7611 - val_loss: 0.7185 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5960 - acc: 0.7333 - val_loss: 0.7150 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5899 - acc: 0.7333 - val_loss: 0.7121 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5731 - acc: 0.7722 - val_loss: 0.7187 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5890 - acc: 0.7556 - val_loss: 0.7303 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5934 - acc: 0.7500 - val_loss: 0.7348 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5718 - acc: 0.7889 - val_loss: 0.7186 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5698 - acc: 0.7778 - val_loss: 0.7183 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5684 - acc: 0.8000 - val_loss: 0.7150 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5758 - acc: 0.7667 - val_loss: 0.7148 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5585 - acc: 0.7778 - val_loss: 0.7139 - val_acc: 0.5857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5777 - acc: 0.7667 - val_loss: 0.7133 - val_acc: 0.5857\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5720 - acc: 0.7500 - val_loss: 0.7284 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5584 - acc: 0.7444 - val_loss: 0.7202 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5501 - acc: 0.7944 - val_loss: 0.7191 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5508 - acc: 0.7278 - val_loss: 0.7167 - val_acc: 0.5714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5436 - acc: 0.7667 - val_loss: 0.7296 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5508 - acc: 0.7833 - val_loss: 0.7194 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5371 - acc: 0.8000 - val_loss: 0.7254 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5345 - acc: 0.7722 - val_loss: 0.7313 - val_acc: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5517 - acc: 0.7667 - val_loss: 0.7354 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5235 - acc: 0.8167 - val_loss: 0.7243 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5511 - acc: 0.7944 - val_loss: 0.7399 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5276 - acc: 0.7833 - val_loss: 0.7303 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5290 - acc: 0.7944 - val_loss: 0.7260 - val_acc: 0.5857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5281 - acc: 0.7833 - val_loss: 0.7367 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5313 - acc: 0.8056 - val_loss: 0.7375 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5450 - acc: 0.7611 - val_loss: 0.7365 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5289 - acc: 0.8111 - val_loss: 0.7396 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5171 - acc: 0.8111 - val_loss: 0.7351 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5184 - acc: 0.8000 - val_loss: 0.7411 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5074 - acc: 0.8111 - val_loss: 0.7427 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5135 - acc: 0.8000 - val_loss: 0.7364 - val_acc: 0.5857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.4962 - acc: 0.8333 - val_loss: 0.7426 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.4934 - acc: 0.8278 - val_loss: 0.7512 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5045 - acc: 0.8056 - val_loss: 0.7450 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 175us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.8084 - acc: 0.4611 - val_loss: 0.7576 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7709 - acc: 0.4667 - val_loss: 0.7535 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7680 - acc: 0.4444 - val_loss: 0.7487 - val_acc: 0.4857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7687 - acc: 0.4500 - val_loss: 0.7452 - val_acc: 0.5714\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7562 - acc: 0.4500 - val_loss: 0.7441 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7540 - acc: 0.4722 - val_loss: 0.7429 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7508 - acc: 0.4611 - val_loss: 0.7425 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7490 - acc: 0.4889 - val_loss: 0.7424 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7505 - acc: 0.4500 - val_loss: 0.7420 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7458 - acc: 0.4944 - val_loss: 0.7414 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7471 - acc: 0.4444 - val_loss: 0.7408 - val_acc: 0.5714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7433 - acc: 0.5056 - val_loss: 0.7403 - val_acc: 0.5857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7437 - acc: 0.5278 - val_loss: 0.7402 - val_acc: 0.5571\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7477 - acc: 0.4611 - val_loss: 0.7397 - val_acc: 0.5571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7403 - acc: 0.5000 - val_loss: 0.7389 - val_acc: 0.5571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7404 - acc: 0.4833 - val_loss: 0.7393 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7373 - acc: 0.5333 - val_loss: 0.7384 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7373 - acc: 0.5611 - val_loss: 0.7382 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.7386 - acc: 0.5000 - val_loss: 0.7376 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7321 - acc: 0.5556 - val_loss: 0.7373 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7322 - acc: 0.5944 - val_loss: 0.7368 - val_acc: 0.4857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.7313 - acc: 0.5778 - val_loss: 0.7366 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.7301 - acc: 0.6000 - val_loss: 0.7361 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7316 - acc: 0.5556 - val_loss: 0.7348 - val_acc: 0.5143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7316 - acc: 0.6000 - val_loss: 0.7343 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7323 - acc: 0.5944 - val_loss: 0.7337 - val_acc: 0.5000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7293 - acc: 0.5444 - val_loss: 0.7340 - val_acc: 0.4857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7260 - acc: 0.6056 - val_loss: 0.7336 - val_acc: 0.4857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7306 - acc: 0.6222 - val_loss: 0.7332 - val_acc: 0.5000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7277 - acc: 0.5889 - val_loss: 0.7325 - val_acc: 0.5000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7268 - acc: 0.6056 - val_loss: 0.7324 - val_acc: 0.5000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7271 - acc: 0.6222 - val_loss: 0.7322 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7196 - acc: 0.6389 - val_loss: 0.7321 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7254 - acc: 0.5500 - val_loss: 0.7316 - val_acc: 0.4857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7228 - acc: 0.5833 - val_loss: 0.7306 - val_acc: 0.5000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7216 - acc: 0.5833 - val_loss: 0.7303 - val_acc: 0.5000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7209 - acc: 0.6000 - val_loss: 0.7297 - val_acc: 0.5143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7209 - acc: 0.6167 - val_loss: 0.7300 - val_acc: 0.4857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7202 - acc: 0.5778 - val_loss: 0.7300 - val_acc: 0.4857\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7140 - acc: 0.6778 - val_loss: 0.7289 - val_acc: 0.5000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7213 - acc: 0.6222 - val_loss: 0.7286 - val_acc: 0.5000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 115us/step - loss: 0.7157 - acc: 0.6778 - val_loss: 0.7289 - val_acc: 0.5143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7173 - acc: 0.6278 - val_loss: 0.7287 - val_acc: 0.4857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7166 - acc: 0.6111 - val_loss: 0.7280 - val_acc: 0.4571\n",
      "Epoch 45/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.7139 - acc: 0.6278 - val_loss: 0.7277 - val_acc: 0.4571\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7136 - acc: 0.6444 - val_loss: 0.7261 - val_acc: 0.4857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7071 - acc: 0.7111 - val_loss: 0.7264 - val_acc: 0.5000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7069 - acc: 0.6667 - val_loss: 0.7265 - val_acc: 0.4714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7082 - acc: 0.6722 - val_loss: 0.7259 - val_acc: 0.4857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7092 - acc: 0.6222 - val_loss: 0.7258 - val_acc: 0.5143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7092 - acc: 0.5944 - val_loss: 0.7259 - val_acc: 0.4857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7032 - acc: 0.6500 - val_loss: 0.7269 - val_acc: 0.5143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7002 - acc: 0.6222 - val_loss: 0.7267 - val_acc: 0.5000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6954 - acc: 0.6333 - val_loss: 0.7274 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6979 - acc: 0.6167 - val_loss: 0.7274 - val_acc: 0.5429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6903 - acc: 0.6222 - val_loss: 0.7279 - val_acc: 0.5286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6951 - acc: 0.6222 - val_loss: 0.7290 - val_acc: 0.5286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6904 - acc: 0.6278 - val_loss: 0.7270 - val_acc: 0.5286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6885 - acc: 0.6556 - val_loss: 0.7260 - val_acc: 0.5286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6884 - acc: 0.6556 - val_loss: 0.7263 - val_acc: 0.5286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6869 - acc: 0.6000 - val_loss: 0.7259 - val_acc: 0.5429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6805 - acc: 0.6111 - val_loss: 0.7279 - val_acc: 0.5286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6798 - acc: 0.6167 - val_loss: 0.7284 - val_acc: 0.5286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6862 - acc: 0.5833 - val_loss: 0.7293 - val_acc: 0.5286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6705 - acc: 0.6722 - val_loss: 0.7273 - val_acc: 0.5286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6829 - acc: 0.6000 - val_loss: 0.7263 - val_acc: 0.5286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6822 - acc: 0.6167 - val_loss: 0.7246 - val_acc: 0.5286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6692 - acc: 0.6500 - val_loss: 0.7233 - val_acc: 0.5286\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6839 - acc: 0.6111 - val_loss: 0.7232 - val_acc: 0.5429\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6746 - acc: 0.6222 - val_loss: 0.7223 - val_acc: 0.5429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6684 - acc: 0.6389 - val_loss: 0.7237 - val_acc: 0.5429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6601 - acc: 0.6444 - val_loss: 0.7253 - val_acc: 0.5429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6528 - acc: 0.6833 - val_loss: 0.7264 - val_acc: 0.5429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.6612 - acc: 0.6667 - val_loss: 0.7219 - val_acc: 0.5143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6640 - acc: 0.6611 - val_loss: 0.7207 - val_acc: 0.5000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6652 - acc: 0.6722 - val_loss: 0.7207 - val_acc: 0.4857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6573 - acc: 0.6944 - val_loss: 0.7230 - val_acc: 0.5429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6492 - acc: 0.7000 - val_loss: 0.7224 - val_acc: 0.5143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6606 - acc: 0.6722 - val_loss: 0.7223 - val_acc: 0.5286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6492 - acc: 0.7056 - val_loss: 0.7220 - val_acc: 0.5143\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.9166 - acc: 0.4611 - val_loss: 0.8322 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.8569 - acc: 0.4611 - val_loss: 0.8047 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.8160 - acc: 0.4611 - val_loss: 0.7906 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.8015 - acc: 0.4611 - val_loss: 0.7780 - val_acc: 0.4857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7961 - acc: 0.4278 - val_loss: 0.7717 - val_acc: 0.4857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7842 - acc: 0.4500 - val_loss: 0.7644 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7617 - acc: 0.5000 - val_loss: 0.7607 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7485 - acc: 0.5389 - val_loss: 0.7587 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7466 - acc: 0.5222 - val_loss: 0.7569 - val_acc: 0.4143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7439 - acc: 0.4889 - val_loss: 0.7552 - val_acc: 0.4429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7400 - acc: 0.5278 - val_loss: 0.7539 - val_acc: 0.4714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7345 - acc: 0.5333 - val_loss: 0.7530 - val_acc: 0.4714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7365 - acc: 0.4833 - val_loss: 0.7527 - val_acc: 0.4571\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7221 - acc: 0.5722 - val_loss: 0.7528 - val_acc: 0.4857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7211 - acc: 0.5722 - val_loss: 0.7515 - val_acc: 0.4857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7217 - acc: 0.5667 - val_loss: 0.7538 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7204 - acc: 0.5722 - val_loss: 0.7509 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7262 - acc: 0.5222 - val_loss: 0.7468 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7247 - acc: 0.5333 - val_loss: 0.7465 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7158 - acc: 0.6056 - val_loss: 0.7454 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7177 - acc: 0.5611 - val_loss: 0.7424 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7113 - acc: 0.5944 - val_loss: 0.7401 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7007 - acc: 0.6111 - val_loss: 0.7383 - val_acc: 0.5571\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7106 - acc: 0.6278 - val_loss: 0.7385 - val_acc: 0.5714\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 122us/step - loss: 0.7010 - acc: 0.6167 - val_loss: 0.7395 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7013 - acc: 0.6222 - val_loss: 0.7377 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7007 - acc: 0.5889 - val_loss: 0.7393 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6913 - acc: 0.6056 - val_loss: 0.7363 - val_acc: 0.5857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6884 - acc: 0.6556 - val_loss: 0.7327 - val_acc: 0.5429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6963 - acc: 0.6333 - val_loss: 0.7319 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6881 - acc: 0.6389 - val_loss: 0.7305 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6785 - acc: 0.6611 - val_loss: 0.7293 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6926 - acc: 0.6167 - val_loss: 0.7291 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6892 - acc: 0.6333 - val_loss: 0.7318 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6773 - acc: 0.6611 - val_loss: 0.7277 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6667 - acc: 0.6722 - val_loss: 0.7240 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6776 - acc: 0.6556 - val_loss: 0.7225 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6762 - acc: 0.6611 - val_loss: 0.7215 - val_acc: 0.5286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6791 - acc: 0.6500 - val_loss: 0.7234 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6834 - acc: 0.6278 - val_loss: 0.7217 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6694 - acc: 0.6500 - val_loss: 0.7225 - val_acc: 0.5571\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6650 - acc: 0.6778 - val_loss: 0.7216 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6618 - acc: 0.6889 - val_loss: 0.7180 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6552 - acc: 0.6722 - val_loss: 0.7171 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6600 - acc: 0.6444 - val_loss: 0.7161 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6588 - acc: 0.6889 - val_loss: 0.7175 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6648 - acc: 0.6389 - val_loss: 0.7234 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6400 - acc: 0.6611 - val_loss: 0.7209 - val_acc: 0.6000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6530 - acc: 0.6444 - val_loss: 0.7148 - val_acc: 0.5571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6396 - acc: 0.7000 - val_loss: 0.7156 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6428 - acc: 0.6778 - val_loss: 0.7131 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6555 - acc: 0.6944 - val_loss: 0.7096 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6281 - acc: 0.7333 - val_loss: 0.7098 - val_acc: 0.5857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6285 - acc: 0.7444 - val_loss: 0.7081 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6479 - acc: 0.6722 - val_loss: 0.7055 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6357 - acc: 0.7056 - val_loss: 0.7105 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6326 - acc: 0.6833 - val_loss: 0.7043 - val_acc: 0.6143\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6221 - acc: 0.7222 - val_loss: 0.7047 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 102us/step - loss: 0.6176 - acc: 0.7333 - val_loss: 0.7068 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6162 - acc: 0.7056 - val_loss: 0.7072 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6107 - acc: 0.7444 - val_loss: 0.7044 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6239 - acc: 0.7167 - val_loss: 0.7095 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6332 - acc: 0.6833 - val_loss: 0.7141 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6108 - acc: 0.7278 - val_loss: 0.7036 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.6149 - acc: 0.6889 - val_loss: 0.7046 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6094 - acc: 0.7167 - val_loss: 0.7012 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5953 - acc: 0.7389 - val_loss: 0.6973 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6180 - acc: 0.7056 - val_loss: 0.7015 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 184us/step - loss: 0.5971 - acc: 0.7389 - val_loss: 0.7007 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5831 - acc: 0.7611 - val_loss: 0.6960 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6057 - acc: 0.7389 - val_loss: 0.6981 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5821 - acc: 0.7111 - val_loss: 0.6991 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5855 - acc: 0.7667 - val_loss: 0.6938 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5978 - acc: 0.7278 - val_loss: 0.6944 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5740 - acc: 0.7778 - val_loss: 0.6946 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5793 - acc: 0.7500 - val_loss: 0.6978 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5739 - acc: 0.7444 - val_loss: 0.6936 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5825 - acc: 0.7333 - val_loss: 0.6917 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5721 - acc: 0.7500 - val_loss: 0.6943 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5908 - acc: 0.7333 - val_loss: 0.6900 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.7415 - acc: 0.5389 - val_loss: 0.7610 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7204 - acc: 0.5222 - val_loss: 0.7545 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.7110 - acc: 0.5611 - val_loss: 0.7584 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7102 - acc: 0.5444 - val_loss: 0.7496 - val_acc: 0.5286\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.7101 - acc: 0.5889 - val_loss: 0.7474 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6973 - acc: 0.6000 - val_loss: 0.7513 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6950 - acc: 0.5944 - val_loss: 0.7550 - val_acc: 0.4714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6925 - acc: 0.6167 - val_loss: 0.7517 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6877 - acc: 0.6333 - val_loss: 0.7462 - val_acc: 0.5429\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6819 - acc: 0.6500 - val_loss: 0.7430 - val_acc: 0.5714\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6816 - acc: 0.6556 - val_loss: 0.7434 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6716 - acc: 0.6389 - val_loss: 0.7435 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6766 - acc: 0.6444 - val_loss: 0.7424 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6739 - acc: 0.6389 - val_loss: 0.7432 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6761 - acc: 0.6333 - val_loss: 0.7411 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6762 - acc: 0.6111 - val_loss: 0.7352 - val_acc: 0.5857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6715 - acc: 0.6500 - val_loss: 0.7336 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6476 - acc: 0.7111 - val_loss: 0.7319 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6557 - acc: 0.6611 - val_loss: 0.7363 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6504 - acc: 0.6500 - val_loss: 0.7296 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6562 - acc: 0.6667 - val_loss: 0.7296 - val_acc: 0.5714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6456 - acc: 0.7000 - val_loss: 0.7335 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6442 - acc: 0.6778 - val_loss: 0.7260 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6448 - acc: 0.6722 - val_loss: 0.7239 - val_acc: 0.6429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6401 - acc: 0.7056 - val_loss: 0.7285 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6347 - acc: 0.7389 - val_loss: 0.7233 - val_acc: 0.6286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6217 - acc: 0.7500 - val_loss: 0.7305 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6336 - acc: 0.7000 - val_loss: 0.7354 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6364 - acc: 0.6778 - val_loss: 0.7286 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6128 - acc: 0.7278 - val_loss: 0.7354 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6149 - acc: 0.7167 - val_loss: 0.7334 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6268 - acc: 0.6944 - val_loss: 0.7233 - val_acc: 0.6429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6093 - acc: 0.7611 - val_loss: 0.7256 - val_acc: 0.6143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6232 - acc: 0.7056 - val_loss: 0.7242 - val_acc: 0.6429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6268 - acc: 0.7000 - val_loss: 0.7286 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6061 - acc: 0.7556 - val_loss: 0.7248 - val_acc: 0.6286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6078 - acc: 0.7611 - val_loss: 0.7235 - val_acc: 0.6857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6236 - acc: 0.6889 - val_loss: 0.7279 - val_acc: 0.6286\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6178 - acc: 0.7444 - val_loss: 0.7344 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5933 - acc: 0.7500 - val_loss: 0.7264 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6063 - acc: 0.7389 - val_loss: 0.7224 - val_acc: 0.6714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6005 - acc: 0.7167 - val_loss: 0.7294 - val_acc: 0.6429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5968 - acc: 0.7278 - val_loss: 0.7355 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5747 - acc: 0.7722 - val_loss: 0.7293 - val_acc: 0.6429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5856 - acc: 0.7389 - val_loss: 0.7370 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5851 - acc: 0.7500 - val_loss: 0.7371 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5894 - acc: 0.7444 - val_loss: 0.7298 - val_acc: 0.6429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5949 - acc: 0.7611 - val_loss: 0.7285 - val_acc: 0.6571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5889 - acc: 0.7278 - val_loss: 0.7367 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5772 - acc: 0.7444 - val_loss: 0.7235 - val_acc: 0.6571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5754 - acc: 0.7444 - val_loss: 0.7266 - val_acc: 0.6571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5680 - acc: 0.7667 - val_loss: 0.7244 - val_acc: 0.6571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5773 - acc: 0.7500 - val_loss: 0.7367 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5669 - acc: 0.7722 - val_loss: 0.7289 - val_acc: 0.6571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5606 - acc: 0.7889 - val_loss: 0.7266 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5696 - acc: 0.7500 - val_loss: 0.7345 - val_acc: 0.6714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5615 - acc: 0.7833 - val_loss: 0.7306 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5499 - acc: 0.7833 - val_loss: 0.7278 - val_acc: 0.6571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5596 - acc: 0.7611 - val_loss: 0.7310 - val_acc: 0.6429\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5499 - acc: 0.7944 - val_loss: 0.7307 - val_acc: 0.6571\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5669 - acc: 0.7833 - val_loss: 0.7404 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5364 - acc: 0.7778 - val_loss: 0.7359 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5424 - acc: 0.7667 - val_loss: 0.7382 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5474 - acc: 0.8111 - val_loss: 0.7497 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5324 - acc: 0.7889 - val_loss: 0.7421 - val_acc: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5360 - acc: 0.8167 - val_loss: 0.7429 - val_acc: 0.6571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5246 - acc: 0.8056 - val_loss: 0.7495 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5213 - acc: 0.8056 - val_loss: 0.7425 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5264 - acc: 0.8000 - val_loss: 0.7408 - val_acc: 0.6429\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5250 - acc: 0.8222 - val_loss: 0.7348 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5316 - acc: 0.8000 - val_loss: 0.7424 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5117 - acc: 0.8333 - val_loss: 0.7526 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5330 - acc: 0.7778 - val_loss: 0.7534 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 141us/step - loss: 0.5170 - acc: 0.8111 - val_loss: 0.7427 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5195 - acc: 0.8056 - val_loss: 0.7447 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5078 - acc: 0.8000 - val_loss: 0.7566 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5045 - acc: 0.8000 - val_loss: 0.7428 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.5053 - acc: 0.8111 - val_loss: 0.7560 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5157 - acc: 0.8222 - val_loss: 0.7474 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5078 - acc: 0.8444 - val_loss: 0.7571 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.7407 - acc: 0.5611 - val_loss: 0.7465 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7546 - acc: 0.5000 - val_loss: 0.7431 - val_acc: 0.5571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7380 - acc: 0.5500 - val_loss: 0.7379 - val_acc: 0.5857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7165 - acc: 0.5722 - val_loss: 0.7352 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7195 - acc: 0.5722 - val_loss: 0.7342 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7159 - acc: 0.5278 - val_loss: 0.7297 - val_acc: 0.5857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7040 - acc: 0.5611 - val_loss: 0.7283 - val_acc: 0.5714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7040 - acc: 0.5778 - val_loss: 0.7241 - val_acc: 0.5714\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7080 - acc: 0.5833 - val_loss: 0.7216 - val_acc: 0.5571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7037 - acc: 0.6333 - val_loss: 0.7216 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6870 - acc: 0.6278 - val_loss: 0.7207 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6893 - acc: 0.6611 - val_loss: 0.7206 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6898 - acc: 0.6444 - val_loss: 0.7235 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6878 - acc: 0.6167 - val_loss: 0.7221 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6838 - acc: 0.6000 - val_loss: 0.7197 - val_acc: 0.5571\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 125us/step - loss: 0.6810 - acc: 0.6056 - val_loss: 0.7208 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6831 - acc: 0.6000 - val_loss: 0.7140 - val_acc: 0.6000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6749 - acc: 0.6167 - val_loss: 0.7122 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6653 - acc: 0.6889 - val_loss: 0.7135 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6664 - acc: 0.6389 - val_loss: 0.7148 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6680 - acc: 0.6556 - val_loss: 0.7087 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6634 - acc: 0.6944 - val_loss: 0.7070 - val_acc: 0.6000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6707 - acc: 0.6333 - val_loss: 0.7095 - val_acc: 0.6000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6613 - acc: 0.6500 - val_loss: 0.7120 - val_acc: 0.6000\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6567 - acc: 0.6556 - val_loss: 0.7064 - val_acc: 0.6000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6531 - acc: 0.6722 - val_loss: 0.7008 - val_acc: 0.6000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6566 - acc: 0.6556 - val_loss: 0.7027 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6549 - acc: 0.6444 - val_loss: 0.7069 - val_acc: 0.6143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6444 - acc: 0.6778 - val_loss: 0.7021 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.6212 - acc: 0.710 - 0s 127us/step - loss: 0.6242 - acc: 0.7056 - val_loss: 0.6985 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6558 - acc: 0.6556 - val_loss: 0.6962 - val_acc: 0.5857\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6436 - acc: 0.6778 - val_loss: 0.6948 - val_acc: 0.6143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6257 - acc: 0.7278 - val_loss: 0.6924 - val_acc: 0.6286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6433 - acc: 0.6667 - val_loss: 0.6916 - val_acc: 0.6429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6111 - acc: 0.7167 - val_loss: 0.6987 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6271 - acc: 0.6833 - val_loss: 0.6993 - val_acc: 0.5857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 141us/step - loss: 0.6201 - acc: 0.7111 - val_loss: 0.6932 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6313 - acc: 0.6889 - val_loss: 0.7034 - val_acc: 0.5857\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5964 - acc: 0.7389 - val_loss: 0.6970 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6183 - acc: 0.7000 - val_loss: 0.6952 - val_acc: 0.6000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6051 - acc: 0.7333 - val_loss: 0.6997 - val_acc: 0.5857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6153 - acc: 0.7000 - val_loss: 0.7019 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5986 - acc: 0.7167 - val_loss: 0.6935 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5979 - acc: 0.7222 - val_loss: 0.6974 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5921 - acc: 0.7500 - val_loss: 0.6933 - val_acc: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.6167 - acc: 0.6889 - val_loss: 0.6894 - val_acc: 0.6857\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6170 - acc: 0.7056 - val_loss: 0.6920 - val_acc: 0.6571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5909 - acc: 0.7556 - val_loss: 0.6934 - val_acc: 0.6571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5918 - acc: 0.7611 - val_loss: 0.6929 - val_acc: 0.6714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5877 - acc: 0.7333 - val_loss: 0.6972 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6005 - acc: 0.7389 - val_loss: 0.7026 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5915 - acc: 0.7000 - val_loss: 0.6932 - val_acc: 0.6714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5784 - acc: 0.7389 - val_loss: 0.6915 - val_acc: 0.6714\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5799 - acc: 0.7278 - val_loss: 0.6994 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5805 - acc: 0.7556 - val_loss: 0.6894 - val_acc: 0.6714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5493 - acc: 0.7944 - val_loss: 0.6921 - val_acc: 0.6714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5879 - acc: 0.7222 - val_loss: 0.6949 - val_acc: 0.6571\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5584 - acc: 0.7833 - val_loss: 0.6950 - val_acc: 0.6571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5690 - acc: 0.7722 - val_loss: 0.7017 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5771 - acc: 0.7500 - val_loss: 0.6894 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5500 - acc: 0.7667 - val_loss: 0.7018 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5536 - acc: 0.7389 - val_loss: 0.6969 - val_acc: 0.6714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5589 - acc: 0.7556 - val_loss: 0.6975 - val_acc: 0.6714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5694 - acc: 0.7444 - val_loss: 0.6956 - val_acc: 0.6714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5711 - acc: 0.7500 - val_loss: 0.7088 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5528 - acc: 0.7611 - val_loss: 0.7043 - val_acc: 0.6571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5643 - acc: 0.7611 - val_loss: 0.7032 - val_acc: 0.6714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5355 - acc: 0.7833 - val_loss: 0.6963 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5624 - acc: 0.7500 - val_loss: 0.6983 - val_acc: 0.6714\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5531 - acc: 0.7444 - val_loss: 0.6957 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5553 - acc: 0.7222 - val_loss: 0.7025 - val_acc: 0.6714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5343 - acc: 0.7889 - val_loss: 0.7024 - val_acc: 0.6714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5352 - acc: 0.7833 - val_loss: 0.6997 - val_acc: 0.6714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5392 - acc: 0.8000 - val_loss: 0.6997 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5528 - acc: 0.7333 - val_loss: 0.7041 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5427 - acc: 0.7722 - val_loss: 0.7015 - val_acc: 0.6571\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5513 - acc: 0.7556 - val_loss: 0.7039 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5259 - acc: 0.7833 - val_loss: 0.7071 - val_acc: 0.6714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5254 - acc: 0.7722 - val_loss: 0.7047 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5238 - acc: 0.7667 - val_loss: 0.7091 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.7588 - acc: 0.5333 - val_loss: 0.7431 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7430 - acc: 0.5222 - val_loss: 0.7409 - val_acc: 0.5429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7284 - acc: 0.5333 - val_loss: 0.7388 - val_acc: 0.5429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7335 - acc: 0.5389 - val_loss: 0.7376 - val_acc: 0.5429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.7364 - acc: 0.5222 - val_loss: 0.7359 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7311 - acc: 0.5222 - val_loss: 0.7347 - val_acc: 0.5429\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7227 - acc: 0.5389 - val_loss: 0.7343 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7193 - acc: 0.5500 - val_loss: 0.7326 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7218 - acc: 0.5389 - val_loss: 0.7307 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7160 - acc: 0.5500 - val_loss: 0.7302 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7043 - acc: 0.6000 - val_loss: 0.7287 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7126 - acc: 0.5556 - val_loss: 0.7275 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7213 - acc: 0.5611 - val_loss: 0.7280 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7098 - acc: 0.5611 - val_loss: 0.7267 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7037 - acc: 0.5611 - val_loss: 0.7258 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7019 - acc: 0.5778 - val_loss: 0.7254 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6977 - acc: 0.5833 - val_loss: 0.7248 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6940 - acc: 0.6222 - val_loss: 0.7247 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7064 - acc: 0.5667 - val_loss: 0.7252 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6914 - acc: 0.5833 - val_loss: 0.7221 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6935 - acc: 0.5944 - val_loss: 0.7204 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6853 - acc: 0.6056 - val_loss: 0.7199 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6957 - acc: 0.5889 - val_loss: 0.7198 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6875 - acc: 0.6167 - val_loss: 0.7194 - val_acc: 0.5143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6931 - acc: 0.5944 - val_loss: 0.7179 - val_acc: 0.5143\n",
      "Epoch 26/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.7017 - acc: 0.5722 - val_loss: 0.7168 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6934 - acc: 0.5722 - val_loss: 0.7176 - val_acc: 0.5143\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6791 - acc: 0.6278 - val_loss: 0.7172 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6707 - acc: 0.6222 - val_loss: 0.7161 - val_acc: 0.5429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6785 - acc: 0.6056 - val_loss: 0.7148 - val_acc: 0.5429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6830 - acc: 0.5944 - val_loss: 0.7134 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6709 - acc: 0.6667 - val_loss: 0.7124 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6729 - acc: 0.6333 - val_loss: 0.7119 - val_acc: 0.5286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6811 - acc: 0.6333 - val_loss: 0.7105 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6642 - acc: 0.6667 - val_loss: 0.7106 - val_acc: 0.5429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6647 - acc: 0.6111 - val_loss: 0.7092 - val_acc: 0.5429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6623 - acc: 0.6556 - val_loss: 0.7094 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6526 - acc: 0.6667 - val_loss: 0.7066 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6600 - acc: 0.6778 - val_loss: 0.7039 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6507 - acc: 0.6778 - val_loss: 0.7027 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6447 - acc: 0.6833 - val_loss: 0.7018 - val_acc: 0.5571\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6577 - acc: 0.6667 - val_loss: 0.6996 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6380 - acc: 0.7167 - val_loss: 0.7006 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6423 - acc: 0.6722 - val_loss: 0.6995 - val_acc: 0.5714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6508 - acc: 0.6889 - val_loss: 0.6998 - val_acc: 0.5571\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6362 - acc: 0.7167 - val_loss: 0.6984 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6214 - acc: 0.7111 - val_loss: 0.6975 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6267 - acc: 0.6944 - val_loss: 0.6964 - val_acc: 0.6000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6399 - acc: 0.7222 - val_loss: 0.6950 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6330 - acc: 0.7056 - val_loss: 0.6970 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6316 - acc: 0.7111 - val_loss: 0.6965 - val_acc: 0.6000\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6148 - acc: 0.7556 - val_loss: 0.6931 - val_acc: 0.6286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6309 - acc: 0.7222 - val_loss: 0.6932 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 499us/step - loss: 0.6141 - acc: 0.7444 - val_loss: 0.6924 - val_acc: 0.6143\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6147 - acc: 0.7333 - val_loss: 0.6956 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6060 - acc: 0.7389 - val_loss: 0.6950 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6003 - acc: 0.7389 - val_loss: 0.6931 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5914 - acc: 0.7722 - val_loss: 0.6954 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6045 - acc: 0.7111 - val_loss: 0.6950 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5901 - acc: 0.7667 - val_loss: 0.6927 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5922 - acc: 0.7611 - val_loss: 0.6961 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6144 - acc: 0.7167 - val_loss: 0.6949 - val_acc: 0.6286\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6067 - acc: 0.7167 - val_loss: 0.6997 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 199us/step - loss: 0.5962 - acc: 0.7278 - val_loss: 0.6971 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5895 - acc: 0.7722 - val_loss: 0.6954 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5963 - acc: 0.7389 - val_loss: 0.6954 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5733 - acc: 0.7889 - val_loss: 0.6955 - val_acc: 0.6429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5843 - acc: 0.7556 - val_loss: 0.6957 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5847 - acc: 0.7556 - val_loss: 0.6988 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5683 - acc: 0.7611 - val_loss: 0.6964 - val_acc: 0.6429\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5775 - acc: 0.7444 - val_loss: 0.6965 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5790 - acc: 0.7444 - val_loss: 0.6985 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5666 - acc: 0.7444 - val_loss: 0.6995 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5663 - acc: 0.7778 - val_loss: 0.6984 - val_acc: 0.6286\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5746 - acc: 0.7556 - val_loss: 0.6971 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5631 - acc: 0.7500 - val_loss: 0.6963 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5604 - acc: 0.7611 - val_loss: 0.6961 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5663 - acc: 0.7667 - val_loss: 0.6971 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5395 - acc: 0.8056 - val_loss: 0.7001 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5476 - acc: 0.7944 - val_loss: 0.7010 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 162us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 0.7424 - acc: 0.5333 - val_loss: 0.7332 - val_acc: 0.5429\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7369 - acc: 0.5278 - val_loss: 0.7267 - val_acc: 0.5571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7238 - acc: 0.5389 - val_loss: 0.7276 - val_acc: 0.5571\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7269 - acc: 0.5500 - val_loss: 0.7234 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7184 - acc: 0.5722 - val_loss: 0.7264 - val_acc: 0.5429\n",
      "Epoch 6/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.7156 - acc: 0.5833 - val_loss: 0.7237 - val_acc: 0.5714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7053 - acc: 0.5944 - val_loss: 0.7199 - val_acc: 0.5714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7138 - acc: 0.5833 - val_loss: 0.7162 - val_acc: 0.5857\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7087 - acc: 0.6056 - val_loss: 0.7204 - val_acc: 0.5714\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7154 - acc: 0.5944 - val_loss: 0.7172 - val_acc: 0.5857\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7019 - acc: 0.6167 - val_loss: 0.7197 - val_acc: 0.5714\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7079 - acc: 0.5667 - val_loss: 0.7144 - val_acc: 0.5857\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6723 - acc: 0.6389 - val_loss: 0.7090 - val_acc: 0.5714\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6959 - acc: 0.6000 - val_loss: 0.7041 - val_acc: 0.5857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6856 - acc: 0.6333 - val_loss: 0.7045 - val_acc: 0.5857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6855 - acc: 0.6000 - val_loss: 0.7067 - val_acc: 0.5857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6930 - acc: 0.6056 - val_loss: 0.7023 - val_acc: 0.6143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6827 - acc: 0.6278 - val_loss: 0.6996 - val_acc: 0.6429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6878 - acc: 0.6056 - val_loss: 0.7102 - val_acc: 0.5857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6916 - acc: 0.6111 - val_loss: 0.7044 - val_acc: 0.6000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6829 - acc: 0.5944 - val_loss: 0.7017 - val_acc: 0.6000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6800 - acc: 0.6278 - val_loss: 0.6966 - val_acc: 0.6429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6702 - acc: 0.6278 - val_loss: 0.6964 - val_acc: 0.6143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6780 - acc: 0.5722 - val_loss: 0.6987 - val_acc: 0.6143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6694 - acc: 0.6389 - val_loss: 0.6976 - val_acc: 0.6429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6780 - acc: 0.6056 - val_loss: 0.6913 - val_acc: 0.6571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6609 - acc: 0.6667 - val_loss: 0.6851 - val_acc: 0.6429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6669 - acc: 0.6389 - val_loss: 0.6921 - val_acc: 0.6571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6496 - acc: 0.6833 - val_loss: 0.6862 - val_acc: 0.6714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6434 - acc: 0.7222 - val_loss: 0.6868 - val_acc: 0.6571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6465 - acc: 0.7000 - val_loss: 0.6848 - val_acc: 0.6714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6396 - acc: 0.7000 - val_loss: 0.6837 - val_acc: 0.6714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6403 - acc: 0.6833 - val_loss: 0.6823 - val_acc: 0.6714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6429 - acc: 0.6778 - val_loss: 0.6788 - val_acc: 0.6714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6255 - acc: 0.7111 - val_loss: 0.6870 - val_acc: 0.6286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6472 - acc: 0.6667 - val_loss: 0.6845 - val_acc: 0.6714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6288 - acc: 0.6611 - val_loss: 0.6744 - val_acc: 0.6429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6308 - acc: 0.7333 - val_loss: 0.6743 - val_acc: 0.6714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6363 - acc: 0.6889 - val_loss: 0.6778 - val_acc: 0.6714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6430 - acc: 0.6611 - val_loss: 0.6804 - val_acc: 0.6714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6218 - acc: 0.6944 - val_loss: 0.6823 - val_acc: 0.6571\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6381 - acc: 0.6667 - val_loss: 0.6866 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6331 - acc: 0.6722 - val_loss: 0.6803 - val_acc: 0.6429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6473 - acc: 0.6500 - val_loss: 0.6773 - val_acc: 0.6429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6046 - acc: 0.7222 - val_loss: 0.6866 - val_acc: 0.6429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6179 - acc: 0.7056 - val_loss: 0.6802 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6256 - acc: 0.6889 - val_loss: 0.6738 - val_acc: 0.6429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6182 - acc: 0.6778 - val_loss: 0.6806 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6031 - acc: 0.7111 - val_loss: 0.6804 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5910 - acc: 0.7111 - val_loss: 0.6729 - val_acc: 0.6429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5757 - acc: 0.7389 - val_loss: 0.6777 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6045 - acc: 0.6889 - val_loss: 0.6776 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6094 - acc: 0.7111 - val_loss: 0.6812 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5940 - acc: 0.7556 - val_loss: 0.6758 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.5995 - acc: 0.7167 - val_loss: 0.6847 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5904 - acc: 0.7556 - val_loss: 0.6794 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5883 - acc: 0.7278 - val_loss: 0.6736 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5824 - acc: 0.7500 - val_loss: 0.6725 - val_acc: 0.6714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6129 - acc: 0.6944 - val_loss: 0.6806 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5898 - acc: 0.7167 - val_loss: 0.6752 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5863 - acc: 0.7278 - val_loss: 0.6715 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5897 - acc: 0.7333 - val_loss: 0.6735 - val_acc: 0.6714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5791 - acc: 0.7333 - val_loss: 0.6802 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.5668 - acc: 0.7444 - val_loss: 0.6750 - val_acc: 0.6714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5605 - acc: 0.7833 - val_loss: 0.6807 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5554 - acc: 0.7333 - val_loss: 0.6832 - val_acc: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5533 - acc: 0.7611 - val_loss: 0.6824 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5447 - acc: 0.7778 - val_loss: 0.6828 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5619 - acc: 0.7611 - val_loss: 0.6765 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5596 - acc: 0.7722 - val_loss: 0.6778 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5468 - acc: 0.8056 - val_loss: 0.6787 - val_acc: 0.6286\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5635 - acc: 0.7556 - val_loss: 0.6816 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5206 - acc: 0.8222 - val_loss: 0.6823 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5518 - acc: 0.7667 - val_loss: 0.6824 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5294 - acc: 0.7611 - val_loss: 0.6897 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5251 - acc: 0.8000 - val_loss: 0.6825 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5288 - acc: 0.7778 - val_loss: 0.6950 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5515 - acc: 0.7500 - val_loss: 0.7000 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5454 - acc: 0.7778 - val_loss: 0.6857 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5200 - acc: 0.8000 - val_loss: 0.6940 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 162us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.7865 - acc: 0.4722 - val_loss: 0.7576 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7620 - acc: 0.4778 - val_loss: 0.7531 - val_acc: 0.4143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7506 - acc: 0.5389 - val_loss: 0.7520 - val_acc: 0.4429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7427 - acc: 0.5667 - val_loss: 0.7506 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7383 - acc: 0.5500 - val_loss: 0.7493 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7307 - acc: 0.6111 - val_loss: 0.7474 - val_acc: 0.4857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7316 - acc: 0.5722 - val_loss: 0.7462 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7246 - acc: 0.5944 - val_loss: 0.7450 - val_acc: 0.4857\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7291 - acc: 0.5889 - val_loss: 0.7444 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7271 - acc: 0.5278 - val_loss: 0.7437 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7256 - acc: 0.5667 - val_loss: 0.7436 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7189 - acc: 0.5889 - val_loss: 0.7430 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7182 - acc: 0.5722 - val_loss: 0.7409 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7132 - acc: 0.5833 - val_loss: 0.7395 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7148 - acc: 0.5778 - val_loss: 0.7395 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7154 - acc: 0.5778 - val_loss: 0.7386 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7011 - acc: 0.6111 - val_loss: 0.7367 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7056 - acc: 0.5889 - val_loss: 0.7338 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7018 - acc: 0.6167 - val_loss: 0.7315 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7043 - acc: 0.6111 - val_loss: 0.7322 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6979 - acc: 0.6111 - val_loss: 0.7302 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.7169 - acc: 0.562 - 0s 155us/step - loss: 0.7036 - acc: 0.5778 - val_loss: 0.7280 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.7010 - acc: 0.5722 - val_loss: 0.7267 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.6978 - acc: 0.6000 - val_loss: 0.7240 - val_acc: 0.5143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.6877 - acc: 0.6167 - val_loss: 0.7244 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 167us/step - loss: 0.6879 - acc: 0.6389 - val_loss: 0.7226 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 167us/step - loss: 0.6896 - acc: 0.6389 - val_loss: 0.7209 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 167us/step - loss: 0.6900 - acc: 0.6222 - val_loss: 0.7204 - val_acc: 0.5286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 131us/step - loss: 0.6806 - acc: 0.6222 - val_loss: 0.7201 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.6801 - acc: 0.6167 - val_loss: 0.7177 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6732 - acc: 0.6500 - val_loss: 0.7161 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6799 - acc: 0.6333 - val_loss: 0.7176 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6807 - acc: 0.6167 - val_loss: 0.7160 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6776 - acc: 0.6278 - val_loss: 0.7122 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6762 - acc: 0.6111 - val_loss: 0.7114 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6634 - acc: 0.6667 - val_loss: 0.7110 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6725 - acc: 0.6333 - val_loss: 0.7100 - val_acc: 0.5571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.6688 - acc: 0.6444 - val_loss: 0.7108 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6658 - acc: 0.6278 - val_loss: 0.7111 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6658 - acc: 0.6444 - val_loss: 0.7073 - val_acc: 0.5714\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6531 - acc: 0.6611 - val_loss: 0.7110 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6563 - acc: 0.6389 - val_loss: 0.7134 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6477 - acc: 0.6333 - val_loss: 0.7068 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6583 - acc: 0.6167 - val_loss: 0.7048 - val_acc: 0.6000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6392 - acc: 0.7000 - val_loss: 0.7026 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6509 - acc: 0.6611 - val_loss: 0.7023 - val_acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6348 - acc: 0.7389 - val_loss: 0.6996 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6360 - acc: 0.6833 - val_loss: 0.7034 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6292 - acc: 0.6889 - val_loss: 0.7051 - val_acc: 0.6143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6276 - acc: 0.7056 - val_loss: 0.6957 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6357 - acc: 0.6722 - val_loss: 0.6978 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6271 - acc: 0.7222 - val_loss: 0.6978 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6258 - acc: 0.6778 - val_loss: 0.6945 - val_acc: 0.5857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6107 - acc: 0.7222 - val_loss: 0.6967 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6271 - acc: 0.6833 - val_loss: 0.6958 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6201 - acc: 0.7111 - val_loss: 0.6979 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6242 - acc: 0.7000 - val_loss: 0.6906 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6141 - acc: 0.7333 - val_loss: 0.6869 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6028 - acc: 0.7667 - val_loss: 0.6844 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5967 - acc: 0.7333 - val_loss: 0.6803 - val_acc: 0.6429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5976 - acc: 0.7667 - val_loss: 0.6827 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.6132 - acc: 0.7056 - val_loss: 0.6783 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5870 - acc: 0.7722 - val_loss: 0.6825 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5854 - acc: 0.7722 - val_loss: 0.6835 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5873 - acc: 0.7556 - val_loss: 0.6770 - val_acc: 0.6714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5877 - acc: 0.7722 - val_loss: 0.6878 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5842 - acc: 0.7444 - val_loss: 0.6892 - val_acc: 0.6000\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5873 - acc: 0.7278 - val_loss: 0.6818 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5687 - acc: 0.7611 - val_loss: 0.6783 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5707 - acc: 0.7722 - val_loss: 0.6783 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5812 - acc: 0.7556 - val_loss: 0.6753 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5834 - acc: 0.7333 - val_loss: 0.6768 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5604 - acc: 0.7889 - val_loss: 0.6763 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5751 - acc: 0.7500 - val_loss: 0.6864 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5650 - acc: 0.7500 - val_loss: 0.6932 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5634 - acc: 0.7444 - val_loss: 0.6964 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5730 - acc: 0.7500 - val_loss: 0.6853 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5641 - acc: 0.7778 - val_loss: 0.6803 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5433 - acc: 0.7778 - val_loss: 0.6855 - val_acc: 0.6571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5661 - acc: 0.7500 - val_loss: 0.6843 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 137us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 4s 25ms/step - loss: 0.7510 - acc: 0.5500 - val_loss: 0.7295 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7411 - acc: 0.5444 - val_loss: 0.7307 - val_acc: 0.5143\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7200 - acc: 0.5778 - val_loss: 0.7274 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7368 - acc: 0.5778 - val_loss: 0.7217 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7406 - acc: 0.5333 - val_loss: 0.7211 - val_acc: 0.5286\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7226 - acc: 0.5722 - val_loss: 0.7210 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7394 - acc: 0.5333 - val_loss: 0.7178 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7116 - acc: 0.6056 - val_loss: 0.7169 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7033 - acc: 0.5667 - val_loss: 0.7184 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7013 - acc: 0.6222 - val_loss: 0.7145 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6785 - acc: 0.6278 - val_loss: 0.7138 - val_acc: 0.5286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7013 - acc: 0.6000 - val_loss: 0.7137 - val_acc: 0.5571\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7018 - acc: 0.5778 - val_loss: 0.7160 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7081 - acc: 0.6000 - val_loss: 0.7135 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6978 - acc: 0.6056 - val_loss: 0.7167 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6916 - acc: 0.6167 - val_loss: 0.7103 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6866 - acc: 0.6056 - val_loss: 0.7061 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.6899 - acc: 0.6000 - val_loss: 0.7005 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6821 - acc: 0.6056 - val_loss: 0.7023 - val_acc: 0.5571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6668 - acc: 0.6333 - val_loss: 0.6997 - val_acc: 0.5714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6861 - acc: 0.6444 - val_loss: 0.6935 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6755 - acc: 0.6333 - val_loss: 0.6927 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6637 - acc: 0.6889 - val_loss: 0.6929 - val_acc: 0.5429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6637 - acc: 0.6500 - val_loss: 0.6965 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6645 - acc: 0.6667 - val_loss: 0.6911 - val_acc: 0.5714\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6582 - acc: 0.6611 - val_loss: 0.7014 - val_acc: 0.5714\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6518 - acc: 0.6611 - val_loss: 0.6896 - val_acc: 0.5714\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6701 - acc: 0.6556 - val_loss: 0.6849 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6512 - acc: 0.6667 - val_loss: 0.6818 - val_acc: 0.6286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6418 - acc: 0.7167 - val_loss: 0.6878 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6410 - acc: 0.7000 - val_loss: 0.6900 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6329 - acc: 0.6722 - val_loss: 0.6839 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6347 - acc: 0.7111 - val_loss: 0.6858 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6355 - acc: 0.6833 - val_loss: 0.6796 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6342 - acc: 0.7111 - val_loss: 0.6742 - val_acc: 0.6000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6251 - acc: 0.7000 - val_loss: 0.6820 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6278 - acc: 0.6778 - val_loss: 0.6769 - val_acc: 0.6000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6147 - acc: 0.7111 - val_loss: 0.6724 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6245 - acc: 0.7056 - val_loss: 0.6778 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6139 - acc: 0.7222 - val_loss: 0.6731 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5985 - acc: 0.7556 - val_loss: 0.6707 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6245 - acc: 0.6833 - val_loss: 0.6777 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6081 - acc: 0.7500 - val_loss: 0.6733 - val_acc: 0.5857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5978 - acc: 0.7444 - val_loss: 0.6658 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6115 - acc: 0.7111 - val_loss: 0.6737 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5951 - acc: 0.7278 - val_loss: 0.6678 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 113us/step - loss: 0.5925 - acc: 0.7500 - val_loss: 0.6706 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6107 - acc: 0.7000 - val_loss: 0.6649 - val_acc: 0.5857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5927 - acc: 0.7389 - val_loss: 0.6646 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5880 - acc: 0.7778 - val_loss: 0.6634 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5842 - acc: 0.7056 - val_loss: 0.6670 - val_acc: 0.5571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 119us/step - loss: 0.5778 - acc: 0.7611 - val_loss: 0.6753 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5866 - acc: 0.7500 - val_loss: 0.6568 - val_acc: 0.6571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5809 - acc: 0.8000 - val_loss: 0.6590 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5644 - acc: 0.7667 - val_loss: 0.6672 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5684 - acc: 0.7889 - val_loss: 0.6709 - val_acc: 0.5571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5584 - acc: 0.7778 - val_loss: 0.6844 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5734 - acc: 0.7444 - val_loss: 0.6679 - val_acc: 0.5714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5658 - acc: 0.7333 - val_loss: 0.6588 - val_acc: 0.6571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5617 - acc: 0.7667 - val_loss: 0.6720 - val_acc: 0.5429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5601 - acc: 0.7778 - val_loss: 0.6635 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5661 - acc: 0.7611 - val_loss: 0.6576 - val_acc: 0.6714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5589 - acc: 0.7556 - val_loss: 0.6606 - val_acc: 0.6286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5461 - acc: 0.7944 - val_loss: 0.6699 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5721 - acc: 0.7500 - val_loss: 0.6702 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5672 - acc: 0.7500 - val_loss: 0.6590 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5238 - acc: 0.8222 - val_loss: 0.6739 - val_acc: 0.5857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5543 - acc: 0.7611 - val_loss: 0.6655 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5249 - acc: 0.8111 - val_loss: 0.6617 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5537 - acc: 0.7833 - val_loss: 0.6618 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5234 - acc: 0.7889 - val_loss: 0.6578 - val_acc: 0.6714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5471 - acc: 0.7556 - val_loss: 0.6639 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5132 - acc: 0.7889 - val_loss: 0.6629 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5741 - acc: 0.7500 - val_loss: 0.6565 - val_acc: 0.7000\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5375 - acc: 0.7444 - val_loss: 0.6597 - val_acc: 0.6714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5154 - acc: 0.7889 - val_loss: 0.6609 - val_acc: 0.6714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5333 - acc: 0.7611 - val_loss: 0.6590 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5353 - acc: 0.7667 - val_loss: 0.6593 - val_acc: 0.6714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5355 - acc: 0.7778 - val_loss: 0.6625 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5123 - acc: 0.8056 - val_loss: 0.6660 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 0.8052 - acc: 0.4556 - val_loss: 0.7554 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7605 - acc: 0.5278 - val_loss: 0.7416 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7530 - acc: 0.5333 - val_loss: 0.7336 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7381 - acc: 0.5889 - val_loss: 0.7277 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7221 - acc: 0.6389 - val_loss: 0.7252 - val_acc: 0.5714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7121 - acc: 0.6167 - val_loss: 0.7224 - val_acc: 0.6714\n",
      "Epoch 7/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/step - loss: 0.7100 - acc: 0.6389 - val_loss: 0.7216 - val_acc: 0.6714\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7029 - acc: 0.6722 - val_loss: 0.7201 - val_acc: 0.6571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7077 - acc: 0.6056 - val_loss: 0.7193 - val_acc: 0.6000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7073 - acc: 0.6278 - val_loss: 0.7182 - val_acc: 0.6286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7018 - acc: 0.6333 - val_loss: 0.7174 - val_acc: 0.6286\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6948 - acc: 0.6167 - val_loss: 0.7157 - val_acc: 0.6143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7016 - acc: 0.6278 - val_loss: 0.7157 - val_acc: 0.6000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6944 - acc: 0.6111 - val_loss: 0.7149 - val_acc: 0.6000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6912 - acc: 0.6111 - val_loss: 0.7148 - val_acc: 0.6000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6893 - acc: 0.6056 - val_loss: 0.7145 - val_acc: 0.6000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6929 - acc: 0.6389 - val_loss: 0.7147 - val_acc: 0.5857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6861 - acc: 0.6278 - val_loss: 0.7134 - val_acc: 0.6143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6809 - acc: 0.6222 - val_loss: 0.7131 - val_acc: 0.6143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6769 - acc: 0.6778 - val_loss: 0.7144 - val_acc: 0.6000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6757 - acc: 0.6389 - val_loss: 0.7146 - val_acc: 0.5714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6610 - acc: 0.6611 - val_loss: 0.7138 - val_acc: 0.5857\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6721 - acc: 0.6389 - val_loss: 0.7150 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6640 - acc: 0.6500 - val_loss: 0.7121 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 101us/step - loss: 0.6708 - acc: 0.6500 - val_loss: 0.7100 - val_acc: 0.6143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6717 - acc: 0.6556 - val_loss: 0.7109 - val_acc: 0.6000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6629 - acc: 0.6556 - val_loss: 0.7115 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6749 - acc: 0.6167 - val_loss: 0.7084 - val_acc: 0.6000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6586 - acc: 0.6611 - val_loss: 0.7078 - val_acc: 0.6143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 109us/step - loss: 0.6569 - acc: 0.6778 - val_loss: 0.7084 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6490 - acc: 0.7167 - val_loss: 0.7064 - val_acc: 0.6000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6512 - acc: 0.6778 - val_loss: 0.7068 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6503 - acc: 0.6833 - val_loss: 0.7049 - val_acc: 0.6286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 112us/step - loss: 0.6377 - acc: 0.7111 - val_loss: 0.7060 - val_acc: 0.6143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6361 - acc: 0.7000 - val_loss: 0.7060 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6505 - acc: 0.6889 - val_loss: 0.7058 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6414 - acc: 0.6722 - val_loss: 0.7013 - val_acc: 0.6143\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6304 - acc: 0.7000 - val_loss: 0.6998 - val_acc: 0.6571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 104us/step - loss: 0.6386 - acc: 0.6833 - val_loss: 0.6998 - val_acc: 0.6286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6239 - acc: 0.7389 - val_loss: 0.6985 - val_acc: 0.6429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6168 - acc: 0.7556 - val_loss: 0.6964 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6280 - acc: 0.7222 - val_loss: 0.6999 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6101 - acc: 0.7500 - val_loss: 0.6969 - val_acc: 0.6286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6229 - acc: 0.7222 - val_loss: 0.6950 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6099 - acc: 0.7444 - val_loss: 0.6982 - val_acc: 0.6429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6097 - acc: 0.7222 - val_loss: 0.6938 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6044 - acc: 0.7167 - val_loss: 0.6934 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 172us/step - loss: 0.6159 - acc: 0.7056 - val_loss: 0.6943 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6153 - acc: 0.7278 - val_loss: 0.6958 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6088 - acc: 0.7389 - val_loss: 0.6928 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6025 - acc: 0.7444 - val_loss: 0.6918 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6236 - acc: 0.7278 - val_loss: 0.6912 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6197 - acc: 0.7222 - val_loss: 0.6918 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5924 - acc: 0.7444 - val_loss: 0.6924 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5905 - acc: 0.7500 - val_loss: 0.6886 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5922 - acc: 0.7611 - val_loss: 0.6861 - val_acc: 0.6571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 128us/step - loss: 0.5785 - acc: 0.7833 - val_loss: 0.6903 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5797 - acc: 0.7444 - val_loss: 0.6883 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5613 - acc: 0.7667 - val_loss: 0.6853 - val_acc: 0.6714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 147us/step - loss: 0.5780 - acc: 0.7611 - val_loss: 0.6842 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5790 - acc: 0.7444 - val_loss: 0.6843 - val_acc: 0.6714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5682 - acc: 0.8000 - val_loss: 0.6851 - val_acc: 0.6571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5692 - acc: 0.7667 - val_loss: 0.6844 - val_acc: 0.6571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5694 - acc: 0.7944 - val_loss: 0.6840 - val_acc: 0.6857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5625 - acc: 0.7667 - val_loss: 0.6876 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5537 - acc: 0.7778 - val_loss: 0.6854 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5639 - acc: 0.7611 - val_loss: 0.6844 - val_acc: 0.6714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5727 - acc: 0.7444 - val_loss: 0.6839 - val_acc: 0.6714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5457 - acc: 0.7833 - val_loss: 0.6843 - val_acc: 0.6571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5495 - acc: 0.7889 - val_loss: 0.6843 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5533 - acc: 0.7778 - val_loss: 0.6823 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5584 - acc: 0.7833 - val_loss: 0.6834 - val_acc: 0.6714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5477 - acc: 0.8000 - val_loss: 0.6858 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5269 - acc: 0.7611 - val_loss: 0.6877 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5476 - acc: 0.7667 - val_loss: 0.6892 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5153 - acc: 0.8278 - val_loss: 0.6903 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5344 - acc: 0.7833 - val_loss: 0.6890 - val_acc: 0.6714\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5445 - acc: 0.7556 - val_loss: 0.6869 - val_acc: 0.6857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5157 - acc: 0.8167 - val_loss: 0.6895 - val_acc: 0.6429\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5277 - acc: 0.8056 - val_loss: 0.6887 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 162us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.8158 - acc: 0.5389 - val_loss: 0.8140 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7760 - acc: 0.5389 - val_loss: 0.7977 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7612 - acc: 0.5389 - val_loss: 0.7886 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7525 - acc: 0.5389 - val_loss: 0.7811 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7557 - acc: 0.5389 - val_loss: 0.7729 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7341 - acc: 0.5444 - val_loss: 0.7673 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7360 - acc: 0.5389 - val_loss: 0.7616 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7251 - acc: 0.5278 - val_loss: 0.7569 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7309 - acc: 0.5389 - val_loss: 0.7524 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7217 - acc: 0.5389 - val_loss: 0.7500 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7153 - acc: 0.5333 - val_loss: 0.7476 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 216us/step - loss: 0.7156 - acc: 0.5333 - val_loss: 0.7467 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7064 - acc: 0.5444 - val_loss: 0.7449 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7132 - acc: 0.5389 - val_loss: 0.7438 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7091 - acc: 0.5444 - val_loss: 0.7435 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7015 - acc: 0.5444 - val_loss: 0.7408 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7045 - acc: 0.5444 - val_loss: 0.7382 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6943 - acc: 0.5611 - val_loss: 0.7374 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6951 - acc: 0.5500 - val_loss: 0.7368 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6910 - acc: 0.5722 - val_loss: 0.7366 - val_acc: 0.5286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6864 - acc: 0.5722 - val_loss: 0.7346 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6965 - acc: 0.5889 - val_loss: 0.7356 - val_acc: 0.5143\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6873 - acc: 0.5722 - val_loss: 0.7332 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6862 - acc: 0.5722 - val_loss: 0.7335 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6805 - acc: 0.5833 - val_loss: 0.7319 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6788 - acc: 0.6000 - val_loss: 0.7313 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6710 - acc: 0.6000 - val_loss: 0.7292 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6777 - acc: 0.6167 - val_loss: 0.7281 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6715 - acc: 0.6667 - val_loss: 0.7267 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6716 - acc: 0.6333 - val_loss: 0.7243 - val_acc: 0.5714\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6683 - acc: 0.6667 - val_loss: 0.7242 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6597 - acc: 0.6389 - val_loss: 0.7251 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6606 - acc: 0.6278 - val_loss: 0.7251 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6595 - acc: 0.6667 - val_loss: 0.7229 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6587 - acc: 0.6556 - val_loss: 0.7234 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6577 - acc: 0.6444 - val_loss: 0.7212 - val_acc: 0.6000\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6461 - acc: 0.6778 - val_loss: 0.7218 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6423 - acc: 0.6389 - val_loss: 0.7236 - val_acc: 0.6000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6394 - acc: 0.6833 - val_loss: 0.7227 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6423 - acc: 0.6944 - val_loss: 0.7236 - val_acc: 0.6000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6390 - acc: 0.6833 - val_loss: 0.7233 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6430 - acc: 0.6722 - val_loss: 0.7237 - val_acc: 0.6000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6368 - acc: 0.6722 - val_loss: 0.7232 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6278 - acc: 0.6889 - val_loss: 0.7191 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6294 - acc: 0.7278 - val_loss: 0.7163 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6157 - acc: 0.7167 - val_loss: 0.7161 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6243 - acc: 0.7167 - val_loss: 0.7137 - val_acc: 0.5714\n",
      "Epoch 48/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 100us/step - loss: 0.6293 - acc: 0.7222 - val_loss: 0.7154 - val_acc: 0.6000\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6136 - acc: 0.7278 - val_loss: 0.7151 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 107us/step - loss: 0.6166 - acc: 0.7111 - val_loss: 0.7139 - val_acc: 0.5714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6165 - acc: 0.7389 - val_loss: 0.7125 - val_acc: 0.5857\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6070 - acc: 0.7389 - val_loss: 0.7118 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6086 - acc: 0.7333 - val_loss: 0.7129 - val_acc: 0.5857\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6033 - acc: 0.7389 - val_loss: 0.7119 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.5975 - acc: 0.7722 - val_loss: 0.7094 - val_acc: 0.5714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5978 - acc: 0.7556 - val_loss: 0.7104 - val_acc: 0.5714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5912 - acc: 0.7611 - val_loss: 0.7129 - val_acc: 0.5714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5899 - acc: 0.7556 - val_loss: 0.7135 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5840 - acc: 0.7722 - val_loss: 0.7125 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5870 - acc: 0.7333 - val_loss: 0.7156 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5929 - acc: 0.7556 - val_loss: 0.7121 - val_acc: 0.5714\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5835 - acc: 0.7722 - val_loss: 0.7118 - val_acc: 0.5714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5783 - acc: 0.7944 - val_loss: 0.7126 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5777 - acc: 0.7556 - val_loss: 0.7097 - val_acc: 0.5714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 103us/step - loss: 0.5754 - acc: 0.7556 - val_loss: 0.7095 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5755 - acc: 0.7611 - val_loss: 0.7107 - val_acc: 0.5714\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5819 - acc: 0.7389 - val_loss: 0.7078 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5765 - acc: 0.7389 - val_loss: 0.7079 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5726 - acc: 0.7722 - val_loss: 0.7080 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5489 - acc: 0.7944 - val_loss: 0.7064 - val_acc: 0.5857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5528 - acc: 0.7722 - val_loss: 0.7095 - val_acc: 0.5857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5533 - acc: 0.8111 - val_loss: 0.7111 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5615 - acc: 0.7611 - val_loss: 0.7085 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5473 - acc: 0.7778 - val_loss: 0.7072 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5468 - acc: 0.8111 - val_loss: 0.7110 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5486 - acc: 0.7556 - val_loss: 0.7129 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5389 - acc: 0.8000 - val_loss: 0.7157 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5387 - acc: 0.8167 - val_loss: 0.7149 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5454 - acc: 0.7833 - val_loss: 0.7108 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5451 - acc: 0.7944 - val_loss: 0.7068 - val_acc: 0.5857\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.7752 - acc: 0.4944 - val_loss: 0.7342 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7545 - acc: 0.5000 - val_loss: 0.7268 - val_acc: 0.6000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7432 - acc: 0.5611 - val_loss: 0.7247 - val_acc: 0.6000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7391 - acc: 0.4944 - val_loss: 0.7248 - val_acc: 0.5857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7240 - acc: 0.5333 - val_loss: 0.7228 - val_acc: 0.5857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7163 - acc: 0.5611 - val_loss: 0.7207 - val_acc: 0.5857\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7119 - acc: 0.5778 - val_loss: 0.7189 - val_acc: 0.5857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7145 - acc: 0.5500 - val_loss: 0.7179 - val_acc: 0.6000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.7249 - acc: 0.5278 - val_loss: 0.7171 - val_acc: 0.6000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7133 - acc: 0.5500 - val_loss: 0.7185 - val_acc: 0.6000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7099 - acc: 0.5722 - val_loss: 0.7184 - val_acc: 0.5571\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7108 - acc: 0.5667 - val_loss: 0.7137 - val_acc: 0.6143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7060 - acc: 0.5667 - val_loss: 0.7150 - val_acc: 0.6000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7009 - acc: 0.6000 - val_loss: 0.7155 - val_acc: 0.5857\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7016 - acc: 0.5944 - val_loss: 0.7117 - val_acc: 0.5857\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6860 - acc: 0.6111 - val_loss: 0.7126 - val_acc: 0.5857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6978 - acc: 0.5667 - val_loss: 0.7101 - val_acc: 0.6143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7027 - acc: 0.5722 - val_loss: 0.7085 - val_acc: 0.6143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6874 - acc: 0.6222 - val_loss: 0.7082 - val_acc: 0.6000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6969 - acc: 0.5722 - val_loss: 0.7098 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6730 - acc: 0.6444 - val_loss: 0.7062 - val_acc: 0.5857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6831 - acc: 0.5944 - val_loss: 0.7067 - val_acc: 0.6000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6745 - acc: 0.6167 - val_loss: 0.7039 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6666 - acc: 0.6778 - val_loss: 0.7026 - val_acc: 0.5857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6744 - acc: 0.6167 - val_loss: 0.7012 - val_acc: 0.5857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6725 - acc: 0.6556 - val_loss: 0.6979 - val_acc: 0.6143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6625 - acc: 0.6333 - val_loss: 0.6959 - val_acc: 0.6571\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.6688 - acc: 0.6444 - val_loss: 0.6941 - val_acc: 0.6429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6580 - acc: 0.6833 - val_loss: 0.6975 - val_acc: 0.5857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 138us/step - loss: 0.6536 - acc: 0.6667 - val_loss: 0.6942 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6557 - acc: 0.6556 - val_loss: 0.6935 - val_acc: 0.5714\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6566 - acc: 0.6611 - val_loss: 0.6946 - val_acc: 0.5857\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6398 - acc: 0.6889 - val_loss: 0.6929 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6645 - acc: 0.6056 - val_loss: 0.6950 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6373 - acc: 0.6889 - val_loss: 0.6932 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6437 - acc: 0.6556 - val_loss: 0.6900 - val_acc: 0.6286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6403 - acc: 0.6944 - val_loss: 0.6903 - val_acc: 0.6286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6425 - acc: 0.6889 - val_loss: 0.6936 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6321 - acc: 0.6944 - val_loss: 0.6894 - val_acc: 0.6143\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6403 - acc: 0.7000 - val_loss: 0.6866 - val_acc: 0.6429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6267 - acc: 0.7333 - val_loss: 0.6882 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6333 - acc: 0.7500 - val_loss: 0.6873 - val_acc: 0.6286\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6284 - acc: 0.7278 - val_loss: 0.6920 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6328 - acc: 0.6500 - val_loss: 0.6894 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6201 - acc: 0.7500 - val_loss: 0.6977 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6217 - acc: 0.6667 - val_loss: 0.6869 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6066 - acc: 0.7500 - val_loss: 0.6902 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6112 - acc: 0.7444 - val_loss: 0.6861 - val_acc: 0.6571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6180 - acc: 0.7111 - val_loss: 0.6898 - val_acc: 0.6286\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6207 - acc: 0.7111 - val_loss: 0.6877 - val_acc: 0.6429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6237 - acc: 0.7222 - val_loss: 0.6908 - val_acc: 0.6286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6057 - acc: 0.7500 - val_loss: 0.6847 - val_acc: 0.6571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6048 - acc: 0.7222 - val_loss: 0.6862 - val_acc: 0.6571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6058 - acc: 0.7333 - val_loss: 0.6827 - val_acc: 0.6571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6044 - acc: 0.7167 - val_loss: 0.6842 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5977 - acc: 0.7333 - val_loss: 0.6850 - val_acc: 0.6571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5957 - acc: 0.7444 - val_loss: 0.6783 - val_acc: 0.6571\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5968 - acc: 0.7278 - val_loss: 0.6836 - val_acc: 0.6429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5841 - acc: 0.7778 - val_loss: 0.6907 - val_acc: 0.6286\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5976 - acc: 0.7389 - val_loss: 0.6811 - val_acc: 0.6429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5891 - acc: 0.7222 - val_loss: 0.6914 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5860 - acc: 0.7389 - val_loss: 0.6897 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5905 - acc: 0.7278 - val_loss: 0.6875 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5786 - acc: 0.7500 - val_loss: 0.6846 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.5725 - acc: 0.7833 - val_loss: 0.6879 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5706 - acc: 0.7278 - val_loss: 0.6862 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5619 - acc: 0.7778 - val_loss: 0.6808 - val_acc: 0.6571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5591 - acc: 0.7778 - val_loss: 0.6832 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 118us/step - loss: 0.5646 - acc: 0.7833 - val_loss: 0.6881 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5825 - acc: 0.7167 - val_loss: 0.6809 - val_acc: 0.6714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5568 - acc: 0.7889 - val_loss: 0.6880 - val_acc: 0.6286\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5616 - acc: 0.7722 - val_loss: 0.6793 - val_acc: 0.6571\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5556 - acc: 0.7778 - val_loss: 0.6805 - val_acc: 0.6714\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5492 - acc: 0.7889 - val_loss: 0.6866 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5518 - acc: 0.7889 - val_loss: 0.6812 - val_acc: 0.6571\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5630 - acc: 0.7778 - val_loss: 0.6878 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.5547 - acc: 0.8056 - val_loss: 0.6842 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5350 - acc: 0.7944 - val_loss: 0.6841 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5367 - acc: 0.7889 - val_loss: 0.6874 - val_acc: 0.6429\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5422 - acc: 0.7611 - val_loss: 0.6792 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 162us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.9017 - acc: 0.4722 - val_loss: 0.8207 - val_acc: 0.4571\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.8204 - acc: 0.4500 - val_loss: 0.8063 - val_acc: 0.4429\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 113us/step - loss: 0.8036 - acc: 0.4833 - val_loss: 0.7991 - val_acc: 0.4286\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7933 - acc: 0.4722 - val_loss: 0.7930 - val_acc: 0.4143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7753 - acc: 0.4778 - val_loss: 0.7899 - val_acc: 0.3857\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7687 - acc: 0.4722 - val_loss: 0.7884 - val_acc: 0.4286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7669 - acc: 0.4389 - val_loss: 0.7883 - val_acc: 0.4714\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.7559 - acc: 0.4944 - val_loss: 0.7878 - val_acc: 0.4143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7648 - acc: 0.5111 - val_loss: 0.7851 - val_acc: 0.4571\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7502 - acc: 0.4833 - val_loss: 0.7835 - val_acc: 0.4286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7358 - acc: 0.5444 - val_loss: 0.7839 - val_acc: 0.4143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7398 - acc: 0.5556 - val_loss: 0.7835 - val_acc: 0.4143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7329 - acc: 0.5444 - val_loss: 0.7819 - val_acc: 0.4143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7354 - acc: 0.5389 - val_loss: 0.7792 - val_acc: 0.4143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7358 - acc: 0.5222 - val_loss: 0.7809 - val_acc: 0.4429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 121us/step - loss: 0.7297 - acc: 0.5278 - val_loss: 0.7806 - val_acc: 0.4571\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7347 - acc: 0.5333 - val_loss: 0.7823 - val_acc: 0.4571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7200 - acc: 0.5333 - val_loss: 0.7787 - val_acc: 0.4286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7215 - acc: 0.5667 - val_loss: 0.7806 - val_acc: 0.4571\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7295 - acc: 0.5667 - val_loss: 0.7810 - val_acc: 0.4714\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7203 - acc: 0.5889 - val_loss: 0.7842 - val_acc: 0.4857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7061 - acc: 0.5889 - val_loss: 0.7823 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7116 - acc: 0.5556 - val_loss: 0.7777 - val_acc: 0.4857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7253 - acc: 0.5222 - val_loss: 0.7754 - val_acc: 0.4571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 119us/step - loss: 0.7119 - acc: 0.5611 - val_loss: 0.7718 - val_acc: 0.4429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7204 - acc: 0.5667 - val_loss: 0.7703 - val_acc: 0.4571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7061 - acc: 0.5889 - val_loss: 0.7689 - val_acc: 0.4571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7091 - acc: 0.5833 - val_loss: 0.7673 - val_acc: 0.4571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7023 - acc: 0.6389 - val_loss: 0.7669 - val_acc: 0.4714\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6953 - acc: 0.6500 - val_loss: 0.7650 - val_acc: 0.4857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6890 - acc: 0.6333 - val_loss: 0.7647 - val_acc: 0.5000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7010 - acc: 0.6167 - val_loss: 0.7671 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6850 - acc: 0.6333 - val_loss: 0.7620 - val_acc: 0.4857\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6957 - acc: 0.6111 - val_loss: 0.7584 - val_acc: 0.4714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6969 - acc: 0.5944 - val_loss: 0.7602 - val_acc: 0.4857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6869 - acc: 0.6222 - val_loss: 0.7582 - val_acc: 0.4714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6828 - acc: 0.6333 - val_loss: 0.7585 - val_acc: 0.5000\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6952 - acc: 0.6000 - val_loss: 0.7556 - val_acc: 0.4714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6769 - acc: 0.6500 - val_loss: 0.7560 - val_acc: 0.5143\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6772 - acc: 0.6500 - val_loss: 0.7531 - val_acc: 0.4857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6782 - acc: 0.6333 - val_loss: 0.7528 - val_acc: 0.4857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6703 - acc: 0.6889 - val_loss: 0.7530 - val_acc: 0.5000\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6662 - acc: 0.6667 - val_loss: 0.7560 - val_acc: 0.5429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6780 - acc: 0.6222 - val_loss: 0.7512 - val_acc: 0.5000\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6551 - acc: 0.6778 - val_loss: 0.7480 - val_acc: 0.5000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6700 - acc: 0.6556 - val_loss: 0.7512 - val_acc: 0.5143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6618 - acc: 0.6500 - val_loss: 0.7507 - val_acc: 0.5143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6542 - acc: 0.6722 - val_loss: 0.7480 - val_acc: 0.5143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6482 - acc: 0.7000 - val_loss: 0.7488 - val_acc: 0.5143\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6535 - acc: 0.6611 - val_loss: 0.7512 - val_acc: 0.5286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6457 - acc: 0.6778 - val_loss: 0.7443 - val_acc: 0.5286\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6503 - acc: 0.6889 - val_loss: 0.7440 - val_acc: 0.5429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6405 - acc: 0.7000 - val_loss: 0.7432 - val_acc: 0.5143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6402 - acc: 0.7444 - val_loss: 0.7435 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6484 - acc: 0.7000 - val_loss: 0.7398 - val_acc: 0.5000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6434 - acc: 0.7222 - val_loss: 0.7382 - val_acc: 0.5000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6460 - acc: 0.6778 - val_loss: 0.7341 - val_acc: 0.5571\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6284 - acc: 0.7167 - val_loss: 0.7366 - val_acc: 0.5000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6364 - acc: 0.7333 - val_loss: 0.7321 - val_acc: 0.5571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6394 - acc: 0.7222 - val_loss: 0.7356 - val_acc: 0.5000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6250 - acc: 0.6833 - val_loss: 0.7330 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6303 - acc: 0.6778 - val_loss: 0.7330 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6191 - acc: 0.7500 - val_loss: 0.7310 - val_acc: 0.5714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6136 - acc: 0.7333 - val_loss: 0.7312 - val_acc: 0.5571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6205 - acc: 0.7500 - val_loss: 0.7328 - val_acc: 0.5571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6112 - acc: 0.7222 - val_loss: 0.7301 - val_acc: 0.5571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6146 - acc: 0.7500 - val_loss: 0.7307 - val_acc: 0.5571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6266 - acc: 0.7333 - val_loss: 0.7305 - val_acc: 0.5429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6029 - acc: 0.7500 - val_loss: 0.7356 - val_acc: 0.5286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6008 - acc: 0.7833 - val_loss: 0.7318 - val_acc: 0.5571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6086 - acc: 0.7389 - val_loss: 0.7347 - val_acc: 0.5429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 119us/step - loss: 0.6066 - acc: 0.7333 - val_loss: 0.7277 - val_acc: 0.5714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5847 - acc: 0.7778 - val_loss: 0.7329 - val_acc: 0.5571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5996 - acc: 0.7389 - val_loss: 0.7321 - val_acc: 0.5571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5981 - acc: 0.7389 - val_loss: 0.7305 - val_acc: 0.5714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5872 - acc: 0.7611 - val_loss: 0.7235 - val_acc: 0.5857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5957 - acc: 0.7000 - val_loss: 0.7319 - val_acc: 0.5571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5855 - acc: 0.7500 - val_loss: 0.7324 - val_acc: 0.5429\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5742 - acc: 0.7500 - val_loss: 0.7325 - val_acc: 0.5571\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5938 - acc: 0.7611 - val_loss: 0.7240 - val_acc: 0.5714\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.8187 - acc: 0.4611 - val_loss: 0.7606 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7686 - acc: 0.4722 - val_loss: 0.7500 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7588 - acc: 0.4778 - val_loss: 0.7445 - val_acc: 0.5143\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7515 - acc: 0.5000 - val_loss: 0.7403 - val_acc: 0.6000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7456 - acc: 0.4833 - val_loss: 0.7404 - val_acc: 0.5143\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7479 - acc: 0.5278 - val_loss: 0.7406 - val_acc: 0.5571\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7346 - acc: 0.5444 - val_loss: 0.7419 - val_acc: 0.5143\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7381 - acc: 0.5278 - val_loss: 0.7427 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7317 - acc: 0.5278 - val_loss: 0.7426 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7217 - acc: 0.5500 - val_loss: 0.7411 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7246 - acc: 0.5333 - val_loss: 0.7422 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7315 - acc: 0.5111 - val_loss: 0.7417 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7105 - acc: 0.5556 - val_loss: 0.7400 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7215 - acc: 0.5611 - val_loss: 0.7404 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 142us/step - loss: 0.7278 - acc: 0.5556 - val_loss: 0.7405 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7260 - acc: 0.5389 - val_loss: 0.7404 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7275 - acc: 0.5556 - val_loss: 0.7396 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7165 - acc: 0.5500 - val_loss: 0.7388 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7147 - acc: 0.5500 - val_loss: 0.7372 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7119 - acc: 0.5722 - val_loss: 0.7384 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7210 - acc: 0.5500 - val_loss: 0.7357 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7127 - acc: 0.5722 - val_loss: 0.7368 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7029 - acc: 0.5444 - val_loss: 0.7370 - val_acc: 0.5429\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7080 - acc: 0.5667 - val_loss: 0.7370 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.7060 - acc: 0.5722 - val_loss: 0.7368 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6983 - acc: 0.5944 - val_loss: 0.7356 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7004 - acc: 0.5889 - val_loss: 0.7328 - val_acc: 0.5286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7022 - acc: 0.5778 - val_loss: 0.7320 - val_acc: 0.5286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7037 - acc: 0.5667 - val_loss: 0.7344 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6914 - acc: 0.5667 - val_loss: 0.7338 - val_acc: 0.5286\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6946 - acc: 0.5889 - val_loss: 0.7349 - val_acc: 0.5286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6857 - acc: 0.6167 - val_loss: 0.7348 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6749 - acc: 0.6167 - val_loss: 0.7290 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6863 - acc: 0.6000 - val_loss: 0.7315 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6923 - acc: 0.5889 - val_loss: 0.7268 - val_acc: 0.5571\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6899 - acc: 0.6278 - val_loss: 0.7173 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6837 - acc: 0.5944 - val_loss: 0.7235 - val_acc: 0.5571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6831 - acc: 0.6167 - val_loss: 0.7241 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6713 - acc: 0.6500 - val_loss: 0.7208 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6878 - acc: 0.5889 - val_loss: 0.7247 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6759 - acc: 0.6278 - val_loss: 0.7180 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6554 - acc: 0.6500 - val_loss: 0.7207 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6840 - acc: 0.5556 - val_loss: 0.7219 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6743 - acc: 0.6000 - val_loss: 0.7087 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6671 - acc: 0.6333 - val_loss: 0.7086 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6635 - acc: 0.6333 - val_loss: 0.7097 - val_acc: 0.5714\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6471 - acc: 0.6944 - val_loss: 0.7055 - val_acc: 0.5714\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6643 - acc: 0.6500 - val_loss: 0.7023 - val_acc: 0.5429\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 105us/step - loss: 0.6610 - acc: 0.6111 - val_loss: 0.7047 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6646 - acc: 0.6500 - val_loss: 0.7064 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6530 - acc: 0.6778 - val_loss: 0.7086 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6457 - acc: 0.6500 - val_loss: 0.7010 - val_acc: 0.5571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6478 - acc: 0.6556 - val_loss: 0.7055 - val_acc: 0.5714\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6521 - acc: 0.6889 - val_loss: 0.7088 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6538 - acc: 0.6889 - val_loss: 0.6982 - val_acc: 0.5714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6502 - acc: 0.6667 - val_loss: 0.7053 - val_acc: 0.5429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6418 - acc: 0.6778 - val_loss: 0.7077 - val_acc: 0.5429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6287 - acc: 0.6944 - val_loss: 0.7126 - val_acc: 0.5571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6393 - acc: 0.6389 - val_loss: 0.6990 - val_acc: 0.5571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6286 - acc: 0.6889 - val_loss: 0.6934 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6265 - acc: 0.7500 - val_loss: 0.7013 - val_acc: 0.5571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6384 - acc: 0.6611 - val_loss: 0.6964 - val_acc: 0.5714\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6306 - acc: 0.7111 - val_loss: 0.6903 - val_acc: 0.6000\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6357 - acc: 0.6222 - val_loss: 0.6915 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6124 - acc: 0.7667 - val_loss: 0.7008 - val_acc: 0.5571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6102 - acc: 0.7111 - val_loss: 0.7010 - val_acc: 0.5571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6130 - acc: 0.7111 - val_loss: 0.6973 - val_acc: 0.5714\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6343 - acc: 0.6667 - val_loss: 0.6926 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6152 - acc: 0.7111 - val_loss: 0.6961 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6005 - acc: 0.7278 - val_loss: 0.6980 - val_acc: 0.5714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6220 - acc: 0.7000 - val_loss: 0.6978 - val_acc: 0.5714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5985 - acc: 0.7333 - val_loss: 0.7082 - val_acc: 0.5714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5946 - acc: 0.7333 - val_loss: 0.6917 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5947 - acc: 0.7389 - val_loss: 0.6921 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5839 - acc: 0.7556 - val_loss: 0.6935 - val_acc: 0.5714\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5970 - acc: 0.7333 - val_loss: 0.6919 - val_acc: 0.5857\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6035 - acc: 0.6889 - val_loss: 0.6892 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5973 - acc: 0.7000 - val_loss: 0.6920 - val_acc: 0.5857\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5894 - acc: 0.7111 - val_loss: 0.6894 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6127 - acc: 0.7222 - val_loss: 0.6896 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.8061 - acc: 0.5333 - val_loss: 0.7454 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7486 - acc: 0.5167 - val_loss: 0.7444 - val_acc: 0.5714\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7363 - acc: 0.5333 - val_loss: 0.7422 - val_acc: 0.5714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7299 - acc: 0.5500 - val_loss: 0.7453 - val_acc: 0.5571\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 138us/step - loss: 0.7300 - acc: 0.5722 - val_loss: 0.7445 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7086 - acc: 0.6167 - val_loss: 0.7470 - val_acc: 0.5429\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7233 - acc: 0.5500 - val_loss: 0.7447 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7175 - acc: 0.5778 - val_loss: 0.7447 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6993 - acc: 0.5722 - val_loss: 0.7379 - val_acc: 0.5857\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7049 - acc: 0.6000 - val_loss: 0.7417 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7001 - acc: 0.6000 - val_loss: 0.7434 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7060 - acc: 0.6056 - val_loss: 0.7339 - val_acc: 0.5714\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7091 - acc: 0.5944 - val_loss: 0.7306 - val_acc: 0.5857\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7060 - acc: 0.5778 - val_loss: 0.7346 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6913 - acc: 0.6111 - val_loss: 0.7289 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6915 - acc: 0.6056 - val_loss: 0.7273 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6926 - acc: 0.5944 - val_loss: 0.7265 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6684 - acc: 0.6444 - val_loss: 0.7230 - val_acc: 0.5857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6814 - acc: 0.6333 - val_loss: 0.7167 - val_acc: 0.6143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6912 - acc: 0.5667 - val_loss: 0.7150 - val_acc: 0.6286\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6751 - acc: 0.6444 - val_loss: 0.7148 - val_acc: 0.6286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6797 - acc: 0.6611 - val_loss: 0.7214 - val_acc: 0.5857\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6686 - acc: 0.6611 - val_loss: 0.7211 - val_acc: 0.5857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6896 - acc: 0.6056 - val_loss: 0.7246 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6584 - acc: 0.6889 - val_loss: 0.7210 - val_acc: 0.5857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6729 - acc: 0.6167 - val_loss: 0.7162 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6653 - acc: 0.6667 - val_loss: 0.7094 - val_acc: 0.6286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6690 - acc: 0.6778 - val_loss: 0.7050 - val_acc: 0.6571\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 122us/step - loss: 0.6576 - acc: 0.7056 - val_loss: 0.7103 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6600 - acc: 0.6222 - val_loss: 0.7086 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6621 - acc: 0.6778 - val_loss: 0.7111 - val_acc: 0.6000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6482 - acc: 0.6833 - val_loss: 0.7108 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6714 - acc: 0.5944 - val_loss: 0.7028 - val_acc: 0.6286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6378 - acc: 0.7056 - val_loss: 0.7021 - val_acc: 0.6429\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6525 - acc: 0.6722 - val_loss: 0.7117 - val_acc: 0.6143\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6280 - acc: 0.6944 - val_loss: 0.7040 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6544 - acc: 0.6611 - val_loss: 0.6972 - val_acc: 0.6571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6402 - acc: 0.6722 - val_loss: 0.6950 - val_acc: 0.6571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6259 - acc: 0.6889 - val_loss: 0.6970 - val_acc: 0.6571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6388 - acc: 0.6833 - val_loss: 0.6994 - val_acc: 0.6429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6482 - acc: 0.6611 - val_loss: 0.7005 - val_acc: 0.6286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6389 - acc: 0.6889 - val_loss: 0.6894 - val_acc: 0.6714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6360 - acc: 0.6778 - val_loss: 0.7010 - val_acc: 0.6143\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6158 - acc: 0.7111 - val_loss: 0.6994 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6298 - acc: 0.6778 - val_loss: 0.7013 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6225 - acc: 0.7056 - val_loss: 0.7002 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6016 - acc: 0.6944 - val_loss: 0.6995 - val_acc: 0.6143\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6203 - acc: 0.7278 - val_loss: 0.6868 - val_acc: 0.6714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6054 - acc: 0.7222 - val_loss: 0.6878 - val_acc: 0.6714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6052 - acc: 0.7056 - val_loss: 0.6843 - val_acc: 0.6714\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5995 - acc: 0.7389 - val_loss: 0.6853 - val_acc: 0.6714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6118 - acc: 0.7056 - val_loss: 0.6880 - val_acc: 0.6571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5977 - acc: 0.7389 - val_loss: 0.6838 - val_acc: 0.6714\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6067 - acc: 0.7500 - val_loss: 0.6884 - val_acc: 0.6714\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5892 - acc: 0.7333 - val_loss: 0.6904 - val_acc: 0.6714\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5898 - acc: 0.7167 - val_loss: 0.6833 - val_acc: 0.6714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5818 - acc: 0.7611 - val_loss: 0.6881 - val_acc: 0.6714\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5851 - acc: 0.7222 - val_loss: 0.6859 - val_acc: 0.6714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5997 - acc: 0.7389 - val_loss: 0.6765 - val_acc: 0.6857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5972 - acc: 0.7278 - val_loss: 0.6864 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5754 - acc: 0.7389 - val_loss: 0.6785 - val_acc: 0.6857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5562 - acc: 0.7611 - val_loss: 0.6750 - val_acc: 0.6857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5824 - acc: 0.7556 - val_loss: 0.6885 - val_acc: 0.6714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5559 - acc: 0.7944 - val_loss: 0.6796 - val_acc: 0.6857\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5696 - acc: 0.7444 - val_loss: 0.6748 - val_acc: 0.6857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5694 - acc: 0.7833 - val_loss: 0.6804 - val_acc: 0.6857\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5842 - acc: 0.7389 - val_loss: 0.6803 - val_acc: 0.6857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5591 - acc: 0.7722 - val_loss: 0.6783 - val_acc: 0.6857\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5597 - acc: 0.7722 - val_loss: 0.6813 - val_acc: 0.6857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5509 - acc: 0.7500 - val_loss: 0.6883 - val_acc: 0.6571\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5652 - acc: 0.7611 - val_loss: 0.6923 - val_acc: 0.6571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.5613 - acc: 0.7389 - val_loss: 0.6815 - val_acc: 0.6857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5570 - acc: 0.7444 - val_loss: 0.6744 - val_acc: 0.6857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5553 - acc: 0.7833 - val_loss: 0.6798 - val_acc: 0.6714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5529 - acc: 0.7611 - val_loss: 0.6899 - val_acc: 0.6571\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5377 - acc: 0.7833 - val_loss: 0.6821 - val_acc: 0.6714\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5443 - acc: 0.7778 - val_loss: 0.6753 - val_acc: 0.6857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5447 - acc: 0.7667 - val_loss: 0.6893 - val_acc: 0.6571\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5295 - acc: 0.7889 - val_loss: 0.6823 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5452 - acc: 0.7500 - val_loss: 0.6764 - val_acc: 0.6857\n",
      "80/80 [==============================] - 0s 175us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 28ms/step - loss: 0.7801 - acc: 0.4500 - val_loss: 0.8047 - val_acc: 0.5286\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.7638 - acc: 0.5278 - val_loss: 0.7800 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.7660 - acc: 0.5167 - val_loss: 0.7851 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7550 - acc: 0.5278 - val_loss: 0.7804 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7482 - acc: 0.5167 - val_loss: 0.7705 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7367 - acc: 0.5222 - val_loss: 0.7659 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7326 - acc: 0.5389 - val_loss: 0.7713 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7173 - acc: 0.5778 - val_loss: 0.7690 - val_acc: 0.5000\n",
      "Epoch 9/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/step - loss: 0.7261 - acc: 0.5556 - val_loss: 0.7728 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7272 - acc: 0.5500 - val_loss: 0.7662 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7167 - acc: 0.5778 - val_loss: 0.7586 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7071 - acc: 0.5611 - val_loss: 0.7541 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7148 - acc: 0.5556 - val_loss: 0.7536 - val_acc: 0.5143\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.7201 - acc: 0.5778 - val_loss: 0.7523 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6958 - acc: 0.6111 - val_loss: 0.7566 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7073 - acc: 0.5944 - val_loss: 0.7559 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7009 - acc: 0.5611 - val_loss: 0.7516 - val_acc: 0.5286\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6898 - acc: 0.5833 - val_loss: 0.7460 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6919 - acc: 0.6000 - val_loss: 0.7468 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6889 - acc: 0.6000 - val_loss: 0.7515 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6781 - acc: 0.6389 - val_loss: 0.7490 - val_acc: 0.5286\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6956 - acc: 0.6278 - val_loss: 0.7460 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7047 - acc: 0.5944 - val_loss: 0.7416 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6769 - acc: 0.6444 - val_loss: 0.7442 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6771 - acc: 0.6611 - val_loss: 0.7410 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6677 - acc: 0.6667 - val_loss: 0.7410 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6605 - acc: 0.6889 - val_loss: 0.7396 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6533 - acc: 0.6667 - val_loss: 0.7349 - val_acc: 0.5286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6711 - acc: 0.6667 - val_loss: 0.7351 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6752 - acc: 0.6889 - val_loss: 0.7305 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6522 - acc: 0.7056 - val_loss: 0.7307 - val_acc: 0.5143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6432 - acc: 0.7444 - val_loss: 0.7330 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6544 - acc: 0.7333 - val_loss: 0.7288 - val_acc: 0.5000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6556 - acc: 0.7000 - val_loss: 0.7289 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6483 - acc: 0.6889 - val_loss: 0.7263 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6306 - acc: 0.7333 - val_loss: 0.7272 - val_acc: 0.5286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6210 - acc: 0.7889 - val_loss: 0.7371 - val_acc: 0.5714\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6340 - acc: 0.7056 - val_loss: 0.7297 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6316 - acc: 0.7056 - val_loss: 0.7287 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6440 - acc: 0.7389 - val_loss: 0.7207 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6301 - acc: 0.7278 - val_loss: 0.7268 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6278 - acc: 0.7222 - val_loss: 0.7242 - val_acc: 0.5714\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6145 - acc: 0.7611 - val_loss: 0.7219 - val_acc: 0.5714\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6244 - acc: 0.7333 - val_loss: 0.7152 - val_acc: 0.5571\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6141 - acc: 0.7500 - val_loss: 0.7216 - val_acc: 0.5714\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6234 - acc: 0.7167 - val_loss: 0.7172 - val_acc: 0.5429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6077 - acc: 0.7722 - val_loss: 0.7146 - val_acc: 0.5571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6140 - acc: 0.7556 - val_loss: 0.7152 - val_acc: 0.5714\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5996 - acc: 0.7333 - val_loss: 0.7155 - val_acc: 0.5857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5952 - acc: 0.7722 - val_loss: 0.7128 - val_acc: 0.5857\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.6022 - acc: 0.7500 - val_loss: 0.7072 - val_acc: 0.5429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6024 - acc: 0.7667 - val_loss: 0.7095 - val_acc: 0.5714\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5908 - acc: 0.7722 - val_loss: 0.7090 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5913 - acc: 0.7722 - val_loss: 0.7053 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6092 - acc: 0.7500 - val_loss: 0.7098 - val_acc: 0.6000\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 118us/step - loss: 0.6008 - acc: 0.7444 - val_loss: 0.7197 - val_acc: 0.6000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5827 - acc: 0.7778 - val_loss: 0.7137 - val_acc: 0.5857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5840 - acc: 0.7500 - val_loss: 0.7161 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5811 - acc: 0.7722 - val_loss: 0.7054 - val_acc: 0.5714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5949 - acc: 0.7389 - val_loss: 0.7077 - val_acc: 0.5857\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5834 - acc: 0.7778 - val_loss: 0.7077 - val_acc: 0.5857\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5665 - acc: 0.7611 - val_loss: 0.7091 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5697 - acc: 0.7889 - val_loss: 0.7036 - val_acc: 0.5429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5851 - acc: 0.7278 - val_loss: 0.7078 - val_acc: 0.6000\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5802 - acc: 0.7667 - val_loss: 0.7066 - val_acc: 0.5714\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5950 - acc: 0.7500 - val_loss: 0.7084 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5607 - acc: 0.7889 - val_loss: 0.7064 - val_acc: 0.5429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5488 - acc: 0.7889 - val_loss: 0.7073 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5394 - acc: 0.8056 - val_loss: 0.7102 - val_acc: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5583 - acc: 0.7778 - val_loss: 0.7083 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5570 - acc: 0.7722 - val_loss: 0.7082 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5688 - acc: 0.7778 - val_loss: 0.7112 - val_acc: 0.6143\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5420 - acc: 0.7889 - val_loss: 0.7100 - val_acc: 0.6143\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5482 - acc: 0.7667 - val_loss: 0.7220 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5504 - acc: 0.7667 - val_loss: 0.7110 - val_acc: 0.6143\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5192 - acc: 0.8056 - val_loss: 0.7191 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5292 - acc: 0.7611 - val_loss: 0.7143 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5384 - acc: 0.7889 - val_loss: 0.7123 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5230 - acc: 0.8056 - val_loss: 0.7111 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5201 - acc: 0.7889 - val_loss: 0.7139 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 162us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 28ms/step - loss: 0.9920 - acc: 0.4611 - val_loss: 0.8385 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.8947 - acc: 0.4611 - val_loss: 0.8093 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.8675 - acc: 0.4556 - val_loss: 0.7879 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.8176 - acc: 0.4667 - val_loss: 0.7747 - val_acc: 0.4857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.8179 - acc: 0.4778 - val_loss: 0.7673 - val_acc: 0.4571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.7999 - acc: 0.4278 - val_loss: 0.7603 - val_acc: 0.4000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7654 - acc: 0.4944 - val_loss: 0.7558 - val_acc: 0.4429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7679 - acc: 0.4722 - val_loss: 0.7516 - val_acc: 0.5571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7531 - acc: 0.5333 - val_loss: 0.7488 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7637 - acc: 0.4889 - val_loss: 0.7460 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 119us/step - loss: 0.7380 - acc: 0.5611 - val_loss: 0.7435 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7387 - acc: 0.5500 - val_loss: 0.7434 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7299 - acc: 0.5778 - val_loss: 0.7444 - val_acc: 0.5286\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7272 - acc: 0.5889 - val_loss: 0.7441 - val_acc: 0.5286\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.7327 - acc: 0.5778 - val_loss: 0.7435 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 183us/step - loss: 0.7214 - acc: 0.5833 - val_loss: 0.7428 - val_acc: 0.4857\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7221 - acc: 0.6056 - val_loss: 0.7435 - val_acc: 0.4857\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7158 - acc: 0.6111 - val_loss: 0.7427 - val_acc: 0.4857\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7101 - acc: 0.6111 - val_loss: 0.7424 - val_acc: 0.4857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7189 - acc: 0.5889 - val_loss: 0.7435 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7130 - acc: 0.5944 - val_loss: 0.7447 - val_acc: 0.4857\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7183 - acc: 0.5722 - val_loss: 0.7451 - val_acc: 0.4857\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.7037 - acc: 0.6167 - val_loss: 0.7449 - val_acc: 0.4857\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7009 - acc: 0.5944 - val_loss: 0.7443 - val_acc: 0.4857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7070 - acc: 0.5778 - val_loss: 0.7442 - val_acc: 0.4857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.7001 - acc: 0.6056 - val_loss: 0.7434 - val_acc: 0.4857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7016 - acc: 0.5944 - val_loss: 0.7406 - val_acc: 0.4857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7111 - acc: 0.6000 - val_loss: 0.7426 - val_acc: 0.4857\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6982 - acc: 0.6000 - val_loss: 0.7431 - val_acc: 0.4857\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6985 - acc: 0.5944 - val_loss: 0.7434 - val_acc: 0.4857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6924 - acc: 0.6167 - val_loss: 0.7384 - val_acc: 0.5143\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6895 - acc: 0.6056 - val_loss: 0.7393 - val_acc: 0.5143\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7013 - acc: 0.6111 - val_loss: 0.7386 - val_acc: 0.5286\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6878 - acc: 0.6556 - val_loss: 0.7376 - val_acc: 0.5143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6775 - acc: 0.6667 - val_loss: 0.7372 - val_acc: 0.5286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6878 - acc: 0.6667 - val_loss: 0.7335 - val_acc: 0.4857\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6754 - acc: 0.6333 - val_loss: 0.7296 - val_acc: 0.5286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6624 - acc: 0.6667 - val_loss: 0.7339 - val_acc: 0.5143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6673 - acc: 0.6667 - val_loss: 0.7311 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6737 - acc: 0.6278 - val_loss: 0.7268 - val_acc: 0.5429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6572 - acc: 0.7278 - val_loss: 0.7261 - val_acc: 0.5429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6686 - acc: 0.6833 - val_loss: 0.7276 - val_acc: 0.5429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6529 - acc: 0.7000 - val_loss: 0.7258 - val_acc: 0.5429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6629 - acc: 0.7056 - val_loss: 0.7252 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6656 - acc: 0.6778 - val_loss: 0.7241 - val_acc: 0.5429\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6649 - acc: 0.6611 - val_loss: 0.7215 - val_acc: 0.5286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6507 - acc: 0.6944 - val_loss: 0.7239 - val_acc: 0.5429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6555 - acc: 0.6722 - val_loss: 0.7244 - val_acc: 0.5429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6584 - acc: 0.6722 - val_loss: 0.7287 - val_acc: 0.5286\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.6516 - acc: 0.6833 - val_loss: 0.7234 - val_acc: 0.5429\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6411 - acc: 0.7111 - val_loss: 0.7274 - val_acc: 0.5429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6513 - acc: 0.6722 - val_loss: 0.7235 - val_acc: 0.5429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6607 - acc: 0.6611 - val_loss: 0.7284 - val_acc: 0.5429\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6488 - acc: 0.6667 - val_loss: 0.7247 - val_acc: 0.5429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6372 - acc: 0.7056 - val_loss: 0.7192 - val_acc: 0.5571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6191 - acc: 0.6889 - val_loss: 0.7191 - val_acc: 0.5714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6344 - acc: 0.7111 - val_loss: 0.7180 - val_acc: 0.5571\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6399 - acc: 0.7500 - val_loss: 0.7144 - val_acc: 0.5714\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6280 - acc: 0.7111 - val_loss: 0.7198 - val_acc: 0.5571\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6370 - acc: 0.6889 - val_loss: 0.7237 - val_acc: 0.5429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6278 - acc: 0.7000 - val_loss: 0.7279 - val_acc: 0.5429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6270 - acc: 0.7222 - val_loss: 0.7224 - val_acc: 0.5571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 112us/step - loss: 0.6104 - acc: 0.7500 - val_loss: 0.7186 - val_acc: 0.5714\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6267 - acc: 0.7111 - val_loss: 0.7211 - val_acc: 0.5571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6131 - acc: 0.7000 - val_loss: 0.7249 - val_acc: 0.5429\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6143 - acc: 0.6944 - val_loss: 0.7254 - val_acc: 0.5571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6109 - acc: 0.7444 - val_loss: 0.7277 - val_acc: 0.5429\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 118us/step - loss: 0.5964 - acc: 0.7667 - val_loss: 0.7210 - val_acc: 0.5714\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6045 - acc: 0.7278 - val_loss: 0.7167 - val_acc: 0.5571\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6160 - acc: 0.7056 - val_loss: 0.7135 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6074 - acc: 0.7500 - val_loss: 0.7176 - val_acc: 0.5571\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 112us/step - loss: 0.5932 - acc: 0.7611 - val_loss: 0.7159 - val_acc: 0.5857\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5873 - acc: 0.7556 - val_loss: 0.7144 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5986 - acc: 0.7333 - val_loss: 0.7221 - val_acc: 0.5571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5734 - acc: 0.7944 - val_loss: 0.7148 - val_acc: 0.5857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 118us/step - loss: 0.5870 - acc: 0.7389 - val_loss: 0.7137 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5904 - acc: 0.7167 - val_loss: 0.7112 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5722 - acc: 0.7389 - val_loss: 0.7197 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5788 - acc: 0.7333 - val_loss: 0.7122 - val_acc: 0.5857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5587 - acc: 0.7500 - val_loss: 0.7104 - val_acc: 0.6143\n",
      "80/80 [==============================] - 0s 170us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 28ms/step - loss: 0.7612 - acc: 0.5389 - val_loss: 0.7731 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7501 - acc: 0.5222 - val_loss: 0.7702 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7402 - acc: 0.5222 - val_loss: 0.7654 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7323 - acc: 0.5444 - val_loss: 0.7626 - val_acc: 0.4857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7389 - acc: 0.5167 - val_loss: 0.7616 - val_acc: 0.4714\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7316 - acc: 0.5667 - val_loss: 0.7601 - val_acc: 0.4714\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7208 - acc: 0.5889 - val_loss: 0.7562 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7243 - acc: 0.5500 - val_loss: 0.7562 - val_acc: 0.5143\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7121 - acc: 0.5722 - val_loss: 0.7539 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7138 - acc: 0.5833 - val_loss: 0.7534 - val_acc: 0.5143\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7219 - acc: 0.5444 - val_loss: 0.7515 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7120 - acc: 0.5556 - val_loss: 0.7521 - val_acc: 0.5143\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7118 - acc: 0.5778 - val_loss: 0.7504 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7073 - acc: 0.5833 - val_loss: 0.7479 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6916 - acc: 0.6333 - val_loss: 0.7465 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6971 - acc: 0.5667 - val_loss: 0.7513 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7025 - acc: 0.5778 - val_loss: 0.7481 - val_acc: 0.5571\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6908 - acc: 0.6167 - val_loss: 0.7508 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7035 - acc: 0.5500 - val_loss: 0.7503 - val_acc: 0.5429\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6946 - acc: 0.5833 - val_loss: 0.7477 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6892 - acc: 0.5889 - val_loss: 0.7449 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6798 - acc: 0.6500 - val_loss: 0.7480 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6936 - acc: 0.5944 - val_loss: 0.7469 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6805 - acc: 0.6111 - val_loss: 0.7453 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6827 - acc: 0.5944 - val_loss: 0.7442 - val_acc: 0.5429\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6889 - acc: 0.6000 - val_loss: 0.7417 - val_acc: 0.5571\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6774 - acc: 0.6444 - val_loss: 0.7406 - val_acc: 0.5571\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6662 - acc: 0.7222 - val_loss: 0.7424 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6763 - acc: 0.6389 - val_loss: 0.7443 - val_acc: 0.5571\n",
      "Epoch 30/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/step - loss: 0.6667 - acc: 0.6222 - val_loss: 0.7424 - val_acc: 0.5571\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6752 - acc: 0.6611 - val_loss: 0.7407 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6768 - acc: 0.6444 - val_loss: 0.7418 - val_acc: 0.5571\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6702 - acc: 0.6500 - val_loss: 0.7400 - val_acc: 0.5571\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6656 - acc: 0.6778 - val_loss: 0.7369 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6671 - acc: 0.6722 - val_loss: 0.7334 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6569 - acc: 0.6722 - val_loss: 0.7329 - val_acc: 0.6143\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6538 - acc: 0.7056 - val_loss: 0.7350 - val_acc: 0.5571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6471 - acc: 0.6833 - val_loss: 0.7367 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6505 - acc: 0.6833 - val_loss: 0.7389 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6521 - acc: 0.6833 - val_loss: 0.7356 - val_acc: 0.6000\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6455 - acc: 0.7000 - val_loss: 0.7367 - val_acc: 0.5857\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6441 - acc: 0.6833 - val_loss: 0.7333 - val_acc: 0.6143\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6537 - acc: 0.7167 - val_loss: 0.7308 - val_acc: 0.6286\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6470 - acc: 0.7056 - val_loss: 0.7343 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6428 - acc: 0.6833 - val_loss: 0.7359 - val_acc: 0.6000\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6442 - acc: 0.7056 - val_loss: 0.7382 - val_acc: 0.5571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6317 - acc: 0.7111 - val_loss: 0.7319 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6326 - acc: 0.7111 - val_loss: 0.7315 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6341 - acc: 0.7500 - val_loss: 0.7290 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6245 - acc: 0.7389 - val_loss: 0.7339 - val_acc: 0.6286\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6274 - acc: 0.7444 - val_loss: 0.7305 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6213 - acc: 0.7333 - val_loss: 0.7261 - val_acc: 0.6286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6099 - acc: 0.7556 - val_loss: 0.7302 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6142 - acc: 0.7556 - val_loss: 0.7310 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6079 - acc: 0.7444 - val_loss: 0.7313 - val_acc: 0.6286\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6204 - acc: 0.7222 - val_loss: 0.7302 - val_acc: 0.6286\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6143 - acc: 0.7556 - val_loss: 0.7282 - val_acc: 0.6429\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6180 - acc: 0.7222 - val_loss: 0.7266 - val_acc: 0.6286\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6153 - acc: 0.7278 - val_loss: 0.7238 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5999 - acc: 0.8056 - val_loss: 0.7248 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5871 - acc: 0.7833 - val_loss: 0.7264 - val_acc: 0.6571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 136us/step - loss: 0.6085 - acc: 0.7722 - val_loss: 0.7241 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6024 - acc: 0.7500 - val_loss: 0.7272 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5811 - acc: 0.8222 - val_loss: 0.7286 - val_acc: 0.6429\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 166us/step - loss: 0.5792 - acc: 0.7833 - val_loss: 0.7254 - val_acc: 0.6286\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 161us/step - loss: 0.5907 - acc: 0.7778 - val_loss: 0.7314 - val_acc: 0.6429\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5847 - acc: 0.7833 - val_loss: 0.7269 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5794 - acc: 0.7611 - val_loss: 0.7275 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 125us/step - loss: 0.5725 - acc: 0.7722 - val_loss: 0.7332 - val_acc: 0.6429\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5706 - acc: 0.7778 - val_loss: 0.7274 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5791 - acc: 0.7556 - val_loss: 0.7284 - val_acc: 0.6429\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5668 - acc: 0.7778 - val_loss: 0.7290 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5669 - acc: 0.7611 - val_loss: 0.7358 - val_acc: 0.6429\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5676 - acc: 0.7667 - val_loss: 0.7330 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5556 - acc: 0.7667 - val_loss: 0.7386 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5538 - acc: 0.7722 - val_loss: 0.7320 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5734 - acc: 0.8056 - val_loss: 0.7315 - val_acc: 0.6429\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5409 - acc: 0.8167 - val_loss: 0.7350 - val_acc: 0.6286\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5559 - acc: 0.7500 - val_loss: 0.7296 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5414 - acc: 0.8056 - val_loss: 0.7272 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 28ms/step - loss: 0.7539 - acc: 0.5278 - val_loss: 0.7463 - val_acc: 0.5429\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7410 - acc: 0.5167 - val_loss: 0.7419 - val_acc: 0.5286\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7299 - acc: 0.5333 - val_loss: 0.7387 - val_acc: 0.5429\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7279 - acc: 0.5000 - val_loss: 0.7380 - val_acc: 0.5429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7236 - acc: 0.5278 - val_loss: 0.7362 - val_acc: 0.5571\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7164 - acc: 0.5333 - val_loss: 0.7341 - val_acc: 0.5429\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7205 - acc: 0.5500 - val_loss: 0.7319 - val_acc: 0.5286\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7227 - acc: 0.5556 - val_loss: 0.7294 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 108us/step - loss: 0.7140 - acc: 0.5500 - val_loss: 0.7243 - val_acc: 0.5429\n",
      "Epoch 10/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/step - loss: 0.7042 - acc: 0.5556 - val_loss: 0.7258 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7090 - acc: 0.5722 - val_loss: 0.7209 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7040 - acc: 0.5667 - val_loss: 0.7189 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7016 - acc: 0.5500 - val_loss: 0.7149 - val_acc: 0.5429\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.6935 - acc: 0.5833 - val_loss: 0.7159 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6981 - acc: 0.5556 - val_loss: 0.7132 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6894 - acc: 0.5889 - val_loss: 0.7117 - val_acc: 0.5714\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6907 - acc: 0.5944 - val_loss: 0.7127 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6887 - acc: 0.5667 - val_loss: 0.7116 - val_acc: 0.5571\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6958 - acc: 0.5667 - val_loss: 0.7065 - val_acc: 0.5714\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6890 - acc: 0.6000 - val_loss: 0.7034 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6828 - acc: 0.5722 - val_loss: 0.7032 - val_acc: 0.5714\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6743 - acc: 0.6000 - val_loss: 0.7047 - val_acc: 0.5714\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6820 - acc: 0.5944 - val_loss: 0.7038 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6660 - acc: 0.6111 - val_loss: 0.7042 - val_acc: 0.5571\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6743 - acc: 0.5722 - val_loss: 0.7010 - val_acc: 0.5571\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6715 - acc: 0.6111 - val_loss: 0.6976 - val_acc: 0.5857\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6724 - acc: 0.6222 - val_loss: 0.6965 - val_acc: 0.5857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6652 - acc: 0.6278 - val_loss: 0.6939 - val_acc: 0.6000\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6589 - acc: 0.6722 - val_loss: 0.6947 - val_acc: 0.6000\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6435 - acc: 0.6944 - val_loss: 0.6938 - val_acc: 0.5857\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6515 - acc: 0.6722 - val_loss: 0.6904 - val_acc: 0.6429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6411 - acc: 0.7056 - val_loss: 0.6915 - val_acc: 0.6000\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6413 - acc: 0.7000 - val_loss: 0.6921 - val_acc: 0.6000\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6428 - acc: 0.6667 - val_loss: 0.6899 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6471 - acc: 0.6667 - val_loss: 0.6861 - val_acc: 0.6286\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6425 - acc: 0.7000 - val_loss: 0.6848 - val_acc: 0.6571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6457 - acc: 0.6833 - val_loss: 0.6867 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6424 - acc: 0.6389 - val_loss: 0.6841 - val_acc: 0.6143\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6241 - acc: 0.7278 - val_loss: 0.6842 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6333 - acc: 0.6722 - val_loss: 0.6798 - val_acc: 0.6286\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6203 - acc: 0.6944 - val_loss: 0.6771 - val_acc: 0.6714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6399 - acc: 0.6667 - val_loss: 0.6790 - val_acc: 0.6429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6348 - acc: 0.6556 - val_loss: 0.6784 - val_acc: 0.6571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6266 - acc: 0.7056 - val_loss: 0.6786 - val_acc: 0.6286\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6073 - acc: 0.7056 - val_loss: 0.6818 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6154 - acc: 0.6833 - val_loss: 0.6807 - val_acc: 0.6286\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6160 - acc: 0.7167 - val_loss: 0.6791 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6199 - acc: 0.7056 - val_loss: 0.6779 - val_acc: 0.6571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6042 - acc: 0.7222 - val_loss: 0.6705 - val_acc: 0.6857\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6109 - acc: 0.7111 - val_loss: 0.6688 - val_acc: 0.6571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6103 - acc: 0.7167 - val_loss: 0.6676 - val_acc: 0.6571\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6079 - acc: 0.7333 - val_loss: 0.6687 - val_acc: 0.6571\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5974 - acc: 0.7444 - val_loss: 0.6711 - val_acc: 0.6714\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6039 - acc: 0.6778 - val_loss: 0.6661 - val_acc: 0.6571\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5894 - acc: 0.7667 - val_loss: 0.6702 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5861 - acc: 0.7222 - val_loss: 0.6661 - val_acc: 0.6429\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6001 - acc: 0.7167 - val_loss: 0.6635 - val_acc: 0.6857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5890 - acc: 0.7500 - val_loss: 0.6672 - val_acc: 0.6571\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5891 - acc: 0.7556 - val_loss: 0.6629 - val_acc: 0.6714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5748 - acc: 0.7944 - val_loss: 0.6614 - val_acc: 0.6714\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5642 - acc: 0.7889 - val_loss: 0.6613 - val_acc: 0.6571\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5712 - acc: 0.7944 - val_loss: 0.6659 - val_acc: 0.6571\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5809 - acc: 0.7389 - val_loss: 0.6594 - val_acc: 0.6429\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5557 - acc: 0.7944 - val_loss: 0.6601 - val_acc: 0.6571\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5655 - acc: 0.7667 - val_loss: 0.6596 - val_acc: 0.6571\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5763 - acc: 0.7389 - val_loss: 0.6582 - val_acc: 0.6571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5663 - acc: 0.7389 - val_loss: 0.6576 - val_acc: 0.6571\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5720 - acc: 0.7611 - val_loss: 0.6628 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5641 - acc: 0.7778 - val_loss: 0.6637 - val_acc: 0.6429\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5444 - acc: 0.7944 - val_loss: 0.6611 - val_acc: 0.6571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5601 - acc: 0.7944 - val_loss: 0.6581 - val_acc: 0.6714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5519 - acc: 0.7778 - val_loss: 0.6574 - val_acc: 0.6714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5398 - acc: 0.8056 - val_loss: 0.6571 - val_acc: 0.6571\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5428 - acc: 0.8111 - val_loss: 0.6677 - val_acc: 0.6429\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5470 - acc: 0.7944 - val_loss: 0.6584 - val_acc: 0.6857\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5490 - acc: 0.7778 - val_loss: 0.6622 - val_acc: 0.6429\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5326 - acc: 0.8056 - val_loss: 0.6588 - val_acc: 0.6857\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5248 - acc: 0.8389 - val_loss: 0.6617 - val_acc: 0.6714\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 113us/step - loss: 0.5495 - acc: 0.7611 - val_loss: 0.6631 - val_acc: 0.6714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5375 - acc: 0.7944 - val_loss: 0.6682 - val_acc: 0.6571\n",
      "80/80 [==============================] - 0s 162us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 30ms/step - loss: 0.7377 - acc: 0.5389 - val_loss: 0.7482 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7350 - acc: 0.5389 - val_loss: 0.7462 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7316 - acc: 0.5444 - val_loss: 0.7429 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7297 - acc: 0.5389 - val_loss: 0.7409 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7199 - acc: 0.5500 - val_loss: 0.7390 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7219 - acc: 0.5500 - val_loss: 0.7371 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7239 - acc: 0.5333 - val_loss: 0.7360 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7080 - acc: 0.5389 - val_loss: 0.7359 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7167 - acc: 0.5444 - val_loss: 0.7355 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 128us/step - loss: 0.7160 - acc: 0.5389 - val_loss: 0.7365 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7129 - acc: 0.5500 - val_loss: 0.7346 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7125 - acc: 0.5500 - val_loss: 0.7340 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7023 - acc: 0.5444 - val_loss: 0.7317 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 136us/step - loss: 0.7047 - acc: 0.5444 - val_loss: 0.7301 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7022 - acc: 0.5500 - val_loss: 0.7294 - val_acc: 0.5143\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7025 - acc: 0.5389 - val_loss: 0.7299 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6883 - acc: 0.5500 - val_loss: 0.7297 - val_acc: 0.5143\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6973 - acc: 0.5556 - val_loss: 0.7302 - val_acc: 0.5143\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6857 - acc: 0.5278 - val_loss: 0.7283 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6927 - acc: 0.5333 - val_loss: 0.7272 - val_acc: 0.5143\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6883 - acc: 0.5556 - val_loss: 0.7274 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6876 - acc: 0.5722 - val_loss: 0.7287 - val_acc: 0.5286\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6840 - acc: 0.5667 - val_loss: 0.7290 - val_acc: 0.5286\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6785 - acc: 0.5556 - val_loss: 0.7263 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.6856 - acc: 0.5556 - val_loss: 0.7230 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6755 - acc: 0.5944 - val_loss: 0.7212 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6780 - acc: 0.6056 - val_loss: 0.7219 - val_acc: 0.5286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6746 - acc: 0.5833 - val_loss: 0.7191 - val_acc: 0.5286\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 177us/step - loss: 0.6691 - acc: 0.5833 - val_loss: 0.7205 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6753 - acc: 0.6222 - val_loss: 0.7216 - val_acc: 0.5429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6679 - acc: 0.6056 - val_loss: 0.7165 - val_acc: 0.5429\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6688 - acc: 0.6111 - val_loss: 0.7158 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6547 - acc: 0.6222 - val_loss: 0.7148 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 138us/step - loss: 0.6585 - acc: 0.6167 - val_loss: 0.7161 - val_acc: 0.5571\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6524 - acc: 0.6222 - val_loss: 0.7126 - val_acc: 0.5429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6533 - acc: 0.6444 - val_loss: 0.7134 - val_acc: 0.5429\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6543 - acc: 0.6222 - val_loss: 0.7138 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6489 - acc: 0.6222 - val_loss: 0.7122 - val_acc: 0.5429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6475 - acc: 0.6722 - val_loss: 0.7143 - val_acc: 0.5429\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6580 - acc: 0.6556 - val_loss: 0.7164 - val_acc: 0.5429\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6339 - acc: 0.6556 - val_loss: 0.7127 - val_acc: 0.5429\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6387 - acc: 0.6556 - val_loss: 0.7110 - val_acc: 0.5429\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6404 - acc: 0.6833 - val_loss: 0.7077 - val_acc: 0.5571\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6352 - acc: 0.7111 - val_loss: 0.7086 - val_acc: 0.5429\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6421 - acc: 0.6778 - val_loss: 0.7086 - val_acc: 0.5286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6254 - acc: 0.6944 - val_loss: 0.7087 - val_acc: 0.5429\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6243 - acc: 0.7167 - val_loss: 0.7101 - val_acc: 0.5429\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6269 - acc: 0.6556 - val_loss: 0.7081 - val_acc: 0.5429\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6310 - acc: 0.7167 - val_loss: 0.7063 - val_acc: 0.5714\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6298 - acc: 0.6611 - val_loss: 0.7042 - val_acc: 0.5571\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 136us/step - loss: 0.6203 - acc: 0.7333 - val_loss: 0.7051 - val_acc: 0.5714\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6095 - acc: 0.7111 - val_loss: 0.7034 - val_acc: 0.5857\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6165 - acc: 0.7222 - val_loss: 0.6973 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6119 - acc: 0.7000 - val_loss: 0.6967 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5999 - acc: 0.7722 - val_loss: 0.6943 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6167 - acc: 0.7444 - val_loss: 0.6978 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5983 - acc: 0.7167 - val_loss: 0.6955 - val_acc: 0.5857\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6005 - acc: 0.7278 - val_loss: 0.6976 - val_acc: 0.6000\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 121us/step - loss: 0.5990 - acc: 0.7278 - val_loss: 0.6998 - val_acc: 0.6000\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6108 - acc: 0.6944 - val_loss: 0.6905 - val_acc: 0.6429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5857 - acc: 0.7722 - val_loss: 0.6935 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5948 - acc: 0.7667 - val_loss: 0.7013 - val_acc: 0.5857\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5865 - acc: 0.7333 - val_loss: 0.6947 - val_acc: 0.6286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5804 - acc: 0.7778 - val_loss: 0.6908 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5847 - acc: 0.7056 - val_loss: 0.6926 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5971 - acc: 0.7167 - val_loss: 0.6912 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5704 - acc: 0.7389 - val_loss: 0.6900 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5667 - acc: 0.7611 - val_loss: 0.6882 - val_acc: 0.6429\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5705 - acc: 0.7833 - val_loss: 0.6911 - val_acc: 0.6143\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5596 - acc: 0.7556 - val_loss: 0.6841 - val_acc: 0.6857\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5688 - acc: 0.7722 - val_loss: 0.6902 - val_acc: 0.6286\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5637 - acc: 0.8000 - val_loss: 0.6947 - val_acc: 0.6286\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5563 - acc: 0.7889 - val_loss: 0.6920 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5531 - acc: 0.7944 - val_loss: 0.6939 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5656 - acc: 0.7944 - val_loss: 0.6901 - val_acc: 0.6429\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 130us/step - loss: 0.5545 - acc: 0.7722 - val_loss: 0.6973 - val_acc: 0.6143\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5549 - acc: 0.7500 - val_loss: 0.6905 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5317 - acc: 0.8111 - val_loss: 0.6926 - val_acc: 0.6429\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5359 - acc: 0.7944 - val_loss: 0.6864 - val_acc: 0.6857\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5307 - acc: 0.8056 - val_loss: 0.6877 - val_acc: 0.6714\n",
      "80/80 [==============================] - 0s 169us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 28ms/step - loss: 0.8461 - acc: 0.4556 - val_loss: 0.7702 - val_acc: 0.5143\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7844 - acc: 0.4722 - val_loss: 0.7605 - val_acc: 0.4857\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7798 - acc: 0.4000 - val_loss: 0.7550 - val_acc: 0.4714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7714 - acc: 0.4667 - val_loss: 0.7507 - val_acc: 0.5143\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7592 - acc: 0.5278 - val_loss: 0.7461 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7588 - acc: 0.4778 - val_loss: 0.7429 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7334 - acc: 0.5778 - val_loss: 0.7393 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7470 - acc: 0.5278 - val_loss: 0.7374 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7288 - acc: 0.5667 - val_loss: 0.7355 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7254 - acc: 0.5778 - val_loss: 0.7359 - val_acc: 0.5429\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7276 - acc: 0.5722 - val_loss: 0.7354 - val_acc: 0.5429\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7399 - acc: 0.5278 - val_loss: 0.7330 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7100 - acc: 0.6111 - val_loss: 0.7331 - val_acc: 0.5571\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7145 - acc: 0.5778 - val_loss: 0.7308 - val_acc: 0.5571\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.7200 - acc: 0.5389 - val_loss: 0.7320 - val_acc: 0.5286\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7138 - acc: 0.5778 - val_loss: 0.7311 - val_acc: 0.5429\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7145 - acc: 0.5889 - val_loss: 0.7294 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7066 - acc: 0.5944 - val_loss: 0.7293 - val_acc: 0.5429\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7001 - acc: 0.6000 - val_loss: 0.7289 - val_acc: 0.5143\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7077 - acc: 0.5833 - val_loss: 0.7267 - val_acc: 0.5571\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7092 - acc: 0.5833 - val_loss: 0.7263 - val_acc: 0.5571\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7031 - acc: 0.5944 - val_loss: 0.7260 - val_acc: 0.5571\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 129us/step - loss: 0.6945 - acc: 0.6278 - val_loss: 0.7280 - val_acc: 0.5000\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7032 - acc: 0.5833 - val_loss: 0.7270 - val_acc: 0.5286\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6957 - acc: 0.6056 - val_loss: 0.7287 - val_acc: 0.5000\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6859 - acc: 0.5722 - val_loss: 0.7235 - val_acc: 0.5429\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6909 - acc: 0.6444 - val_loss: 0.7251 - val_acc: 0.5286\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 118us/step - loss: 0.6897 - acc: 0.5778 - val_loss: 0.7212 - val_acc: 0.5714\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6843 - acc: 0.6167 - val_loss: 0.7212 - val_acc: 0.5571\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6942 - acc: 0.5889 - val_loss: 0.7196 - val_acc: 0.5571\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/step - loss: 0.6815 - acc: 0.6333 - val_loss: 0.7186 - val_acc: 0.5571\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.6729 - acc: 0.6722 - val_loss: 0.7198 - val_acc: 0.5714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6860 - acc: 0.5944 - val_loss: 0.7197 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6790 - acc: 0.5944 - val_loss: 0.7164 - val_acc: 0.5714\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6678 - acc: 0.6667 - val_loss: 0.7134 - val_acc: 0.5714\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6739 - acc: 0.6333 - val_loss: 0.7104 - val_acc: 0.6286\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6727 - acc: 0.6611 - val_loss: 0.7098 - val_acc: 0.6286\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6711 - acc: 0.6556 - val_loss: 0.7079 - val_acc: 0.6429\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6614 - acc: 0.6889 - val_loss: 0.7138 - val_acc: 0.5714\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6593 - acc: 0.6444 - val_loss: 0.7105 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6629 - acc: 0.6778 - val_loss: 0.7121 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6534 - acc: 0.6889 - val_loss: 0.7100 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6575 - acc: 0.6556 - val_loss: 0.7082 - val_acc: 0.6000\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6473 - acc: 0.6611 - val_loss: 0.7084 - val_acc: 0.6143\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6430 - acc: 0.6667 - val_loss: 0.7053 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6653 - acc: 0.6667 - val_loss: 0.7021 - val_acc: 0.6571\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6448 - acc: 0.6722 - val_loss: 0.7018 - val_acc: 0.6571\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6527 - acc: 0.7111 - val_loss: 0.7029 - val_acc: 0.6286\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6383 - acc: 0.7056 - val_loss: 0.7025 - val_acc: 0.6429\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6353 - acc: 0.7111 - val_loss: 0.7038 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6343 - acc: 0.6889 - val_loss: 0.7014 - val_acc: 0.6429\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6392 - acc: 0.6833 - val_loss: 0.7006 - val_acc: 0.6429\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6383 - acc: 0.7111 - val_loss: 0.6991 - val_acc: 0.6571\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6312 - acc: 0.7278 - val_loss: 0.7018 - val_acc: 0.6286\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6193 - acc: 0.7111 - val_loss: 0.6997 - val_acc: 0.6571\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6190 - acc: 0.7222 - val_loss: 0.6981 - val_acc: 0.6714\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6259 - acc: 0.7167 - val_loss: 0.7019 - val_acc: 0.6286\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6133 - acc: 0.7056 - val_loss: 0.6996 - val_acc: 0.6429\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6056 - acc: 0.7722 - val_loss: 0.6939 - val_acc: 0.6857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6184 - acc: 0.7222 - val_loss: 0.6989 - val_acc: 0.6429\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6026 - acc: 0.7333 - val_loss: 0.7001 - val_acc: 0.6429\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5895 - acc: 0.7444 - val_loss: 0.6985 - val_acc: 0.6429\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6089 - acc: 0.7333 - val_loss: 0.6961 - val_acc: 0.6571\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5834 - acc: 0.7389 - val_loss: 0.6913 - val_acc: 0.6714\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6007 - acc: 0.7278 - val_loss: 0.6915 - val_acc: 0.6857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5911 - acc: 0.7500 - val_loss: 0.6878 - val_acc: 0.6571\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5909 - acc: 0.7556 - val_loss: 0.6951 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5956 - acc: 0.7333 - val_loss: 0.6877 - val_acc: 0.6571\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5652 - acc: 0.7667 - val_loss: 0.6924 - val_acc: 0.6286\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5794 - acc: 0.7667 - val_loss: 0.6848 - val_acc: 0.6714\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5887 - acc: 0.7222 - val_loss: 0.6828 - val_acc: 0.6714\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5879 - acc: 0.7611 - val_loss: 0.6876 - val_acc: 0.6714\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5864 - acc: 0.7389 - val_loss: 0.6957 - val_acc: 0.6286\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5698 - acc: 0.7444 - val_loss: 0.6900 - val_acc: 0.6571\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5684 - acc: 0.7833 - val_loss: 0.6940 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5599 - acc: 0.7722 - val_loss: 0.6931 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5741 - acc: 0.7444 - val_loss: 0.6871 - val_acc: 0.6571\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 115us/step - loss: 0.5508 - acc: 0.8056 - val_loss: 0.6912 - val_acc: 0.6429\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5534 - acc: 0.7778 - val_loss: 0.6999 - val_acc: 0.6286\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5522 - acc: 0.7944 - val_loss: 0.6878 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 162us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 29ms/step - loss: 0.8045 - acc: 0.4611 - val_loss: 0.7600 - val_acc: 0.5000\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7850 - acc: 0.4611 - val_loss: 0.7544 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7755 - acc: 0.4611 - val_loss: 0.7500 - val_acc: 0.5000\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7658 - acc: 0.4611 - val_loss: 0.7473 - val_acc: 0.5000\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7599 - acc: 0.4444 - val_loss: 0.7467 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7560 - acc: 0.4667 - val_loss: 0.7446 - val_acc: 0.5000\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7520 - acc: 0.4667 - val_loss: 0.7434 - val_acc: 0.4857\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7507 - acc: 0.4667 - val_loss: 0.7428 - val_acc: 0.4571\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7459 - acc: 0.4500 - val_loss: 0.7422 - val_acc: 0.5143\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7422 - acc: 0.4889 - val_loss: 0.7412 - val_acc: 0.4714\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 127us/step - loss: 0.7425 - acc: 0.5000 - val_loss: 0.7405 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7413 - acc: 0.4944 - val_loss: 0.7400 - val_acc: 0.5286\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.7402 - acc: 0.5056 - val_loss: 0.7397 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7379 - acc: 0.5167 - val_loss: 0.7390 - val_acc: 0.5143\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7365 - acc: 0.5222 - val_loss: 0.7381 - val_acc: 0.5714\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7351 - acc: 0.5500 - val_loss: 0.7378 - val_acc: 0.5143\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7317 - acc: 0.5611 - val_loss: 0.7376 - val_acc: 0.4714\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7320 - acc: 0.5500 - val_loss: 0.7372 - val_acc: 0.4714\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7309 - acc: 0.5944 - val_loss: 0.7368 - val_acc: 0.4857\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7276 - acc: 0.6056 - val_loss: 0.7365 - val_acc: 0.4857\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7282 - acc: 0.5833 - val_loss: 0.7356 - val_acc: 0.5143\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7229 - acc: 0.6389 - val_loss: 0.7351 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7215 - acc: 0.5667 - val_loss: 0.7346 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7226 - acc: 0.5944 - val_loss: 0.7335 - val_acc: 0.4857\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7220 - acc: 0.6000 - val_loss: 0.7330 - val_acc: 0.4857\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7171 - acc: 0.6222 - val_loss: 0.7323 - val_acc: 0.5000\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.7154 - acc: 0.6556 - val_loss: 0.7318 - val_acc: 0.4857\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7148 - acc: 0.6278 - val_loss: 0.7311 - val_acc: 0.5143\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7165 - acc: 0.6222 - val_loss: 0.7304 - val_acc: 0.5143\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7097 - acc: 0.6444 - val_loss: 0.7304 - val_acc: 0.5143\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7075 - acc: 0.6611 - val_loss: 0.7306 - val_acc: 0.5000\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7135 - acc: 0.6278 - val_loss: 0.7305 - val_acc: 0.4714\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7076 - acc: 0.6611 - val_loss: 0.7299 - val_acc: 0.5143\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7083 - acc: 0.6500 - val_loss: 0.7291 - val_acc: 0.5143\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7047 - acc: 0.6222 - val_loss: 0.7285 - val_acc: 0.5000\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.7053 - acc: 0.6500 - val_loss: 0.7274 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7027 - acc: 0.6389 - val_loss: 0.7272 - val_acc: 0.5429\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6944 - acc: 0.6944 - val_loss: 0.7269 - val_acc: 0.5714\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6961 - acc: 0.6944 - val_loss: 0.7266 - val_acc: 0.5286\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6928 - acc: 0.6667 - val_loss: 0.7257 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6930 - acc: 0.6833 - val_loss: 0.7250 - val_acc: 0.5286\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6946 - acc: 0.6889 - val_loss: 0.7240 - val_acc: 0.5571\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6858 - acc: 0.6889 - val_loss: 0.7241 - val_acc: 0.5429\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6828 - acc: 0.6889 - val_loss: 0.7236 - val_acc: 0.5714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6817 - acc: 0.6833 - val_loss: 0.7230 - val_acc: 0.6286\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6795 - acc: 0.7111 - val_loss: 0.7229 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6735 - acc: 0.7167 - val_loss: 0.7222 - val_acc: 0.6286\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6848 - acc: 0.6722 - val_loss: 0.7223 - val_acc: 0.6571\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6784 - acc: 0.6778 - val_loss: 0.7221 - val_acc: 0.6571\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6780 - acc: 0.6833 - val_loss: 0.7220 - val_acc: 0.6571\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6747 - acc: 0.7111 - val_loss: 0.7217 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6718 - acc: 0.6833 - val_loss: 0.7215 - val_acc: 0.6286\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6620 - acc: 0.7056 - val_loss: 0.7208 - val_acc: 0.6286\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6645 - acc: 0.7167 - val_loss: 0.7202 - val_acc: 0.6429\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6671 - acc: 0.6944 - val_loss: 0.7193 - val_acc: 0.6429\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6626 - acc: 0.7111 - val_loss: 0.7193 - val_acc: 0.6571\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6572 - acc: 0.7333 - val_loss: 0.7203 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6505 - acc: 0.7611 - val_loss: 0.7208 - val_acc: 0.5857\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6431 - acc: 0.7278 - val_loss: 0.7211 - val_acc: 0.5714\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6579 - acc: 0.7000 - val_loss: 0.7196 - val_acc: 0.6286\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6511 - acc: 0.7333 - val_loss: 0.7194 - val_acc: 0.6286\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6415 - acc: 0.7278 - val_loss: 0.7192 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6540 - acc: 0.6889 - val_loss: 0.7208 - val_acc: 0.5857\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6440 - acc: 0.7278 - val_loss: 0.7194 - val_acc: 0.6143\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6431 - acc: 0.7222 - val_loss: 0.7200 - val_acc: 0.6000\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6371 - acc: 0.7667 - val_loss: 0.7195 - val_acc: 0.6143\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6396 - acc: 0.7167 - val_loss: 0.7187 - val_acc: 0.6143\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6374 - acc: 0.7389 - val_loss: 0.7192 - val_acc: 0.6000\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6326 - acc: 0.7333 - val_loss: 0.7201 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6315 - acc: 0.7500 - val_loss: 0.7194 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6361 - acc: 0.7167 - val_loss: 0.7201 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6229 - acc: 0.7389 - val_loss: 0.7205 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6206 - acc: 0.7722 - val_loss: 0.7209 - val_acc: 0.5857\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6085 - acc: 0.7778 - val_loss: 0.7207 - val_acc: 0.5857\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6170 - acc: 0.7889 - val_loss: 0.7214 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6066 - acc: 0.7722 - val_loss: 0.7216 - val_acc: 0.6000\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6061 - acc: 0.7778 - val_loss: 0.7205 - val_acc: 0.6286\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6078 - acc: 0.7389 - val_loss: 0.7215 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6056 - acc: 0.7722 - val_loss: 0.7230 - val_acc: 0.5714\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.5971 - acc: 0.7889 - val_loss: 0.7207 - val_acc: 0.6000\n",
      "80/80 [==============================] - 0s 175us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 5s 31ms/step - loss: 0.7615 - acc: 0.4333 - val_loss: 0.7469 - val_acc: 0.4714\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7435 - acc: 0.4833 - val_loss: 0.7424 - val_acc: 0.5000\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7353 - acc: 0.5556 - val_loss: 0.7410 - val_acc: 0.4857\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7325 - acc: 0.5333 - val_loss: 0.7406 - val_acc: 0.4857\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7343 - acc: 0.5389 - val_loss: 0.7404 - val_acc: 0.5000\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7357 - acc: 0.5444 - val_loss: 0.7380 - val_acc: 0.5143\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7298 - acc: 0.5500 - val_loss: 0.7361 - val_acc: 0.5000\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7210 - acc: 0.5722 - val_loss: 0.7364 - val_acc: 0.5000\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7153 - acc: 0.5667 - val_loss: 0.7367 - val_acc: 0.5000\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7259 - acc: 0.5944 - val_loss: 0.7362 - val_acc: 0.5000\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7265 - acc: 0.5389 - val_loss: 0.7356 - val_acc: 0.5000\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 131us/step - loss: 0.7146 - acc: 0.5611 - val_loss: 0.7352 - val_acc: 0.5000\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7157 - acc: 0.5333 - val_loss: 0.7362 - val_acc: 0.5000\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7152 - acc: 0.5500 - val_loss: 0.7342 - val_acc: 0.5000\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7068 - acc: 0.5722 - val_loss: 0.7362 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7045 - acc: 0.5556 - val_loss: 0.7327 - val_acc: 0.5000\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7110 - acc: 0.5722 - val_loss: 0.7327 - val_acc: 0.5000\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7027 - acc: 0.5722 - val_loss: 0.7338 - val_acc: 0.5000\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7032 - acc: 0.5722 - val_loss: 0.7331 - val_acc: 0.5000\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7064 - acc: 0.5722 - val_loss: 0.7319 - val_acc: 0.5000\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7021 - acc: 0.5500 - val_loss: 0.7329 - val_acc: 0.5000\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.7013 - acc: 0.5833 - val_loss: 0.7297 - val_acc: 0.5000\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.7049 - acc: 0.5722 - val_loss: 0.7264 - val_acc: 0.5143\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.7059 - acc: 0.5833 - val_loss: 0.7249 - val_acc: 0.5143\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6875 - acc: 0.6000 - val_loss: 0.7252 - val_acc: 0.5143\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6897 - acc: 0.5889 - val_loss: 0.7244 - val_acc: 0.5286\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6838 - acc: 0.6222 - val_loss: 0.7227 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6966 - acc: 0.5944 - val_loss: 0.7201 - val_acc: 0.5429\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6860 - acc: 0.6444 - val_loss: 0.7200 - val_acc: 0.5429\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6807 - acc: 0.6167 - val_loss: 0.7171 - val_acc: 0.5429\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6776 - acc: 0.6444 - val_loss: 0.7147 - val_acc: 0.5286\n",
      "Epoch 32/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6824 - acc: 0.6222 - val_loss: 0.7120 - val_acc: 0.5286\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6714 - acc: 0.6722 - val_loss: 0.7142 - val_acc: 0.5429\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6745 - acc: 0.6444 - val_loss: 0.7111 - val_acc: 0.5286\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6838 - acc: 0.6056 - val_loss: 0.7093 - val_acc: 0.5429\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6666 - acc: 0.6611 - val_loss: 0.7080 - val_acc: 0.5571\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 277us/step - loss: 0.6771 - acc: 0.6278 - val_loss: 0.7105 - val_acc: 0.5571\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 233us/step - loss: 0.6653 - acc: 0.6667 - val_loss: 0.7123 - val_acc: 0.5571\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6542 - acc: 0.6556 - val_loss: 0.7101 - val_acc: 0.5571\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6712 - acc: 0.6611 - val_loss: 0.7075 - val_acc: 0.5571\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6640 - acc: 0.6611 - val_loss: 0.7070 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.6611 - acc: 0.6556 - val_loss: 0.7027 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6471 - acc: 0.6944 - val_loss: 0.7025 - val_acc: 0.5857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6586 - acc: 0.7111 - val_loss: 0.7061 - val_acc: 0.5857\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.6459 - acc: 0.6389 - val_loss: 0.7028 - val_acc: 0.6143\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6547 - acc: 0.6778 - val_loss: 0.7036 - val_acc: 0.6000\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6570 - acc: 0.6611 - val_loss: 0.6990 - val_acc: 0.5857\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6392 - acc: 0.6889 - val_loss: 0.7013 - val_acc: 0.6143\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6365 - acc: 0.7167 - val_loss: 0.7020 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6417 - acc: 0.7000 - val_loss: 0.6979 - val_acc: 0.6000\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6384 - acc: 0.7111 - val_loss: 0.7004 - val_acc: 0.6000\n",
      "Epoch 52/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 122us/step - loss: 0.6282 - acc: 0.7444 - val_loss: 0.7011 - val_acc: 0.6000\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6245 - acc: 0.7278 - val_loss: 0.6949 - val_acc: 0.6000\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6264 - acc: 0.7278 - val_loss: 0.6962 - val_acc: 0.6000\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.6301 - acc: 0.7111 - val_loss: 0.6939 - val_acc: 0.6143\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6227 - acc: 0.7444 - val_loss: 0.6973 - val_acc: 0.6143\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6283 - acc: 0.7000 - val_loss: 0.7009 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6184 - acc: 0.7222 - val_loss: 0.6958 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6179 - acc: 0.7222 - val_loss: 0.6987 - val_acc: 0.5857\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6180 - acc: 0.7333 - val_loss: 0.6986 - val_acc: 0.6000\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6090 - acc: 0.7278 - val_loss: 0.6940 - val_acc: 0.6143\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.6060 - acc: 0.7111 - val_loss: 0.6955 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6241 - acc: 0.7167 - val_loss: 0.6902 - val_acc: 0.6286\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6114 - acc: 0.7000 - val_loss: 0.6884 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6008 - acc: 0.7667 - val_loss: 0.6902 - val_acc: 0.6143\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.6016 - acc: 0.7500 - val_loss: 0.6940 - val_acc: 0.6000\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 205us/step - loss: 0.6056 - acc: 0.7167 - val_loss: 0.6962 - val_acc: 0.5857\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6090 - acc: 0.7278 - val_loss: 0.6960 - val_acc: 0.5857\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5970 - acc: 0.7611 - val_loss: 0.6915 - val_acc: 0.6000\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6007 - acc: 0.7444 - val_loss: 0.6885 - val_acc: 0.6143\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 266us/step - loss: 0.5974 - acc: 0.7500 - val_loss: 0.6873 - val_acc: 0.6143\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5906 - acc: 0.7722 - val_loss: 0.6945 - val_acc: 0.6000\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5774 - acc: 0.7778 - val_loss: 0.6944 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5898 - acc: 0.7500 - val_loss: 0.7001 - val_acc: 0.5714\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5965 - acc: 0.7278 - val_loss: 0.6910 - val_acc: 0.6286\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 144us/step - loss: 0.5767 - acc: 0.7722 - val_loss: 0.6889 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 115us/step - loss: 0.5677 - acc: 0.7889 - val_loss: 0.6972 - val_acc: 0.6000\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5771 - acc: 0.7444 - val_loss: 0.6967 - val_acc: 0.6143\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5697 - acc: 0.7722 - val_loss: 0.6982 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5613 - acc: 0.7778 - val_loss: 0.6909 - val_acc: 0.6429\n",
      "80/80 [==============================] - 0s 150us/step\n",
      "Train on 180 samples, validate on 70 samples\n",
      "Epoch 1/80\n",
      "180/180 [==============================] - 6s 34ms/step - loss: 0.7922 - acc: 0.4722 - val_loss: 0.7447 - val_acc: 0.4429\n",
      "Epoch 2/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.7421 - acc: 0.5111 - val_loss: 0.7365 - val_acc: 0.5571\n",
      "Epoch 3/80\n",
      "180/180 [==============================] - 0s 158us/step - loss: 0.7261 - acc: 0.5778 - val_loss: 0.7339 - val_acc: 0.5714\n",
      "Epoch 4/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7320 - acc: 0.5500 - val_loss: 0.7350 - val_acc: 0.5429\n",
      "Epoch 5/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7140 - acc: 0.6111 - val_loss: 0.7344 - val_acc: 0.5429\n",
      "Epoch 6/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7148 - acc: 0.5889 - val_loss: 0.7377 - val_acc: 0.5286\n",
      "Epoch 7/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7153 - acc: 0.5889 - val_loss: 0.7372 - val_acc: 0.5429\n",
      "Epoch 8/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.7064 - acc: 0.6333 - val_loss: 0.7364 - val_acc: 0.5286\n",
      "Epoch 9/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6996 - acc: 0.6056 - val_loss: 0.7343 - val_acc: 0.5286\n",
      "Epoch 10/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6968 - acc: 0.6333 - val_loss: 0.7339 - val_acc: 0.5286\n",
      "Epoch 11/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7023 - acc: 0.6167 - val_loss: 0.7348 - val_acc: 0.5143\n",
      "Epoch 12/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.7007 - acc: 0.6056 - val_loss: 0.7285 - val_acc: 0.5429\n",
      "Epoch 13/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6816 - acc: 0.6778 - val_loss: 0.7252 - val_acc: 0.5571\n",
      "Epoch 14/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6890 - acc: 0.6667 - val_loss: 0.7271 - val_acc: 0.5429\n",
      "Epoch 15/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6959 - acc: 0.6278 - val_loss: 0.7244 - val_acc: 0.5429\n",
      "Epoch 16/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6873 - acc: 0.6222 - val_loss: 0.7281 - val_acc: 0.5286\n",
      "Epoch 17/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6870 - acc: 0.6556 - val_loss: 0.7293 - val_acc: 0.5429\n",
      "Epoch 18/80\n",
      "180/180 [==============================] - 0s 172us/step - loss: 0.6727 - acc: 0.6667 - val_loss: 0.7246 - val_acc: 0.5286\n",
      "Epoch 19/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6710 - acc: 0.6389 - val_loss: 0.7237 - val_acc: 0.5286\n",
      "Epoch 20/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6750 - acc: 0.6556 - val_loss: 0.7265 - val_acc: 0.5429\n",
      "Epoch 21/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6668 - acc: 0.6667 - val_loss: 0.7249 - val_acc: 0.5429\n",
      "Epoch 22/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6530 - acc: 0.6389 - val_loss: 0.7224 - val_acc: 0.5429\n",
      "Epoch 23/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6608 - acc: 0.6222 - val_loss: 0.7196 - val_acc: 0.5714\n",
      "Epoch 24/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6739 - acc: 0.6389 - val_loss: 0.7226 - val_acc: 0.5429\n",
      "Epoch 25/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6549 - acc: 0.6667 - val_loss: 0.7263 - val_acc: 0.5286\n",
      "Epoch 26/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6569 - acc: 0.6556 - val_loss: 0.7223 - val_acc: 0.5143\n",
      "Epoch 27/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6516 - acc: 0.6889 - val_loss: 0.7220 - val_acc: 0.5429\n",
      "Epoch 28/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6526 - acc: 0.6556 - val_loss: 0.7191 - val_acc: 0.5571\n",
      "Epoch 29/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6418 - acc: 0.6722 - val_loss: 0.7223 - val_acc: 0.5286\n",
      "Epoch 30/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6484 - acc: 0.6556 - val_loss: 0.7175 - val_acc: 0.6000\n",
      "Epoch 31/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6407 - acc: 0.7167 - val_loss: 0.7218 - val_acc: 0.5286\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 127us/step - loss: 0.6387 - acc: 0.7056 - val_loss: 0.7225 - val_acc: 0.5429\n",
      "Epoch 33/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.6388 - acc: 0.7111 - val_loss: 0.7165 - val_acc: 0.5714\n",
      "Epoch 34/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6257 - acc: 0.6889 - val_loss: 0.7176 - val_acc: 0.5857\n",
      "Epoch 35/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.6179 - acc: 0.7111 - val_loss: 0.7183 - val_acc: 0.5857\n",
      "Epoch 36/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6227 - acc: 0.7278 - val_loss: 0.7196 - val_acc: 0.5714\n",
      "Epoch 37/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6250 - acc: 0.7000 - val_loss: 0.7190 - val_acc: 0.5857\n",
      "Epoch 38/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6212 - acc: 0.6889 - val_loss: 0.7178 - val_acc: 0.6000\n",
      "Epoch 39/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.6198 - acc: 0.7111 - val_loss: 0.7155 - val_acc: 0.6000\n",
      "Epoch 40/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6165 - acc: 0.7278 - val_loss: 0.7155 - val_acc: 0.5857\n",
      "Epoch 41/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6121 - acc: 0.7389 - val_loss: 0.7198 - val_acc: 0.5714\n",
      "Epoch 42/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.6134 - acc: 0.7278 - val_loss: 0.7222 - val_acc: 0.5857\n",
      "Epoch 43/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5923 - acc: 0.7389 - val_loss: 0.7225 - val_acc: 0.5857\n",
      "Epoch 44/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.6038 - acc: 0.7167 - val_loss: 0.7205 - val_acc: 0.5714\n",
      "Epoch 45/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5981 - acc: 0.7222 - val_loss: 0.7206 - val_acc: 0.5857\n",
      "Epoch 46/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5997 - acc: 0.7444 - val_loss: 0.7227 - val_acc: 0.6143\n",
      "Epoch 47/80\n",
      "180/180 [==============================] - 0s 124us/step - loss: 0.6036 - acc: 0.7167 - val_loss: 0.7134 - val_acc: 0.6000\n",
      "Epoch 48/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5896 - acc: 0.7389 - val_loss: 0.7138 - val_acc: 0.5857\n",
      "Epoch 49/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5870 - acc: 0.7278 - val_loss: 0.7173 - val_acc: 0.6000\n",
      "Epoch 50/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5831 - acc: 0.7444 - val_loss: 0.7142 - val_acc: 0.6143\n",
      "Epoch 51/80\n",
      "180/180 [==============================] - 0s 139us/step - loss: 0.5677 - acc: 0.8000 - val_loss: 0.7218 - val_acc: 0.6143\n",
      "Epoch 52/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5940 - acc: 0.7556 - val_loss: 0.7211 - val_acc: 0.6143\n",
      "Epoch 53/80\n",
      "180/180 [==============================] - 0s 150us/step - loss: 0.5701 - acc: 0.7722 - val_loss: 0.7182 - val_acc: 0.6143\n",
      "Epoch 54/80\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.5854 - acc: 0.7444 - val_loss: 0.7130 - val_acc: 0.5857\n",
      "Epoch 55/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5973 - acc: 0.7389 - val_loss: 0.7130 - val_acc: 0.5857\n",
      "Epoch 56/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5740 - acc: 0.7333 - val_loss: 0.7146 - val_acc: 0.6000\n",
      "Epoch 57/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5748 - acc: 0.7778 - val_loss: 0.7177 - val_acc: 0.6000\n",
      "Epoch 58/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5455 - acc: 0.8056 - val_loss: 0.7143 - val_acc: 0.6143\n",
      "Epoch 59/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5434 - acc: 0.8111 - val_loss: 0.7178 - val_acc: 0.6143\n",
      "Epoch 60/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5583 - acc: 0.7611 - val_loss: 0.7193 - val_acc: 0.6143\n",
      "Epoch 61/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5511 - acc: 0.7778 - val_loss: 0.7162 - val_acc: 0.6000\n",
      "Epoch 62/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5320 - acc: 0.8000 - val_loss: 0.7215 - val_acc: 0.6143\n",
      "Epoch 63/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5422 - acc: 0.7833 - val_loss: 0.7171 - val_acc: 0.6143\n",
      "Epoch 64/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5592 - acc: 0.7389 - val_loss: 0.7171 - val_acc: 0.6286\n",
      "Epoch 65/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5415 - acc: 0.7778 - val_loss: 0.7134 - val_acc: 0.5857\n",
      "Epoch 66/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5701 - acc: 0.7111 - val_loss: 0.7248 - val_acc: 0.6286\n",
      "Epoch 67/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5388 - acc: 0.7556 - val_loss: 0.7238 - val_acc: 0.6286\n",
      "Epoch 68/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5447 - acc: 0.7889 - val_loss: 0.7191 - val_acc: 0.6143\n",
      "Epoch 69/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5470 - acc: 0.7889 - val_loss: 0.7164 - val_acc: 0.5857\n",
      "Epoch 70/80\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.5348 - acc: 0.7778 - val_loss: 0.7181 - val_acc: 0.6286\n",
      "Epoch 71/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5099 - acc: 0.8056 - val_loss: 0.7158 - val_acc: 0.5857\n",
      "Epoch 72/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5385 - acc: 0.7444 - val_loss: 0.7206 - val_acc: 0.6429\n",
      "Epoch 73/80\n",
      "180/180 [==============================] - 0s 130us/step - loss: 0.5136 - acc: 0.7944 - val_loss: 0.7186 - val_acc: 0.6000\n",
      "Epoch 74/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.5100 - acc: 0.8167 - val_loss: 0.7191 - val_acc: 0.6143\n",
      "Epoch 75/80\n",
      "180/180 [==============================] - 0s 155us/step - loss: 0.5191 - acc: 0.7944 - val_loss: 0.7192 - val_acc: 0.6000\n",
      "Epoch 76/80\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.4954 - acc: 0.8111 - val_loss: 0.7261 - val_acc: 0.6286\n",
      "Epoch 77/80\n",
      "180/180 [==============================] - 0s 114us/step - loss: 0.5250 - acc: 0.7722 - val_loss: 0.7212 - val_acc: 0.6143\n",
      "Epoch 78/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5219 - acc: 0.7778 - val_loss: 0.7172 - val_acc: 0.6000\n",
      "Epoch 79/80\n",
      "180/180 [==============================] - 0s 127us/step - loss: 0.5088 - acc: 0.7944 - val_loss: 0.7179 - val_acc: 0.6143\n",
      "Epoch 80/80\n",
      "180/180 [==============================] - 0s 122us/step - loss: 0.5192 - acc: 0.7833 - val_loss: 0.7256 - val_acc: 0.6286\n",
      "80/80 [==============================] - 0s 150us/step\n"
     ]
    }
   ],
   "source": [
    "test_set_acc = []\n",
    "for i in range( 100):\n",
    "    model = models.Sequential()\n",
    "    model.add( layers.Dense(28, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add( layers.Dropout(0.1))\n",
    "    model.add( layers.Dense(14, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add( layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=80,\n",
    "                        batch_size=128,\n",
    "                        validation_data=(x_val, y_val))\n",
    "    test_set_acc.append( model.evaluate( x_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6143749999999999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = sum(test_set_acc) / len(test_set_acc)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(test_set_acc)), test_set_acc)\n",
    "plt.plot(np.arange(len(test_set_acc)), np.repeat(avg, len(test_set_acc)), \"r\")\n",
    "plt.title('Performance on test set for different runs')\n",
    "plt.xlabel('Run no')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.6261 - acc: 0.7167\n",
      "Epoch 2/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.6306 - acc: 0.6733\n",
      "Epoch 3/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5965 - acc: 0.7100\n",
      "Epoch 4/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5850 - acc: 0.7433\n",
      "Epoch 5/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5904 - acc: 0.6900\n",
      "Epoch 6/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5783 - acc: 0.7267\n",
      "Epoch 7/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5558 - acc: 0.7133\n",
      "Epoch 8/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5349 - acc: 0.7567\n",
      "Epoch 9/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5346 - acc: 0.7367\n",
      "Epoch 10/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5233 - acc: 0.7600\n",
      "Epoch 11/11\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5275 - acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# optional training at the end, with validation set included\n",
    "history = model.fit(data[:10*30][:],\n",
    "                    label[:10*30],\n",
    "                    epochs=11,\n",
    "                    batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 187us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6741812705993653, 0.6375]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate( x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
